{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " every image is represented as a 28×28 array rather than a 1D array of size 784. Moreover, the pixel intensities are represented as integers (from 0 to 255) rather than floats (from 0.0 to 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the input since we are using Gradient Descent\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understanding the class labels\n",
    "\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "                   \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a model using the sequential API\n",
    "model = keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model.add(keras.layers.Dense(300,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x7fbc92a17c90>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fbc921fc450>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fbce1e7ebd0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fbca1489190>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the weights, and biases of the model\n",
    "weights, biases = model.get_layer('dense_1').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01128004, -0.00735682,  0.09361725, ..., -0.09209834,\n",
       "        -0.08681822, -0.03004577],\n",
       "       [ 0.05650689, -0.00498833,  0.05840374, ..., -0.01784371,\n",
       "        -0.06637096,  0.11309985],\n",
       "       [-0.02546272, -0.08141825,  0.08683679, ..., -0.00883499,\n",
       "        -0.0058987 , -0.06083787],\n",
       "       ...,\n",
       "       [ 0.00953818,  0.03811146, -0.00605261, ...,  0.0470515 ,\n",
       "        -0.05743313,  0.04480235],\n",
       "       [-0.09500621,  0.02215839, -0.05008762, ...,  0.03873315,\n",
       "         0.00718696,  0.09941693],\n",
       "       [ 0.03429104,  0.0424263 , -0.1135316 , ...,  0.11729642,\n",
       "        -0.01590876,  0.03119291]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can set kernel_initializer (kernel is another name for the matrix of connec‐ tion weights) or bias_initializer when creating the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                  optimizer=\"sgd\",\n",
    "                  metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 3s 49us/sample - loss: 0.7224 - accuracy: 0.7591 - val_loss: 0.5125 - val_accuracy: 0.8282\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 2s 44us/sample - loss: 0.4948 - accuracy: 0.8273 - val_loss: 0.4814 - val_accuracy: 0.8312\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 2s 43us/sample - loss: 0.4480 - accuracy: 0.8432 - val_loss: 0.4308 - val_accuracy: 0.8482\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 2s 44us/sample - loss: 0.4196 - accuracy: 0.8533 - val_loss: 0.3980 - val_accuracy: 0.8656\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.3999 - accuracy: 0.8596 - val_loss: 0.3863 - val_accuracy: 0.8644\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 2s 44us/sample - loss: 0.3835 - accuracy: 0.8664 - val_loss: 0.3899 - val_accuracy: 0.8616\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.3698 - accuracy: 0.8692 - val_loss: 0.3594 - val_accuracy: 0.8758\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.3577 - accuracy: 0.8731 - val_loss: 0.3653 - val_accuracy: 0.8714\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 2s 44us/sample - loss: 0.3474 - accuracy: 0.8779 - val_loss: 0.3455 - val_accuracy: 0.8770\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 2s 44us/sample - loss: 0.3384 - accuracy: 0.8797 - val_loss: 0.3421 - val_accuracy: 0.8798\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.3288 - accuracy: 0.8836 - val_loss: 0.3403 - val_accuracy: 0.8800\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.3205 - accuracy: 0.8852 - val_loss: 0.3630 - val_accuracy: 0.8720\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.3123 - accuracy: 0.8880 - val_loss: 0.3283 - val_accuracy: 0.8876\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 3s 45us/sample - loss: 0.3065 - accuracy: 0.8904 - val_loss: 0.3214 - val_accuracy: 0.8834\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.2991 - accuracy: 0.8921 - val_loss: 0.3186 - val_accuracy: 0.8880\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.2931 - accuracy: 0.8949 - val_loss: 0.3237 - val_accuracy: 0.8836\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.2878 - accuracy: 0.8965 - val_loss: 0.3278 - val_accuracy: 0.8832\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.2821 - accuracy: 0.8999 - val_loss: 0.3083 - val_accuracy: 0.8910\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 3s 46us/sample - loss: 0.2764 - accuracy: 0.9004 - val_loss: 0.3142 - val_accuracy: 0.8908\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 3s 46us/sample - loss: 0.2723 - accuracy: 0.9025 - val_loss: 0.3132 - val_accuracy: 0.8906\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.2667 - accuracy: 0.9027 - val_loss: 0.3174 - val_accuracy: 0.8854\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.2614 - accuracy: 0.9055 - val_loss: 0.2996 - val_accuracy: 0.8934\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 3s 46us/sample - loss: 0.2579 - accuracy: 0.9081 - val_loss: 0.2950 - val_accuracy: 0.8936\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.2528 - accuracy: 0.9093 - val_loss: 0.3106 - val_accuracy: 0.8870\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.2491 - accuracy: 0.9110 - val_loss: 0.3279 - val_accuracy: 0.8834\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.2437 - accuracy: 0.9113 - val_loss: 0.3005 - val_accuracy: 0.8922\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.2405 - accuracy: 0.9135 - val_loss: 0.3077 - val_accuracy: 0.8860\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.2361 - accuracy: 0.9151 - val_loss: 0.2973 - val_accuracy: 0.8960\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 2s 44us/sample - loss: 0.2322 - accuracy: 0.9168 - val_loss: 0.2994 - val_accuracy: 0.8928\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 2s 44us/sample - loss: 0.2283 - accuracy: 0.9189 - val_loss: 0.2870 - val_accuracy: 0.8926\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, \n",
    "                    validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'epochs': 30,\n",
       " 'steps': 1719,\n",
       " 'samples': 55000,\n",
       " 'verbose': 0,\n",
       " 'do_validation': True,\n",
       " 'metrics': ['loss', 'accuracy', 'val_loss', 'val_accuracy']}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.7223682985956018,\n",
       "  0.4947564394604076,\n",
       "  0.44802508129856805,\n",
       "  0.4196484719016335,\n",
       "  0.39993995835130863,\n",
       "  0.3835165087526495,\n",
       "  0.3697991550055417,\n",
       "  0.3577111726630818,\n",
       "  0.3473910493590615,\n",
       "  0.33842482429200954,\n",
       "  0.32880902249596333,\n",
       "  0.3205253321951086,\n",
       "  0.3122899998426437,\n",
       "  0.306469693498178,\n",
       "  0.29909581359083004,\n",
       "  0.2931331576889212,\n",
       "  0.28775002394806254,\n",
       "  0.28205479870709504,\n",
       "  0.27640809055458415,\n",
       "  0.2723044556942853,\n",
       "  0.2667009500850331,\n",
       "  0.2614359555883841,\n",
       "  0.2579382946469567,\n",
       "  0.2528232771645893,\n",
       "  0.2490648357413032,\n",
       "  0.24371447787772527,\n",
       "  0.24048340202895077,\n",
       "  0.2360901727123694,\n",
       "  0.23215109536431053,\n",
       "  0.22829796201315794],\n",
       " 'accuracy': [0.7591091,\n",
       "  0.82732725,\n",
       "  0.8432182,\n",
       "  0.85327274,\n",
       "  0.85963637,\n",
       "  0.86643636,\n",
       "  0.8692182,\n",
       "  0.87307274,\n",
       "  0.8778727,\n",
       "  0.8797455,\n",
       "  0.88356364,\n",
       "  0.8852364,\n",
       "  0.8880182,\n",
       "  0.8903818,\n",
       "  0.89214545,\n",
       "  0.8949091,\n",
       "  0.8965091,\n",
       "  0.8998727,\n",
       "  0.90043634,\n",
       "  0.9025091,\n",
       "  0.9026909,\n",
       "  0.90549093,\n",
       "  0.9080727,\n",
       "  0.90927273,\n",
       "  0.91098183,\n",
       "  0.9113455,\n",
       "  0.9135091,\n",
       "  0.9150909,\n",
       "  0.9168364,\n",
       "  0.91885453],\n",
       " 'val_loss': [0.5124915121078492,\n",
       "  0.48140500721931456,\n",
       "  0.43083464485406875,\n",
       "  0.398021731710434,\n",
       "  0.3862582328915596,\n",
       "  0.38987717763185503,\n",
       "  0.35936189645528793,\n",
       "  0.36528732118606566,\n",
       "  0.34551237617731095,\n",
       "  0.3420543613195419,\n",
       "  0.34031134568452837,\n",
       "  0.36303920538425444,\n",
       "  0.3283116232872009,\n",
       "  0.3213602659165859,\n",
       "  0.318601215916872,\n",
       "  0.32371392475366595,\n",
       "  0.32781322520971296,\n",
       "  0.3082569923996925,\n",
       "  0.314211381059885,\n",
       "  0.3132270549416542,\n",
       "  0.31738317203521726,\n",
       "  0.29955972567796707,\n",
       "  0.2949870453596115,\n",
       "  0.31064029975235463,\n",
       "  0.3279365381896496,\n",
       "  0.3004607965558767,\n",
       "  0.3077434210807085,\n",
       "  0.2972915891468525,\n",
       "  0.2993949495911598,\n",
       "  0.2869762137651444],\n",
       " 'val_accuracy': [0.8282,\n",
       "  0.8312,\n",
       "  0.8482,\n",
       "  0.8656,\n",
       "  0.8644,\n",
       "  0.8616,\n",
       "  0.8758,\n",
       "  0.8714,\n",
       "  0.877,\n",
       "  0.8798,\n",
       "  0.88,\n",
       "  0.872,\n",
       "  0.8876,\n",
       "  0.8834,\n",
       "  0.888,\n",
       "  0.8836,\n",
       "  0.8832,\n",
       "  0.891,\n",
       "  0.8908,\n",
       "  0.8906,\n",
       "  0.8854,\n",
       "  0.8934,\n",
       "  0.8936,\n",
       "  0.887,\n",
       "  0.8834,\n",
       "  0.8922,\n",
       "  0.886,\n",
       "  0.896,\n",
       "  0.8928,\n",
       "  0.8926]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the learning curves\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5)) \n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1] plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may be a little bit of overfitting. Not much they seem close to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss seems to be going down in the validation set. So, we could train further.\n",
    "#It’s as simple as calling the fit() method again, since Keras just continues train‐ ing where it left off "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 2s 44us/sample - loss: 0.2247 - accuracy: 0.9193 - val_loss: 0.3005 - val_accuracy: 0.8960\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 2s 44us/sample - loss: 0.2216 - accuracy: 0.9206 - val_loss: 0.2926 - val_accuracy: 0.8930\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 2s 42us/sample - loss: 0.2171 - accuracy: 0.9221 - val_loss: 0.2993 - val_accuracy: 0.8876\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 2s 43us/sample - loss: 0.2138 - accuracy: 0.9243 - val_loss: 0.2938 - val_accuracy: 0.8976\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 2s 43us/sample - loss: 0.2100 - accuracy: 0.9244 - val_loss: 0.2995 - val_accuracy: 0.8974\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5, \n",
    "                    validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 31us/sample - loss: 70.7952 - accuracy: 0.8477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[70.79522146884202, 0.8477]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the test set\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine tuning the model for network hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]): \n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "    \n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", **options))\n",
    "  \n",
    "    \n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate) \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,metrics=[\"accuracy\"]) \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_classifier = keras.wrappers.scikit_learn.KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Random search CV to find the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 1.2052 - accuracy: 0.6048 - val_loss: 0.7269 - val_accuracy: 0.7526\n",
      "Epoch 2/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6529 - accuracy: 0.7723 - val_loss: 0.5751 - val_accuracy: 0.8024\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5594 - accuracy: 0.8063 - val_loss: 0.5189 - val_accuracy: 0.8266\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.5145 - accuracy: 0.8188 - val_loss: 0.4855 - val_accuracy: 0.8296\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4870 - accuracy: 0.8286 - val_loss: 0.4634 - val_accuracy: 0.8410\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4685 - accuracy: 0.8358 - val_loss: 0.4478 - val_accuracy: 0.8486\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.4535 - accuracy: 0.8406 - val_loss: 0.4326 - val_accuracy: 0.8536\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4396 - accuracy: 0.8459 - val_loss: 0.4425 - val_accuracy: 0.8488\n",
      "Epoch 9/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4283 - accuracy: 0.8504 - val_loss: 0.4785 - val_accuracy: 0.8266\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4182 - accuracy: 0.8536 - val_loss: 0.4134 - val_accuracy: 0.8578\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4101 - accuracy: 0.8574 - val_loss: 0.4000 - val_accuracy: 0.8616\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4010 - accuracy: 0.8604 - val_loss: 0.3976 - val_accuracy: 0.8620\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3943 - accuracy: 0.8633 - val_loss: 0.4000 - val_accuracy: 0.8628\n",
      "Epoch 14/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3861 - accuracy: 0.8661 - val_loss: 0.3943 - val_accuracy: 0.8640\n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3803 - accuracy: 0.8664 - val_loss: 0.3930 - val_accuracy: 0.8648\n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3731 - accuracy: 0.8686 - val_loss: 0.4013 - val_accuracy: 0.8566\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3691 - accuracy: 0.8718 - val_loss: 0.3769 - val_accuracy: 0.8652\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3640 - accuracy: 0.8727 - val_loss: 0.3694 - val_accuracy: 0.8706\n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3586 - accuracy: 0.8741 - val_loss: 0.3901 - val_accuracy: 0.8676\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3542 - accuracy: 0.8767 - val_loss: 0.3933 - val_accuracy: 0.8638\n",
      "Epoch 21/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3488 - accuracy: 0.8775 - val_loss: 0.3900 - val_accuracy: 0.8652\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3458 - accuracy: 0.8771 - val_loss: 0.3718 - val_accuracy: 0.8690\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3403 - accuracy: 0.8795 - val_loss: 0.3730 - val_accuracy: 0.8664\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3385 - accuracy: 0.8802 - val_loss: 0.3596 - val_accuracy: 0.8744\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3326 - accuracy: 0.8817 - val_loss: 0.3695 - val_accuracy: 0.8656\n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3299 - accuracy: 0.8835 - val_loss: 0.3580 - val_accuracy: 0.8694\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3264 - accuracy: 0.8836 - val_loss: 0.3617 - val_accuracy: 0.8728\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3228 - accuracy: 0.8853 - val_loss: 0.3551 - val_accuracy: 0.8754\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3197 - accuracy: 0.8870 - val_loss: 0.3534 - val_accuracy: 0.8776\n",
      "Epoch 30/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3167 - accuracy: 0.8876 - val_loss: 0.3616 - val_accuracy: 0.8706\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3130 - accuracy: 0.8882 - val_loss: 0.3498 - val_accuracy: 0.8776\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3099 - accuracy: 0.8888 - val_loss: 0.3595 - val_accuracy: 0.8748\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.3065 - accuracy: 0.8925 - val_loss: 0.3406 - val_accuracy: 0.8792\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3031 - accuracy: 0.8911 - val_loss: 0.3667 - val_accuracy: 0.8716\n",
      "Epoch 35/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3017 - accuracy: 0.8926 - val_loss: 0.3595 - val_accuracy: 0.8738\n",
      "Epoch 36/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2972 - accuracy: 0.8950 - val_loss: 0.3459 - val_accuracy: 0.8798\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2959 - accuracy: 0.8939 - val_loss: 0.3527 - val_accuracy: 0.8760\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.2926 - accuracy: 0.8962 - val_loss: 0.3450 - val_accuracy: 0.8742\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.2909 - accuracy: 0.8959 - val_loss: 0.3487 - val_accuracy: 0.8768\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2873 - accuracy: 0.8979 - val_loss: 0.3546 - val_accuracy: 0.8760\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.2849 - accuracy: 0.8982 - val_loss: 0.3532 - val_accuracy: 0.8748\n",
      "Epoch 42/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2843 - accuracy: 0.8986 - val_loss: 0.3482 - val_accuracy: 0.8784\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2805 - accuracy: 0.8999 - val_loss: 0.3465 - val_accuracy: 0.8786\n",
      "18334/18334 [==============================] - 0s 22us/sample - loss: 0.3519 - accuracy: 0.8718\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 1.2177 - accuracy: 0.5951 - val_loss: 0.7370 - val_accuracy: 0.7464\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6806 - accuracy: 0.7574 - val_loss: 0.6137 - val_accuracy: 0.7930\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5815 - accuracy: 0.7992 - val_loss: 0.5403 - val_accuracy: 0.8174\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5294 - accuracy: 0.8149 - val_loss: 0.4896 - val_accuracy: 0.8358\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4981 - accuracy: 0.8258 - val_loss: 0.4702 - val_accuracy: 0.8386\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4771 - accuracy: 0.8296 - val_loss: 0.4495 - val_accuracy: 0.8472\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4601 - accuracy: 0.8369 - val_loss: 0.4803 - val_accuracy: 0.8320\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4464 - accuracy: 0.8417 - val_loss: 0.4297 - val_accuracy: 0.8518\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4340 - accuracy: 0.8472 - val_loss: 0.4198 - val_accuracy: 0.8560\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4250 - accuracy: 0.8491 - val_loss: 0.4238 - val_accuracy: 0.8558\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4156 - accuracy: 0.8535 - val_loss: 0.4256 - val_accuracy: 0.8494\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4072 - accuracy: 0.8546 - val_loss: 0.4129 - val_accuracy: 0.8552\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4006 - accuracy: 0.8585 - val_loss: 0.3986 - val_accuracy: 0.8612\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3942 - accuracy: 0.8592 - val_loss: 0.3917 - val_accuracy: 0.8646\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3865 - accuracy: 0.8635 - val_loss: 0.3970 - val_accuracy: 0.8640\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3808 - accuracy: 0.8652 - val_loss: 0.3931 - val_accuracy: 0.8618\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3765 - accuracy: 0.8680 - val_loss: 0.4008 - val_accuracy: 0.8626\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3714 - accuracy: 0.8681 - val_loss: 0.3806 - val_accuracy: 0.8700\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3670 - accuracy: 0.8697 - val_loss: 0.3842 - val_accuracy: 0.8670\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3617 - accuracy: 0.8719 - val_loss: 0.3761 - val_accuracy: 0.8752\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3587 - accuracy: 0.8731 - val_loss: 0.3784 - val_accuracy: 0.8678\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3537 - accuracy: 0.8742 - val_loss: 0.3790 - val_accuracy: 0.8682\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3498 - accuracy: 0.8750 - val_loss: 0.3792 - val_accuracy: 0.8650\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3458 - accuracy: 0.8767 - val_loss: 0.3669 - val_accuracy: 0.8766\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3429 - accuracy: 0.8776 - val_loss: 0.3690 - val_accuracy: 0.8708\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3399 - accuracy: 0.8795 - val_loss: 0.3816 - val_accuracy: 0.8654\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3353 - accuracy: 0.8794 - val_loss: 0.3602 - val_accuracy: 0.8744\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3323 - accuracy: 0.8816 - val_loss: 0.3689 - val_accuracy: 0.8718\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3300 - accuracy: 0.8816 - val_loss: 0.3608 - val_accuracy: 0.8764\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3255 - accuracy: 0.8840 - val_loss: 0.3553 - val_accuracy: 0.8778\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3230 - accuracy: 0.8825 - val_loss: 0.3508 - val_accuracy: 0.8764\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3208 - accuracy: 0.8845 - val_loss: 0.3527 - val_accuracy: 0.8758\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3166 - accuracy: 0.8874 - val_loss: 0.3506 - val_accuracy: 0.8786\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3133 - accuracy: 0.8880 - val_loss: 0.3518 - val_accuracy: 0.8800\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3112 - accuracy: 0.8868 - val_loss: 0.3444 - val_accuracy: 0.8792\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3078 - accuracy: 0.8894 - val_loss: 0.3512 - val_accuracy: 0.8750\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3055 - accuracy: 0.8908 - val_loss: 0.3472 - val_accuracy: 0.8820\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3023 - accuracy: 0.8909 - val_loss: 0.3488 - val_accuracy: 0.8784\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3000 - accuracy: 0.8915 - val_loss: 0.3411 - val_accuracy: 0.8802\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2981 - accuracy: 0.8917 - val_loss: 0.3479 - val_accuracy: 0.8770\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2939 - accuracy: 0.8934 - val_loss: 0.3349 - val_accuracy: 0.8828\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2923 - accuracy: 0.8942 - val_loss: 0.3535 - val_accuracy: 0.8748\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2901 - accuracy: 0.8948 - val_loss: 0.3361 - val_accuracy: 0.8818\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2868 - accuracy: 0.8958 - val_loss: 0.3403 - val_accuracy: 0.8802\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2847 - accuracy: 0.8973 - val_loss: 0.3454 - val_accuracy: 0.8772\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2828 - accuracy: 0.8972 - val_loss: 0.3384 - val_accuracy: 0.8802\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2803 - accuracy: 0.8967 - val_loss: 0.3418 - val_accuracy: 0.8798\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2769 - accuracy: 0.8997 - val_loss: 0.3348 - val_accuracy: 0.8836\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2757 - accuracy: 0.8993 - val_loss: 0.3338 - val_accuracy: 0.8834\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2735 - accuracy: 0.9006 - val_loss: 0.3356 - val_accuracy: 0.8812\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2711 - accuracy: 0.9019 - val_loss: 0.3404 - val_accuracy: 0.8822\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2699 - accuracy: 0.9024 - val_loss: 0.3371 - val_accuracy: 0.8816\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2671 - accuracy: 0.9024 - val_loss: 0.3320 - val_accuracy: 0.8826\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2636 - accuracy: 0.9044 - val_loss: 0.3266 - val_accuracy: 0.8858\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2636 - accuracy: 0.9034 - val_loss: 0.3391 - val_accuracy: 0.8782\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2613 - accuracy: 0.9039 - val_loss: 0.3440 - val_accuracy: 0.8774\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2584 - accuracy: 0.9052 - val_loss: 0.3326 - val_accuracy: 0.8832\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2571 - accuracy: 0.9056 - val_loss: 0.3412 - val_accuracy: 0.8842\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2534 - accuracy: 0.9086 - val_loss: 0.3412 - val_accuracy: 0.8818\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2527 - accuracy: 0.9077 - val_loss: 0.3243 - val_accuracy: 0.8838\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2518 - accuracy: 0.9080 - val_loss: 0.3247 - val_accuracy: 0.8844\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2497 - accuracy: 0.9092 - val_loss: 0.3598 - val_accuracy: 0.8758\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2469 - accuracy: 0.9093 - val_loss: 0.3261 - val_accuracy: 0.8830\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2458 - accuracy: 0.9110 - val_loss: 0.3260 - val_accuracy: 0.8848\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2444 - accuracy: 0.9102 - val_loss: 0.3298 - val_accuracy: 0.8840\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2428 - accuracy: 0.9109 - val_loss: 0.3370 - val_accuracy: 0.8802\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2404 - accuracy: 0.9113 - val_loss: 0.3333 - val_accuracy: 0.8790\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2390 - accuracy: 0.9126 - val_loss: 0.3324 - val_accuracy: 0.8826\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2372 - accuracy: 0.9117 - val_loss: 0.3276 - val_accuracy: 0.8820\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2347 - accuracy: 0.9152 - val_loss: 0.3292 - val_accuracy: 0.8844\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 0.3428 - accuracy: 0.8831\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 1.2814 - accuracy: 0.5613 - val_loss: 0.7615 - val_accuracy: 0.7362\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6922 - accuracy: 0.7561 - val_loss: 0.6147 - val_accuracy: 0.7860\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5957 - accuracy: 0.7942 - val_loss: 0.5546 - val_accuracy: 0.8028\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5398 - accuracy: 0.8102 - val_loss: 0.5056 - val_accuracy: 0.8270\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5028 - accuracy: 0.8253 - val_loss: 0.4830 - val_accuracy: 0.8346\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4768 - accuracy: 0.8325 - val_loss: 0.4612 - val_accuracy: 0.8468\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4600 - accuracy: 0.8375 - val_loss: 0.4404 - val_accuracy: 0.8522\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4435 - accuracy: 0.8433 - val_loss: 0.4370 - val_accuracy: 0.8510\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4308 - accuracy: 0.8470 - val_loss: 0.4403 - val_accuracy: 0.8490\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4196 - accuracy: 0.8516 - val_loss: 0.4330 - val_accuracy: 0.8452\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4091 - accuracy: 0.8540 - val_loss: 0.4121 - val_accuracy: 0.8554\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4006 - accuracy: 0.8584 - val_loss: 0.4313 - val_accuracy: 0.8464\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3950 - accuracy: 0.8612 - val_loss: 0.4327 - val_accuracy: 0.8442\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3868 - accuracy: 0.8626 - val_loss: 0.3968 - val_accuracy: 0.8648\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3799 - accuracy: 0.8657 - val_loss: 0.3949 - val_accuracy: 0.8602\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3738 - accuracy: 0.8673 - val_loss: 0.3902 - val_accuracy: 0.8638\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3693 - accuracy: 0.8691 - val_loss: 0.3762 - val_accuracy: 0.8692\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3635 - accuracy: 0.8711 - val_loss: 0.4085 - val_accuracy: 0.8540\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3583 - accuracy: 0.8734 - val_loss: 0.3718 - val_accuracy: 0.8714\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3529 - accuracy: 0.8743 - val_loss: 0.3742 - val_accuracy: 0.8708\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3488 - accuracy: 0.8750 - val_loss: 0.3824 - val_accuracy: 0.8690\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3435 - accuracy: 0.8773 - val_loss: 0.3662 - val_accuracy: 0.8734\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3396 - accuracy: 0.8784 - val_loss: 0.3615 - val_accuracy: 0.8716\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3361 - accuracy: 0.8792 - val_loss: 0.3619 - val_accuracy: 0.8734\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3314 - accuracy: 0.8818 - val_loss: 0.3770 - val_accuracy: 0.8630\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3276 - accuracy: 0.8825 - val_loss: 0.3596 - val_accuracy: 0.8734\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3243 - accuracy: 0.8837 - val_loss: 0.3594 - val_accuracy: 0.8750\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3208 - accuracy: 0.8846 - val_loss: 0.3566 - val_accuracy: 0.8728\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3195 - accuracy: 0.8851 - val_loss: 0.3551 - val_accuracy: 0.8742\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3145 - accuracy: 0.8869 - val_loss: 0.3587 - val_accuracy: 0.8736\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3107 - accuracy: 0.8890 - val_loss: 0.3514 - val_accuracy: 0.8790\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3079 - accuracy: 0.8899 - val_loss: 0.3689 - val_accuracy: 0.8736\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3036 - accuracy: 0.8909 - val_loss: 0.3548 - val_accuracy: 0.8748\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3019 - accuracy: 0.8918 - val_loss: 0.3633 - val_accuracy: 0.8688\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2989 - accuracy: 0.8925 - val_loss: 0.3490 - val_accuracy: 0.8746\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2964 - accuracy: 0.8930 - val_loss: 0.3645 - val_accuracy: 0.8740\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2918 - accuracy: 0.8948 - val_loss: 0.3595 - val_accuracy: 0.8744\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2899 - accuracy: 0.8971 - val_loss: 0.3458 - val_accuracy: 0.8764\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2882 - accuracy: 0.8964 - val_loss: 0.3438 - val_accuracy: 0.8790\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2842 - accuracy: 0.8977 - val_loss: 0.3408 - val_accuracy: 0.8794\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2812 - accuracy: 0.8978 - val_loss: 0.3446 - val_accuracy: 0.8786\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2792 - accuracy: 0.9003 - val_loss: 0.3511 - val_accuracy: 0.8776\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2762 - accuracy: 0.9008 - val_loss: 0.3526 - val_accuracy: 0.8746\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2752 - accuracy: 0.9002 - val_loss: 0.3375 - val_accuracy: 0.8804\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2722 - accuracy: 0.9024 - val_loss: 0.3384 - val_accuracy: 0.8806\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2697 - accuracy: 0.9025 - val_loss: 0.3418 - val_accuracy: 0.8832\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2663 - accuracy: 0.9045 - val_loss: 0.3362 - val_accuracy: 0.8804\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.2656 - accuracy: 0.9032 - val_loss: 0.3385 - val_accuracy: 0.8810\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2618 - accuracy: 0.9052 - val_loss: 0.3352 - val_accuracy: 0.8822\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2609 - accuracy: 0.9066 - val_loss: 0.3429 - val_accuracy: 0.8788\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2579 - accuracy: 0.9060 - val_loss: 0.3383 - val_accuracy: 0.8798\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2554 - accuracy: 0.9080 - val_loss: 0.3316 - val_accuracy: 0.8824\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2538 - accuracy: 0.9070 - val_loss: 0.3385 - val_accuracy: 0.8796\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2525 - accuracy: 0.9078 - val_loss: 0.3360 - val_accuracy: 0.8832\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.2495 - accuracy: 0.9105 - val_loss: 0.3300 - val_accuracy: 0.8862\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2486 - accuracy: 0.9103 - val_loss: 0.3305 - val_accuracy: 0.8826\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2458 - accuracy: 0.9104 - val_loss: 0.3397 - val_accuracy: 0.8786\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2431 - accuracy: 0.9123 - val_loss: 0.3389 - val_accuracy: 0.8794\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2416 - accuracy: 0.9129 - val_loss: 0.3363 - val_accuracy: 0.8800\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2386 - accuracy: 0.9133 - val_loss: 0.3422 - val_accuracy: 0.8800\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2388 - accuracy: 0.9139 - val_loss: 0.3524 - val_accuracy: 0.8776\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2371 - accuracy: 0.9135 - val_loss: 0.3354 - val_accuracy: 0.8856\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2343 - accuracy: 0.9158 - val_loss: 0.3337 - val_accuracy: 0.8828\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2314 - accuracy: 0.9171 - val_loss: 0.3342 - val_accuracy: 0.8826\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2291 - accuracy: 0.9178 - val_loss: 0.3630 - val_accuracy: 0.8760\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.3726 - accuracy: 0.8712\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 1.0706 - accuracy: 0.6617 - val_loss: 0.7826 - val_accuracy: 0.7534\n",
      "Epoch 2/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.7272 - accuracy: 0.7664 - val_loss: 0.6705 - val_accuracy: 0.7946\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.6506 - accuracy: 0.7924 - val_loss: 0.6188 - val_accuracy: 0.8072\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.6091 - accuracy: 0.8054 - val_loss: 0.5936 - val_accuracy: 0.8124\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.5819 - accuracy: 0.8115 - val_loss: 0.5668 - val_accuracy: 0.8198\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5619 - accuracy: 0.8186 - val_loss: 0.5492 - val_accuracy: 0.8270\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5466 - accuracy: 0.8227 - val_loss: 0.5388 - val_accuracy: 0.8272\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.5340 - accuracy: 0.8255 - val_loss: 0.5250 - val_accuracy: 0.8336\n",
      "Epoch 9/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.5239 - accuracy: 0.8290 - val_loss: 0.5186 - val_accuracy: 0.8364\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5151 - accuracy: 0.8304 - val_loss: 0.5096 - val_accuracy: 0.8384\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.5080 - accuracy: 0.8327 - val_loss: 0.5025 - val_accuracy: 0.8366\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.5013 - accuracy: 0.8351 - val_loss: 0.4967 - val_accuracy: 0.8404\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4955 - accuracy: 0.8365 - val_loss: 0.4938 - val_accuracy: 0.8428\n",
      "Epoch 14/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4902 - accuracy: 0.8379 - val_loss: 0.4874 - val_accuracy: 0.8414\n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4856 - accuracy: 0.8388 - val_loss: 0.4845 - val_accuracy: 0.8446\n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4813 - accuracy: 0.8402 - val_loss: 0.4804 - val_accuracy: 0.8440: 0.4791 - accuracy: 0.84 - ETA: 0s - loss: 0.4802 - accuracy: 0.\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4775 - accuracy: 0.8412 - val_loss: 0.4758 - val_accuracy: 0.8476\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4739 - accuracy: 0.8426 - val_loss: 0.4762 - val_accuracy: 0.8476\n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4708 - accuracy: 0.8434 - val_loss: 0.4714 - val_accuracy: 0.8462\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4675 - accuracy: 0.8441 - val_loss: 0.4685 - val_accuracy: 0.8494\n",
      "Epoch 21/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4650 - accuracy: 0.8446 - val_loss: 0.4653 - val_accuracy: 0.8492\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4619 - accuracy: 0.8455 - val_loss: 0.4646 - val_accuracy: 0.8484\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4595 - accuracy: 0.8465 - val_loss: 0.4615 - val_accuracy: 0.8504\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4570 - accuracy: 0.8470 - val_loss: 0.4639 - val_accuracy: 0.8512\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4549 - accuracy: 0.8485 - val_loss: 0.4582 - val_accuracy: 0.8518\n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4527 - accuracy: 0.8487 - val_loss: 0.4573 - val_accuracy: 0.8508\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4512 - accuracy: 0.8490 - val_loss: 0.4540 - val_accuracy: 0.8530\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4489 - accuracy: 0.8503 - val_loss: 0.4537 - val_accuracy: 0.8522s - loss: 0.4\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4471 - accuracy: 0.8500 - val_loss: 0.4514 - val_accuracy: 0.8540\n",
      "Epoch 30/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4456 - accuracy: 0.8507 - val_loss: 0.4506 - val_accuracy: 0.8536\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4439 - accuracy: 0.8512 - val_loss: 0.4497 - val_accuracy: 0.8532\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4423 - accuracy: 0.8522 - val_loss: 0.4471 - val_accuracy: 0.8550\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4410 - accuracy: 0.8522 - val_loss: 0.4463 - val_accuracy: 0.8546\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4396 - accuracy: 0.8523 - val_loss: 0.4461 - val_accuracy: 0.8556\n",
      "Epoch 35/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4380 - accuracy: 0.8522 - val_loss: 0.4452 - val_accuracy: 0.8538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4367 - accuracy: 0.8533 - val_loss: 0.4432 - val_accuracy: 0.8552\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4354 - accuracy: 0.8535 - val_loss: 0.4434 - val_accuracy: 0.8550\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4340 - accuracy: 0.8537 - val_loss: 0.4424 - val_accuracy: 0.8554\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4329 - accuracy: 0.8543 - val_loss: 0.4408 - val_accuracy: 0.8548\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4318 - accuracy: 0.8549 - val_loss: 0.4409 - val_accuracy: 0.8538\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4308 - accuracy: 0.8552 - val_loss: 0.4393 - val_accuracy: 0.8550\n",
      "Epoch 42/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4299 - accuracy: 0.8554 - val_loss: 0.4392 - val_accuracy: 0.8560\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4287 - accuracy: 0.8561 - val_loss: 0.4373 - val_accuracy: 0.8562\n",
      "Epoch 44/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4273 - accuracy: 0.8557 - val_loss: 0.4397 - val_accuracy: 0.8542\n",
      "Epoch 45/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4268 - accuracy: 0.8556 - val_loss: 0.4354 - val_accuracy: 0.8548\n",
      "Epoch 46/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4258 - accuracy: 0.8568 - val_loss: 0.4357 - val_accuracy: 0.8560\n",
      "Epoch 47/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4248 - accuracy: 0.8564 - val_loss: 0.4371 - val_accuracy: 0.8566\n",
      "Epoch 48/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4240 - accuracy: 0.8570 - val_loss: 0.4352 - val_accuracy: 0.8562\n",
      "Epoch 49/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4234 - accuracy: 0.8574 - val_loss: 0.4343 - val_accuracy: 0.8566\n",
      "Epoch 50/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4224 - accuracy: 0.8583 - val_loss: 0.4377 - val_accuracy: 0.8560\n",
      "Epoch 51/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4215 - accuracy: 0.8573 - val_loss: 0.4336 - val_accuracy: 0.8576\n",
      "Epoch 52/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4206 - accuracy: 0.8585 - val_loss: 0.4326 - val_accuracy: 0.8566\n",
      "Epoch 53/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4201 - accuracy: 0.8580 - val_loss: 0.4318 - val_accuracy: 0.8574\n",
      "Epoch 54/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4191 - accuracy: 0.8591 - val_loss: 0.4308 - val_accuracy: 0.8576\n",
      "Epoch 55/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4184 - accuracy: 0.8597 - val_loss: 0.4311 - val_accuracy: 0.8582\n",
      "Epoch 56/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4178 - accuracy: 0.8592 - val_loss: 0.4294 - val_accuracy: 0.8564\n",
      "Epoch 57/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4171 - accuracy: 0.8596 - val_loss: 0.4303 - val_accuracy: 0.8586\n",
      "Epoch 58/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4164 - accuracy: 0.8588 - val_loss: 0.4310 - val_accuracy: 0.8574\n",
      "Epoch 59/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4157 - accuracy: 0.8599 - val_loss: 0.4295 - val_accuracy: 0.8582\n",
      "Epoch 60/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4148 - accuracy: 0.8599 - val_loss: 0.4291 - val_accuracy: 0.8590\n",
      "Epoch 61/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4142 - accuracy: 0.8600 - val_loss: 0.4273 - val_accuracy: 0.8584\n",
      "Epoch 62/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4136 - accuracy: 0.8598 - val_loss: 0.4279 - val_accuracy: 0.8592\n",
      "Epoch 63/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4132 - accuracy: 0.8606 - val_loss: 0.4273 - val_accuracy: 0.8604\n",
      "Epoch 64/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4125 - accuracy: 0.8608 - val_loss: 0.4291 - val_accuracy: 0.8582\n",
      "Epoch 65/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4119 - accuracy: 0.8612 - val_loss: 0.4287 - val_accuracy: 0.8580\n",
      "Epoch 66/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4114 - accuracy: 0.8609 - val_loss: 0.4250 - val_accuracy: 0.8586\n",
      "Epoch 67/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4106 - accuracy: 0.8615 - val_loss: 0.4261 - val_accuracy: 0.8582\n",
      "Epoch 68/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4101 - accuracy: 0.8603 - val_loss: 0.4266 - val_accuracy: 0.8598\n",
      "Epoch 69/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4099 - accuracy: 0.8628 - val_loss: 0.4271 - val_accuracy: 0.8600\n",
      "Epoch 70/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4090 - accuracy: 0.8625 - val_loss: 0.4254 - val_accuracy: 0.8578\n",
      "Epoch 71/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4087 - accuracy: 0.8622 - val_loss: 0.4243 - val_accuracy: 0.8592\n",
      "Epoch 72/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4081 - accuracy: 0.8625 - val_loss: 0.4226 - val_accuracy: 0.8600\n",
      "Epoch 73/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4076 - accuracy: 0.8626 - val_loss: 0.4247 - val_accuracy: 0.8594\n",
      "Epoch 74/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4072 - accuracy: 0.8619 - val_loss: 0.4262 - val_accuracy: 0.8596\n",
      "Epoch 75/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4066 - accuracy: 0.8631 - val_loss: 0.4239 - val_accuracy: 0.8576\n",
      "Epoch 76/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4063 - accuracy: 0.8628 - val_loss: 0.4237 - val_accuracy: 0.8608\n",
      "Epoch 77/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4059 - accuracy: 0.8631 - val_loss: 0.4235 - val_accuracy: 0.8594\n",
      "Epoch 78/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4053 - accuracy: 0.8640 - val_loss: 0.4241 - val_accuracy: 0.8614\n",
      "Epoch 79/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4046 - accuracy: 0.8629 - val_loss: 0.4229 - val_accuracy: 0.8580\n",
      "Epoch 80/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4045 - accuracy: 0.8632 - val_loss: 0.4217 - val_accuracy: 0.8600\n",
      "Epoch 81/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4035 - accuracy: 0.8632 - val_loss: 0.4265 - val_accuracy: 0.8580\n",
      "Epoch 82/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4034 - accuracy: 0.8639 - val_loss: 0.4220 - val_accuracy: 0.8588\n",
      "Epoch 83/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4029 - accuracy: 0.8643 - val_loss: 0.4220 - val_accuracy: 0.8598\n",
      "Epoch 84/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4026 - accuracy: 0.8637 - val_loss: 0.4215 - val_accuracy: 0.8600\n",
      "Epoch 85/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4020 - accuracy: 0.8639 - val_loss: 0.4229 - val_accuracy: 0.8610\n",
      "Epoch 86/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4016 - accuracy: 0.8651 - val_loss: 0.4220 - val_accuracy: 0.8598\n",
      "Epoch 87/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4013 - accuracy: 0.8639 - val_loss: 0.4208 - val_accuracy: 0.8606\n",
      "Epoch 88/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4009 - accuracy: 0.8645 - val_loss: 0.4200 - val_accuracy: 0.8608\n",
      "Epoch 89/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4006 - accuracy: 0.8649 - val_loss: 0.4222 - val_accuracy: 0.8612\n",
      "Epoch 90/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4002 - accuracy: 0.8657 - val_loss: 0.4232 - val_accuracy: 0.8610\n",
      "Epoch 91/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.3999 - accuracy: 0.8651 - val_loss: 0.4213 - val_accuracy: 0.8590\n",
      "Epoch 92/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.3993 - accuracy: 0.8654 - val_loss: 0.4196 - val_accuracy: 0.8598\n",
      "Epoch 93/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.3991 - accuracy: 0.8660 - val_loss: 0.4185 - val_accuracy: 0.8604\n",
      "Epoch 94/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.3987 - accuracy: 0.8651 - val_loss: 0.4190 - val_accuracy: 0.8596\n",
      "Epoch 95/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.3984 - accuracy: 0.8665 - val_loss: 0.4204 - val_accuracy: 0.8626\n",
      "Epoch 96/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.3981 - accuracy: 0.8661 - val_loss: 0.4193 - val_accuracy: 0.8592\n",
      "Epoch 97/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.3976 - accuracy: 0.8665 - val_loss: 0.4209 - val_accuracy: 0.8624\n",
      "Epoch 98/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.3972 - accuracy: 0.8661 - val_loss: 0.4226 - val_accuracy: 0.8618\n",
      "Epoch 99/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.3969 - accuracy: 0.8648 - val_loss: 0.4188 - val_accuracy: 0.8616\n",
      "Epoch 100/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.3966 - accuracy: 0.8657 - val_loss: 0.4187 - val_accuracy: 0.8614\n",
      "18334/18334 [==============================] - 0s 18us/sample - loss: 0.4319 - accuracy: 0.8484\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.0910 - accuracy: 0.6539 - val_loss: 0.7858 - val_accuracy: 0.7538\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.7354 - accuracy: 0.7622 - val_loss: 0.6703 - val_accuracy: 0.7888\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.6566 - accuracy: 0.7872 - val_loss: 0.6167 - val_accuracy: 0.8066\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.6134 - accuracy: 0.8004 - val_loss: 0.5894 - val_accuracy: 0.8132\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5857 - accuracy: 0.8089 - val_loss: 0.5665 - val_accuracy: 0.8210\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5651 - accuracy: 0.8156 - val_loss: 0.5472 - val_accuracy: 0.8276\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5496 - accuracy: 0.8173 - val_loss: 0.5358 - val_accuracy: 0.8282\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5371 - accuracy: 0.8220 - val_loss: 0.5231 - val_accuracy: 0.8332\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5269 - accuracy: 0.8247 - val_loss: 0.5143 - val_accuracy: 0.8338\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5178 - accuracy: 0.8271 - val_loss: 0.5084 - val_accuracy: 0.8348\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5104 - accuracy: 0.8289 - val_loss: 0.5009 - val_accuracy: 0.8382\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5040 - accuracy: 0.8307 - val_loss: 0.4958 - val_accuracy: 0.8408\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4980 - accuracy: 0.8323 - val_loss: 0.4938 - val_accuracy: 0.8384\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4928 - accuracy: 0.8336 - val_loss: 0.4879 - val_accuracy: 0.8382\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4880 - accuracy: 0.8343 - val_loss: 0.4831 - val_accuracy: 0.8404\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4840 - accuracy: 0.8354 - val_loss: 0.4791 - val_accuracy: 0.8432\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4801 - accuracy: 0.8375 - val_loss: 0.4760 - val_accuracy: 0.8448\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4765 - accuracy: 0.8380 - val_loss: 0.4750 - val_accuracy: 0.8434\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4732 - accuracy: 0.8393 - val_loss: 0.4705 - val_accuracy: 0.8450\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4702 - accuracy: 0.8402 - val_loss: 0.4697 - val_accuracy: 0.8472\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4675 - accuracy: 0.8414 - val_loss: 0.4651 - val_accuracy: 0.8460\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4646 - accuracy: 0.8417 - val_loss: 0.4635 - val_accuracy: 0.8484\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4622 - accuracy: 0.8434 - val_loss: 0.4618 - val_accuracy: 0.8486\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4599 - accuracy: 0.8435 - val_loss: 0.4624 - val_accuracy: 0.8482\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4576 - accuracy: 0.8444 - val_loss: 0.4596 - val_accuracy: 0.8488\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4556 - accuracy: 0.8453 - val_loss: 0.4575 - val_accuracy: 0.8490\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4535 - accuracy: 0.8454 - val_loss: 0.4544 - val_accuracy: 0.8504\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4514 - accuracy: 0.8468 - val_loss: 0.4548 - val_accuracy: 0.8486\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4498 - accuracy: 0.8459 - val_loss: 0.4575 - val_accuracy: 0.8508\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4484 - accuracy: 0.8473 - val_loss: 0.4515 - val_accuracy: 0.8490s - loss: 0.4455 - accuracy: 0.\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4469 - accuracy: 0.8469 - val_loss: 0.4498 - val_accuracy: 0.8502\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4449 - accuracy: 0.8485 - val_loss: 0.4498 - val_accuracy: 0.8512\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4436 - accuracy: 0.8486 - val_loss: 0.4478 - val_accuracy: 0.8510\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4424 - accuracy: 0.8485 - val_loss: 0.4460 - val_accuracy: 0.8530\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4407 - accuracy: 0.8502 - val_loss: 0.4462 - val_accuracy: 0.8492\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4396 - accuracy: 0.8496 - val_loss: 0.4438 - val_accuracy: 0.8518\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4382 - accuracy: 0.8502 - val_loss: 0.4443 - val_accuracy: 0.8524\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4372 - accuracy: 0.8506 - val_loss: 0.4423 - val_accuracy: 0.8528\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4358 - accuracy: 0.8510 - val_loss: 0.4415 - val_accuracy: 0.8520\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4347 - accuracy: 0.8515 - val_loss: 0.4411 - val_accuracy: 0.8524\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4338 - accuracy: 0.8520 - val_loss: 0.4403 - val_accuracy: 0.8534\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4325 - accuracy: 0.8525 - val_loss: 0.4412 - val_accuracy: 0.8540\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4318 - accuracy: 0.8525 - val_loss: 0.4381 - val_accuracy: 0.8532\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4306 - accuracy: 0.8527 - val_loss: 0.4377 - val_accuracy: 0.8528\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4296 - accuracy: 0.8524 - val_loss: 0.4372 - val_accuracy: 0.8534\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4287 - accuracy: 0.8528 - val_loss: 0.4362 - val_accuracy: 0.8530\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4276 - accuracy: 0.8539 - val_loss: 0.4354 - val_accuracy: 0.8542\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4269 - accuracy: 0.8538 - val_loss: 0.4355 - val_accuracy: 0.8540\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4260 - accuracy: 0.8541 - val_loss: 0.4364 - val_accuracy: 0.8558\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4253 - accuracy: 0.8543 - val_loss: 0.4346 - val_accuracy: 0.8538\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4246 - accuracy: 0.8545 - val_loss: 0.4341 - val_accuracy: 0.8522\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4236 - accuracy: 0.8553 - val_loss: 0.4327 - val_accuracy: 0.8540\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4231 - accuracy: 0.8551 - val_loss: 0.4327 - val_accuracy: 0.8544\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4224 - accuracy: 0.8552 - val_loss: 0.4316 - val_accuracy: 0.8540\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4214 - accuracy: 0.8558 - val_loss: 0.4322 - val_accuracy: 0.8550\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4207 - accuracy: 0.8558 - val_loss: 0.4335 - val_accuracy: 0.8560\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4200 - accuracy: 0.8552 - val_loss: 0.4307 - val_accuracy: 0.8528\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4194 - accuracy: 0.8562 - val_loss: 0.4306 - val_accuracy: 0.8536\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4187 - accuracy: 0.8562 - val_loss: 0.4333 - val_accuracy: 0.8524\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4179 - accuracy: 0.8570 - val_loss: 0.4294 - val_accuracy: 0.8554\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4173 - accuracy: 0.8567 - val_loss: 0.4299 - val_accuracy: 0.8554\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4168 - accuracy: 0.8565 - val_loss: 0.4280 - val_accuracy: 0.8528\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4160 - accuracy: 0.8578 - val_loss: 0.4280 - val_accuracy: 0.8540\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4155 - accuracy: 0.8569 - val_loss: 0.4274 - val_accuracy: 0.8554\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4148 - accuracy: 0.8578 - val_loss: 0.4344 - val_accuracy: 0.8532\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4147 - accuracy: 0.8580 - val_loss: 0.4303 - val_accuracy: 0.8568\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4139 - accuracy: 0.8575 - val_loss: 0.4300 - val_accuracy: 0.8536\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4134 - accuracy: 0.8573 - val_loss: 0.4280 - val_accuracy: 0.8556\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4127 - accuracy: 0.8577 - val_loss: 0.4264 - val_accuracy: 0.8556\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4121 - accuracy: 0.8589 - val_loss: 0.4267 - val_accuracy: 0.8546\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4117 - accuracy: 0.8587 - val_loss: 0.4283 - val_accuracy: 0.8562\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4109 - accuracy: 0.8596 - val_loss: 0.4265 - val_accuracy: 0.8542\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4108 - accuracy: 0.8588 - val_loss: 0.4250 - val_accuracy: 0.8544\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4101 - accuracy: 0.8581 - val_loss: 0.4259 - val_accuracy: 0.8582\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4097 - accuracy: 0.8588 - val_loss: 0.4244 - val_accuracy: 0.8562\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4091 - accuracy: 0.8592 - val_loss: 0.4243 - val_accuracy: 0.8566\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4087 - accuracy: 0.8597 - val_loss: 0.4267 - val_accuracy: 0.8550\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4085 - accuracy: 0.8587 - val_loss: 0.4240 - val_accuracy: 0.8564\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4076 - accuracy: 0.8600 - val_loss: 0.4254 - val_accuracy: 0.8546\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4076 - accuracy: 0.8589 - val_loss: 0.4235 - val_accuracy: 0.8552\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4069 - accuracy: 0.8599 - val_loss: 0.4233 - val_accuracy: 0.8568\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4066 - accuracy: 0.8597 - val_loss: 0.4240 - val_accuracy: 0.8570\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4062 - accuracy: 0.8598 - val_loss: 0.4231 - val_accuracy: 0.8564\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4058 - accuracy: 0.8598 - val_loss: 0.4218 - val_accuracy: 0.8558\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4054 - accuracy: 0.8599 - val_loss: 0.4223 - val_accuracy: 0.8556\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4049 - accuracy: 0.8596 - val_loss: 0.4221 - val_accuracy: 0.8568\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4045 - accuracy: 0.8607 - val_loss: 0.4227 - val_accuracy: 0.8558\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4041 - accuracy: 0.8609 - val_loss: 0.4227 - val_accuracy: 0.8576\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4039 - accuracy: 0.8610 - val_loss: 0.4204 - val_accuracy: 0.8560\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4033 - accuracy: 0.8609 - val_loss: 0.4236 - val_accuracy: 0.8568\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4033 - accuracy: 0.8607 - val_loss: 0.4210 - val_accuracy: 0.8550\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4027 - accuracy: 0.8614 - val_loss: 0.4213 - val_accuracy: 0.8568: 0.4026 \n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4019 - accuracy: 0.8608 - val_loss: 0.4216 - val_accuracy: 0.8566\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4018 - accuracy: 0.8616 - val_loss: 0.4221 - val_accuracy: 0.8562\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4017 - accuracy: 0.8613 - val_loss: 0.4201 - val_accuracy: 0.8570\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4011 - accuracy: 0.8618 - val_loss: 0.4215 - val_accuracy: 0.8570\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4010 - accuracy: 0.8624 - val_loss: 0.4205 - val_accuracy: 0.8568\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4004 - accuracy: 0.8616 - val_loss: 0.4195 - val_accuracy: 0.8576\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4001 - accuracy: 0.8625 - val_loss: 0.4200 - val_accuracy: 0.8556\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.3999 - accuracy: 0.8621 - val_loss: 0.4203 - val_accuracy: 0.8558\n",
      "18333/18333 [==============================] - 0s 18us/sample - loss: 0.4237 - accuracy: 0.8571\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0584 - accuracy: 0.6839 - val_loss: 0.7722 - val_accuracy: 0.7680\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.7256 - accuracy: 0.7722 - val_loss: 0.6664 - val_accuracy: 0.7956\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.6508 - accuracy: 0.7932 - val_loss: 0.6145 - val_accuracy: 0.8056\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.6092 - accuracy: 0.8054 - val_loss: 0.5854 - val_accuracy: 0.8096\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5823 - accuracy: 0.8113 - val_loss: 0.5618 - val_accuracy: 0.8210\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5626 - accuracy: 0.8163 - val_loss: 0.5468 - val_accuracy: 0.8258\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5473 - accuracy: 0.8205 - val_loss: 0.5373 - val_accuracy: 0.8310\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5349 - accuracy: 0.8242 - val_loss: 0.5227 - val_accuracy: 0.8326\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5247 - accuracy: 0.8267 - val_loss: 0.5159 - val_accuracy: 0.8318\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5164 - accuracy: 0.8302 - val_loss: 0.5081 - val_accuracy: 0.8378\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5087 - accuracy: 0.8313 - val_loss: 0.5018 - val_accuracy: 0.8380\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5022 - accuracy: 0.8329 - val_loss: 0.4957 - val_accuracy: 0.8404\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4965 - accuracy: 0.8344 - val_loss: 0.4909 - val_accuracy: 0.8432\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4914 - accuracy: 0.8368 - val_loss: 0.4891 - val_accuracy: 0.8416\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4870 - accuracy: 0.8377 - val_loss: 0.4849 - val_accuracy: 0.8434\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4825 - accuracy: 0.8393 - val_loss: 0.4788 - val_accuracy: 0.8438\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4787 - accuracy: 0.8402 - val_loss: 0.4797 - val_accuracy: 0.8418\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4751 - accuracy: 0.8414 - val_loss: 0.4760 - val_accuracy: 0.8430\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4719 - accuracy: 0.8420 - val_loss: 0.4723 - val_accuracy: 0.8418\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4688 - accuracy: 0.8423 - val_loss: 0.4705 - val_accuracy: 0.8444\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4662 - accuracy: 0.8435 - val_loss: 0.4697 - val_accuracy: 0.8464\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4634 - accuracy: 0.8445 - val_loss: 0.4650 - val_accuracy: 0.8472\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4611 - accuracy: 0.8455 - val_loss: 0.4633 - val_accuracy: 0.8458\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4585 - accuracy: 0.8460 - val_loss: 0.4639 - val_accuracy: 0.8476\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4565 - accuracy: 0.8460 - val_loss: 0.4585 - val_accuracy: 0.8486\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4546 - accuracy: 0.8473 - val_loss: 0.4564 - val_accuracy: 0.8500\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4525 - accuracy: 0.8471 - val_loss: 0.4552 - val_accuracy: 0.8494\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4506 - accuracy: 0.8483 - val_loss: 0.4532 - val_accuracy: 0.8520\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4486 - accuracy: 0.8490 - val_loss: 0.4532 - val_accuracy: 0.8522\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4472 - accuracy: 0.8481 - val_loss: 0.4509 - val_accuracy: 0.8524\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4457 - accuracy: 0.8495 - val_loss: 0.4498 - val_accuracy: 0.8514\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4440 - accuracy: 0.8505 - val_loss: 0.4503 - val_accuracy: 0.8502\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4427 - accuracy: 0.8501 - val_loss: 0.4495 - val_accuracy: 0.8534\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4410 - accuracy: 0.8498 - val_loss: 0.4492 - val_accuracy: 0.8524\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4399 - accuracy: 0.8509 - val_loss: 0.4454 - val_accuracy: 0.8522\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4385 - accuracy: 0.8509 - val_loss: 0.4453 - val_accuracy: 0.8528\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4371 - accuracy: 0.8520 - val_loss: 0.4461 - val_accuracy: 0.8530\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4362 - accuracy: 0.8507 - val_loss: 0.4439 - val_accuracy: 0.8548\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4349 - accuracy: 0.8518 - val_loss: 0.4428 - val_accuracy: 0.8538\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4338 - accuracy: 0.8533 - val_loss: 0.4423 - val_accuracy: 0.8554\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4329 - accuracy: 0.8525 - val_loss: 0.4411 - val_accuracy: 0.8532\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4315 - accuracy: 0.8529 - val_loss: 0.4416 - val_accuracy: 0.8534\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4305 - accuracy: 0.8546 - val_loss: 0.4406 - val_accuracy: 0.8544\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4298 - accuracy: 0.8535 - val_loss: 0.4395 - val_accuracy: 0.8546\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4288 - accuracy: 0.8538 - val_loss: 0.4379 - val_accuracy: 0.8554\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4279 - accuracy: 0.8547 - val_loss: 0.4372 - val_accuracy: 0.8536\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4270 - accuracy: 0.8534 - val_loss: 0.4397 - val_accuracy: 0.8548\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4258 - accuracy: 0.8541 - val_loss: 0.4382 - val_accuracy: 0.8538\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4251 - accuracy: 0.8552 - val_loss: 0.4388 - val_accuracy: 0.8542\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4244 - accuracy: 0.8551 - val_loss: 0.4367 - val_accuracy: 0.8534\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4237 - accuracy: 0.8552 - val_loss: 0.4339 - val_accuracy: 0.8552\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4229 - accuracy: 0.8553 - val_loss: 0.4332 - val_accuracy: 0.8576\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4220 - accuracy: 0.8561 - val_loss: 0.4334 - val_accuracy: 0.8568\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4211 - accuracy: 0.8559 - val_loss: 0.4331 - val_accuracy: 0.8570\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4206 - accuracy: 0.8563 - val_loss: 0.4324 - val_accuracy: 0.8566\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4199 - accuracy: 0.8566 - val_loss: 0.4316 - val_accuracy: 0.8568\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4190 - accuracy: 0.8562 - val_loss: 0.4308 - val_accuracy: 0.8576\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4182 - accuracy: 0.8574 - val_loss: 0.4314 - val_accuracy: 0.8564\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4179 - accuracy: 0.8578 - val_loss: 0.4325 - val_accuracy: 0.8558\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4172 - accuracy: 0.8575 - val_loss: 0.4338 - val_accuracy: 0.8556\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4166 - accuracy: 0.8577 - val_loss: 0.4302 - val_accuracy: 0.8570\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4162 - accuracy: 0.8579 - val_loss: 0.4308 - val_accuracy: 0.8560\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4154 - accuracy: 0.8582 - val_loss: 0.4294 - val_accuracy: 0.8586\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4146 - accuracy: 0.8581 - val_loss: 0.4308 - val_accuracy: 0.8546\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4142 - accuracy: 0.8588 - val_loss: 0.4294 - val_accuracy: 0.8564\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4137 - accuracy: 0.8588 - val_loss: 0.4293 - val_accuracy: 0.8576\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4132 - accuracy: 0.8592 - val_loss: 0.4281 - val_accuracy: 0.8570s - loss: 0.4133 - accuracy: 0.85\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4126 - accuracy: 0.8590 - val_loss: 0.4271 - val_accuracy: 0.8580\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4121 - accuracy: 0.8583 - val_loss: 0.4279 - val_accuracy: 0.8564\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4115 - accuracy: 0.8589 - val_loss: 0.4276 - val_accuracy: 0.8550\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4109 - accuracy: 0.8598 - val_loss: 0.4268 - val_accuracy: 0.8570s - loss: 0.4107 - accu\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4105 - accuracy: 0.8596 - val_loss: 0.4305 - val_accuracy: 0.8556\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4100 - accuracy: 0.8606 - val_loss: 0.4272 - val_accuracy: 0.8562\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4097 - accuracy: 0.8599 - val_loss: 0.4261 - val_accuracy: 0.8564 - accuracy - ETA: 0s - loss: 0.4106 - accuracy: 0.\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4089 - accuracy: 0.8601 - val_loss: 0.4298 - val_accuracy: 0.8560\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4087 - accuracy: 0.8601 - val_loss: 0.4252 - val_accuracy: 0.8564\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4079 - accuracy: 0.8610 - val_loss: 0.4279 - val_accuracy: 0.8558\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4077 - accuracy: 0.8602 - val_loss: 0.4247 - val_accuracy: 0.8582\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4073 - accuracy: 0.8613 - val_loss: 0.4261 - val_accuracy: 0.8552ss: 0.4065 - accuracy: 0. - ETA: 0s - loss: 0.4095 - ac\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4069 - accuracy: 0.8607 - val_loss: 0.4261 - val_accuracy: 0.8542\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4063 - accuracy: 0.8607 - val_loss: 0.4245 - val_accuracy: 0.8572\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4058 - accuracy: 0.8616 - val_loss: 0.4239 - val_accuracy: 0.8586\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4056 - accuracy: 0.8611 - val_loss: 0.4256 - val_accuracy: 0.8572\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4050 - accuracy: 0.8617 - val_loss: 0.4238 - val_accuracy: 0.8580\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4047 - accuracy: 0.8611 - val_loss: 0.4231 - val_accuracy: 0.8586\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4045 - accuracy: 0.8618 - val_loss: 0.4222 - val_accuracy: 0.8582\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4036 - accuracy: 0.8619 - val_loss: 0.4258 - val_accuracy: 0.8574\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4036 - accuracy: 0.8618 - val_loss: 0.4224 - val_accuracy: 0.8568\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4031 - accuracy: 0.8621 - val_loss: 0.4234 - val_accuracy: 0.8576\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4030 - accuracy: 0.8619 - val_loss: 0.4239 - val_accuracy: 0.8592\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4021 - accuracy: 0.8622 - val_loss: 0.4232 - val_accuracy: 0.8562\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4020 - accuracy: 0.8619 - val_loss: 0.4255 - val_accuracy: 0.8576\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4018 - accuracy: 0.8627 - val_loss: 0.4240 - val_accuracy: 0.8576\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4014 - accuracy: 0.8627 - val_loss: 0.4228 - val_accuracy: 0.8560\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4011 - accuracy: 0.8625 - val_loss: 0.4216 - val_accuracy: 0.8602\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4007 - accuracy: 0.8625 - val_loss: 0.4232 - val_accuracy: 0.8580\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4005 - accuracy: 0.8629 - val_loss: 0.4232 - val_accuracy: 0.8568\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4000 - accuracy: 0.8632 - val_loss: 0.4219 - val_accuracy: 0.8590\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.3995 - accuracy: 0.8632 - val_loss: 0.4220 - val_accuracy: 0.8576\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.3992 - accuracy: 0.8630 - val_loss: 0.4230 - val_accuracy: 0.8588 accura\n",
      "18333/18333 [==============================] - 0s 18us/sample - loss: 0.4275 - accuracy: 0.8534\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.4829 - accuracy: 0.5328 - val_loss: 1.0261 - val_accuracy: 0.6790\n",
      "Epoch 2/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.8958 - accuracy: 0.7158 - val_loss: 0.7925 - val_accuracy: 0.7472\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.7485 - accuracy: 0.7621 - val_loss: 0.6970 - val_accuracy: 0.7724\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.6751 - accuracy: 0.7833 - val_loss: 0.6419 - val_accuracy: 0.7892\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.6283 - accuracy: 0.7981 - val_loss: 0.6027 - val_accuracy: 0.8068\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5952 - accuracy: 0.8073 - val_loss: 0.5758 - val_accuracy: 0.8152\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5709 - accuracy: 0.8141 - val_loss: 0.5558 - val_accuracy: 0.8222\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5518 - accuracy: 0.8188 - val_loss: 0.5378 - val_accuracy: 0.8232\n",
      "Epoch 9/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5365 - accuracy: 0.8225 - val_loss: 0.5284 - val_accuracy: 0.8248\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5238 - accuracy: 0.8257 - val_loss: 0.5130 - val_accuracy: 0.8302\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5128 - accuracy: 0.8280 - val_loss: 0.5037 - val_accuracy: 0.8348\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5035 - accuracy: 0.8309 - val_loss: 0.4996 - val_accuracy: 0.8310\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4957 - accuracy: 0.8331 - val_loss: 0.4879 - val_accuracy: 0.8380\n",
      "Epoch 14/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4881 - accuracy: 0.8364 - val_loss: 0.4820 - val_accuracy: 0.8382: 0.4862 \n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4817 - accuracy: 0.8366 - val_loss: 0.4781 - val_accuracy: 0.84184872 \n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4758 - accuracy: 0.8395 - val_loss: 0.4718 - val_accuracy: 0.8436\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4707 - accuracy: 0.8400 - val_loss: 0.4690 - val_accuracy: 0.8448\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4658 - accuracy: 0.8421 - val_loss: 0.4648 - val_accuracy: 0.8466- loss: 0.4613 - accura\n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4612 - accuracy: 0.8438 - val_loss: 0.4591 - val_accuracy: 0.8492\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4571 - accuracy: 0.8445 - val_loss: 0.4556 - val_accuracy: 0.8500\n",
      "Epoch 21/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4530 - accuracy: 0.8456 - val_loss: 0.4534 - val_accuracy: 0.8512\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4492 - accuracy: 0.8468 - val_loss: 0.4481 - val_accuracy: 0.8534\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4460 - accuracy: 0.8474 - val_loss: 0.4457 - val_accuracy: 0.8528\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4425 - accuracy: 0.8498 - val_loss: 0.4473 - val_accuracy: 0.8516\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4396 - accuracy: 0.8496 - val_loss: 0.4436 - val_accuracy: 0.8534- loss: 0.4406 - accura - ETA: 0s - loss: 0.4385 - \n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4365 - accuracy: 0.8503 - val_loss: 0.4396 - val_accuracy: 0.8558\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4338 - accuracy: 0.8531 - val_loss: 0.4366 - val_accuracy: 0.8574\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4309 - accuracy: 0.8533 - val_loss: 0.4411 - val_accuracy: 0.8548\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4282 - accuracy: 0.8546 - val_loss: 0.4327 - val_accuracy: 0.8590\n",
      "Epoch 30/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4256 - accuracy: 0.8559 - val_loss: 0.4311 - val_accuracy: 0.8592\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4229 - accuracy: 0.8555 - val_loss: 0.4269 - val_accuracy: 0.8596\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4208 - accuracy: 0.8563 - val_loss: 0.4293 - val_accuracy: 0.8592\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4189 - accuracy: 0.8561 - val_loss: 0.4240 - val_accuracy: 0.85820.4183 - accuracy: 0. - ETA: 0s - loss: 0.4170 - ac - ETA: 0s - loss: 0.4184 - accuracy: 0.\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4166 - accuracy: 0.8571 - val_loss: 0.4217 - val_accuracy: 0.8616\n",
      "Epoch 35/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4144 - accuracy: 0.8571 - val_loss: 0.4238 - val_accuracy: 0.8596\n",
      "Epoch 36/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4124 - accuracy: 0.8582 - val_loss: 0.4254 - val_accuracy: 0.8596\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4104 - accuracy: 0.8602 - val_loss: 0.4180 - val_accuracy: 0.8634\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4086 - accuracy: 0.8598 - val_loss: 0.4167 - val_accuracy: 0.8626\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4069 - accuracy: 0.8603 - val_loss: 0.4149 - val_accuracy: 0.8626\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4048 - accuracy: 0.8613 - val_loss: 0.4139 - val_accuracy: 0.8626\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4032 - accuracy: 0.8621 - val_loss: 0.4123 - val_accuracy: 0.8648\n",
      "Epoch 42/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4014 - accuracy: 0.8624 - val_loss: 0.4120 - val_accuracy: 0.8630- loss: 0.4018 - accuracy\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3999 - accuracy: 0.8627 - val_loss: 0.4097 - val_accuracy: 0.8638\n",
      "Epoch 44/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3985 - accuracy: 0.8632 - val_loss: 0.4090 - val_accuracy: 0.8654\n",
      "Epoch 45/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3968 - accuracy: 0.8640 - val_loss: 0.4085 - val_accuracy: 0.8638\n",
      "Epoch 46/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3950 - accuracy: 0.8650 - val_loss: 0.4066 - val_accuracy: 0.8662\n",
      "Epoch 47/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3937 - accuracy: 0.8647 - val_loss: 0.4145 - val_accuracy: 0.8616\n",
      "Epoch 48/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3919 - accuracy: 0.8651 - val_loss: 0.4044 - val_accuracy: 0.8650\n",
      "Epoch 49/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3905 - accuracy: 0.8659 - val_loss: 0.4025 - val_accuracy: 0.8656\n",
      "Epoch 50/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3887 - accuracy: 0.8660 - val_loss: 0.4038 - val_accuracy: 0.8636\n",
      "Epoch 51/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3876 - accuracy: 0.8668 - val_loss: 0.4058 - val_accuracy: 0.8640\n",
      "Epoch 52/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3863 - accuracy: 0.8670 - val_loss: 0.4017 - val_accuracy: 0.8656\n",
      "Epoch 53/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3851 - accuracy: 0.8679 - val_loss: 0.3989 - val_accuracy: 0.8682 0.86\n",
      "Epoch 54/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3840 - accuracy: 0.8669 - val_loss: 0.3995 - val_accuracy: 0.8652\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3824 - accuracy: 0.8683 - val_loss: 0.3981 - val_accuracy: 0.8650\n",
      "Epoch 56/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3808 - accuracy: 0.8688 - val_loss: 0.3997 - val_accuracy: 0.8656\n",
      "Epoch 57/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3799 - accuracy: 0.8676 - val_loss: 0.4022 - val_accuracy: 0.8660\n",
      "Epoch 58/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3787 - accuracy: 0.8699 - val_loss: 0.3980 - val_accuracy: 0.8666\n",
      "Epoch 59/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3773 - accuracy: 0.8713 - val_loss: 0.3952 - val_accuracy: 0.8662\n",
      "Epoch 60/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3759 - accuracy: 0.8702 - val_loss: 0.3943 - val_accuracy: 0.8660\n",
      "Epoch 61/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3750 - accuracy: 0.8705 - val_loss: 0.3940 - val_accuracy: 0.8676\n",
      "Epoch 62/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3737 - accuracy: 0.8717 - val_loss: 0.3940 - val_accuracy: 0.8698\n",
      "Epoch 63/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3728 - accuracy: 0.8717 - val_loss: 0.3936 - val_accuracy: 0.8662\n",
      "Epoch 64/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3716 - accuracy: 0.8732 - val_loss: 0.3916 - val_accuracy: 0.8682\n",
      "Epoch 65/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3704 - accuracy: 0.8726 - val_loss: 0.3898 - val_accuracy: 0.8684\n",
      "Epoch 66/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3694 - accuracy: 0.8735 - val_loss: 0.3899 - val_accuracy: 0.8684\n",
      "Epoch 67/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3683 - accuracy: 0.8743 - val_loss: 0.3885 - val_accuracy: 0.8680\n",
      "Epoch 68/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3674 - accuracy: 0.8737 - val_loss: 0.3881 - val_accuracy: 0.8670ss: 0.3651 - accuracy - ETA: 0s - loss: 0.3677 - accuracy: 0.87\n",
      "Epoch 69/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3664 - accuracy: 0.8742 - val_loss: 0.3869 - val_accuracy: 0.868462 - accuracy\n",
      "Epoch 70/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3656 - accuracy: 0.8749 - val_loss: 0.3860 - val_accuracy: 0.8688\n",
      "Epoch 71/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3639 - accuracy: 0.8752 - val_loss: 0.3900 - val_accuracy: 0.8646\n",
      "Epoch 72/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3632 - accuracy: 0.8754 - val_loss: 0.3835 - val_accuracy: 0.8698\n",
      "Epoch 73/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3621 - accuracy: 0.8753 - val_loss: 0.3851 - val_accuracy: 0.8710\n",
      "Epoch 74/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3610 - accuracy: 0.8756 - val_loss: 0.3873 - val_accuracy: 0.8694\n",
      "Epoch 75/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3602 - accuracy: 0.8765 - val_loss: 0.3829 - val_accuracy: 0.8720 ac\n",
      "Epoch 76/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3593 - accuracy: 0.8771 - val_loss: 0.3849 - val_accuracy: 0.8668\n",
      "Epoch 77/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3584 - accuracy: 0.8774 - val_loss: 0.3865 - val_accuracy: 0.8680\n",
      "Epoch 78/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3575 - accuracy: 0.8777 - val_loss: 0.3834 - val_accuracy: 0.8718\n",
      "Epoch 79/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3565 - accuracy: 0.8784 - val_loss: 0.3828 - val_accuracy: 0.8714\n",
      "Epoch 80/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3554 - accuracy: 0.8789 - val_loss: 0.3848 - val_accuracy: 0.8690\n",
      "Epoch 81/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3546 - accuracy: 0.8788 - val_loss: 0.3827 - val_accuracy: 0.870023 - accu\n",
      "Epoch 82/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3540 - accuracy: 0.8797 - val_loss: 0.3795 - val_accuracy: 0.8710\n",
      "Epoch 83/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3530 - accuracy: 0.8789 - val_loss: 0.3780 - val_accuracy: 0.8722\n",
      "Epoch 84/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3522 - accuracy: 0.8797 - val_loss: 0.3805 - val_accuracy: 0.8714s - loss: 0.3488 - accuracy:  - ETA: 0s - loss: 0.3547 - accuracy - ETA: 0s - loss: 0.3503 \n",
      "Epoch 85/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3512 - accuracy: 0.8798 - val_loss: 0.3798 - val_accuracy: 0.8688\n",
      "Epoch 86/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3501 - accuracy: 0.8804 - val_loss: 0.3786 - val_accuracy: 0.87260.3505 \n",
      "Epoch 87/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3494 - accuracy: 0.8810 - val_loss: 0.3767 - val_accuracy: 0.8730\n",
      "Epoch 88/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3487 - accuracy: 0.8813 - val_loss: 0.3799 - val_accuracy: 0.8716\n",
      "Epoch 89/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3479 - accuracy: 0.8812 - val_loss: 0.3775 - val_accuracy: 0.8706\n",
      "Epoch 90/100\n",
      "36666/36666 [==============================] - ETA: 0s - loss: 0.3465 - accuracy: 0.88 - 1s 36us/sample - loss: 0.3470 - accuracy: 0.8815 - val_loss: 0.3755 - val_accuracy: 0.8726\n",
      "Epoch 91/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3460 - accuracy: 0.8812 - val_loss: 0.3750 - val_accuracy: 0.8718\n",
      "Epoch 92/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3455 - accuracy: 0.8819 - val_loss: 0.3768 - val_accuracy: 0.8714 - accuracy: \n",
      "Epoch 93/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3441 - accuracy: 0.8819 - val_loss: 0.3793 - val_accuracy: 0.8714\n",
      "Epoch 94/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3437 - accuracy: 0.8826 - val_loss: 0.3754 - val_accuracy: 0.8726\n",
      "Epoch 95/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3425 - accuracy: 0.8831 - val_loss: 0.3732 - val_accuracy: 0.8726\n",
      "Epoch 96/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3419 - accuracy: 0.8827 - val_loss: 0.3782 - val_accuracy: 0.8728\n",
      "Epoch 97/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3412 - accuracy: 0.8834 - val_loss: 0.3748 - val_accuracy: 0.8700\n",
      "Epoch 98/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3407 - accuracy: 0.8838 - val_loss: 0.3735 - val_accuracy: 0.8728\n",
      "Epoch 99/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3400 - accuracy: 0.8837 - val_loss: 0.3742 - val_accuracy: 0.8738\n",
      "Epoch 100/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3388 - accuracy: 0.8841 - val_loss: 0.3729 - val_accuracy: 0.8738\n",
      "18334/18334 [==============================] - 0s 24us/sample - loss: 0.3880 - accuracy: 0.8618\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.4283 - accuracy: 0.5420 - val_loss: 0.9739 - val_accuracy: 0.6994\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.8620 - accuracy: 0.7222 - val_loss: 0.7628 - val_accuracy: 0.7538\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.7294 - accuracy: 0.7622 - val_loss: 0.6776 - val_accuracy: 0.7758- l\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6636 - accuracy: 0.7824 - val_loss: 0.6296 - val_accuracy: 0.7932uracy\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6211 - accuracy: 0.7938 - val_loss: 0.5960 - val_accuracy: 0.80246217 - accuracy: 0.79\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5913 - accuracy: 0.8026 - val_loss: 0.5678 - val_accuracy: 0.8102\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - ETA: 0s - loss: 0.5688 - accuracy: 0.80 - 1s 33us/sample - loss: 0.5686 - accuracy: 0.8088 - val_loss: 0.5514 - val_accuracy: 0.8170\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5509 - accuracy: 0.8138 - val_loss: 0.5352 - val_accuracy: 0.8232\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5365 - accuracy: 0.8179 - val_loss: 0.5224 - val_accuracy: 0.8270\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5246 - accuracy: 0.8210 - val_loss: 0.5122 - val_accuracy: 0.8322\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5145 - accuracy: 0.8242 - val_loss: 0.5030 - val_accuracy: 0.8332\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5059 - accuracy: 0.8260 - val_loss: 0.4943 - val_accuracy: 0.8366\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4982 - accuracy: 0.8287 - val_loss: 0.4902 - val_accuracy: 0.8356\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4914 - accuracy: 0.8289 - val_loss: 0.4834 - val_accuracy: 0.8404\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4855 - accuracy: 0.8315 - val_loss: 0.4777 - val_accuracy: 0.8408\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4799 - accuracy: 0.8333 - val_loss: 0.4760 - val_accuracy: 0.8388\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4747 - accuracy: 0.8354 - val_loss: 0.4681 - val_accuracy: 0.8438\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4701 - accuracy: 0.8367 - val_loss: 0.4652 - val_accuracy: 0.8432\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4660 - accuracy: 0.8382 - val_loss: 0.4621 - val_accuracy: 0.8456\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4622 - accuracy: 0.8400 - val_loss: 0.4569 - val_accuracy: 0.8484\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4583 - accuracy: 0.8406 - val_loss: 0.4549 - val_accuracy: 0.8480\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - ETA: 0s - loss: 0.4549 - accuracy: 0.84 - 1s 33us/sample - loss: 0.4546 - accuracy: 0.8421 - val_loss: 0.4508 - val_accuracy: 0.8500\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4518 - accuracy: 0.8427 - val_loss: 0.4489 - val_accuracy: 0.8490\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4487 - accuracy: 0.8431 - val_loss: 0.4469 - val_accuracy: 0.8498\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4456 - accuracy: 0.8443 - val_loss: 0.4435 - val_accuracy: 0.8532\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4433 - accuracy: 0.8448 - val_loss: 0.4484 - val_accuracy: 0.8472\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4408 - accuracy: 0.8460 - val_loss: 0.4389 - val_accuracy: 0.8528\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4381 - accuracy: 0.8462 - val_loss: 0.4380 - val_accuracy: 0.8528ss: 0.4369  - ETA: 0s - loss: 0.4396 - accuracy: 0.\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4358 - accuracy: 0.8469 - val_loss: 0.4359 - val_accuracy: 0.8544\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4332 - accuracy: 0.8481 - val_loss: 0.4344 - val_accuracy: 0.8514y: 0.84\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4308 - accuracy: 0.8493 - val_loss: 0.4317 - val_accuracy: 0.8542\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4290 - accuracy: 0.8493 - val_loss: 0.4315 - val_accuracy: 0.8528 - accu\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4267 - accuracy: 0.8499 - val_loss: 0.4298 - val_accuracy: 0.8526\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4246 - accuracy: 0.8509 - val_loss: 0.4279 - val_accuracy: 0.8550\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4230 - accuracy: 0.8521 - val_loss: 0.4259 - val_accuracy: 0.8554\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4210 - accuracy: 0.8526 - val_loss: 0.4236 - val_accuracy: 0.8576\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4194 - accuracy: 0.8539 - val_loss: 0.4249 - val_accuracy: 0.8546\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4172 - accuracy: 0.8546 - val_loss: 0.4211 - val_accuracy: 0.8556\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4157 - accuracy: 0.8550 - val_loss: 0.4200 - val_accuracy: 0.8550\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4136 - accuracy: 0.8549 - val_loss: 0.4195 - val_accuracy: 0.8552\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4120 - accuracy: 0.8557 - val_loss: 0.4178 - val_accuracy: 0.8578\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4105 - accuracy: 0.8566 - val_loss: 0.4166 - val_accuracy: 0.8580\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4091 - accuracy: 0.8578 - val_loss: 0.4153 - val_accuracy: 0.8594\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4073 - accuracy: 0.8576 - val_loss: 0.4132 - val_accuracy: 0.8582\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4057 - accuracy: 0.8573 - val_loss: 0.4141 - val_accuracy: 0.8590 - accu\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4047 - accuracy: 0.8578 - val_loss: 0.4126 - val_accuracy: 0.8570\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4031 - accuracy: 0.8586 - val_loss: 0.4120 - val_accuracy: 0.8596\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4016 - accuracy: 0.8594 - val_loss: 0.4106 - val_accuracy: 0.8620\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4000 - accuracy: 0.8597 - val_loss: 0.4135 - val_accuracy: 0.8576\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3987 - accuracy: 0.8601 - val_loss: 0.4073 - val_accuracy: 0.8594\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3974 - accuracy: 0.8609 - val_loss: 0.4094 - val_accuracy: 0.8626\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3959 - accuracy: 0.8612 - val_loss: 0.4088 - val_accuracy: 0.8604\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3950 - accuracy: 0.8622 - val_loss: 0.4060 - val_accuracy: 0.8586\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3936 - accuracy: 0.8619 - val_loss: 0.4113 - val_accuracy: 0.8588\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3930 - accuracy: 0.8618 - val_loss: 0.4042 - val_accuracy: 0.8626\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3914 - accuracy: 0.8620 - val_loss: 0.4043 - val_accuracy: 0.8584\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3903 - accuracy: 0.8627 - val_loss: 0.4041 - val_accuracy: 0.8630\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3892 - accuracy: 0.8629 - val_loss: 0.4041 - val_accuracy: 0.8574: 0.3901 - accu - ETA: 0s - loss: 0.3918 - accuracy: \n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3879 - accuracy: 0.8646 - val_loss: 0.4038 - val_accuracy: 0.8634\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3869 - accuracy: 0.8642 - val_loss: 0.3986 - val_accuracy: 0.8618ura\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3855 - accuracy: 0.8650 - val_loss: 0.4015 - val_accuracy: 0.8624\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3847 - accuracy: 0.8649 - val_loss: 0.3984 - val_accuracy: 0.8630\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3837 - accuracy: 0.8648 - val_loss: 0.3973 - val_accuracy: 0.8624\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3827 - accuracy: 0.8651 - val_loss: 0.3967 - val_accuracy: 0.8624\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3817 - accuracy: 0.8654 - val_loss: 0.3957 - val_accuracy: 0.8620\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3806 - accuracy: 0.8664 - val_loss: 0.3951 - val_accuracy: 0.8622\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3797 - accuracy: 0.8662 - val_loss: 0.3962 - val_accuracy: 0.8620- loss: 0.377 - ETA: 0s - loss: 0.3781 - accura\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3788 - accuracy: 0.8686 - val_loss: 0.3928 - val_accuracy: 0.8630- los\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3774 - accuracy: 0.8670 - val_loss: 0.3970 - val_accuracy: 0.8602\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3765 - accuracy: 0.8679 - val_loss: 0.3922 - val_accuracy: 0.8612\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3756 - accuracy: 0.8695 - val_loss: 0.3969 - val_accuracy: 0.8622\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3745 - accuracy: 0.8683 - val_loss: 0.3933 - val_accuracy: 0.8616\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3738 - accuracy: 0.8683 - val_loss: 0.3908 - val_accuracy: 0.8622\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3731 - accuracy: 0.8697 - val_loss: 0.3893 - val_accuracy: 0.8622\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3721 - accuracy: 0.8697 - val_loss: 0.3913 - val_accuracy: 0.8628\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3711 - accuracy: 0.8697 - val_loss: 0.3917 - val_accuracy: 0.8652ss: 0.3716 - accura\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3705 - accuracy: 0.8697 - val_loss: 0.3916 - val_accuracy: 0.8648\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3693 - accuracy: 0.8708 - val_loss: 0.3905 - val_accuracy: 0.8644\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3687 - accuracy: 0.8704 - val_loss: 0.3920 - val_accuracy: 0.8612\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3682 - accuracy: 0.8707 - val_loss: 0.3889 - val_accuracy: 0.8626\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3669 - accuracy: 0.8708 - val_loss: 0.3891 - val_accuracy: 0.8640\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3662 - accuracy: 0.8698 - val_loss: 0.3884 - val_accuracy: 0.8618\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3654 - accuracy: 0.8714 - val_loss: 0.3872 - val_accuracy: 0.8642\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3646 - accuracy: 0.8721 - val_loss: 0.3907 - val_accuracy: 0.8630\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3639 - accuracy: 0.8720 - val_loss: 0.3887 - val_accuracy: 0.8644 - \n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3629 - accuracy: 0.8724 - val_loss: 0.3843 - val_accuracy: 0.8630\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3624 - accuracy: 0.8734 - val_loss: 0.3868 - val_accuracy: 0.8648\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3616 - accuracy: 0.8733 - val_loss: 0.3856 - val_accuracy: 0.8656\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3606 - accuracy: 0.8746 - val_loss: 0.3878 - val_accuracy: 0.8624\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3602 - accuracy: 0.8731 - val_loss: 0.3859 - val_accuracy: 0.8646\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3590 - accuracy: 0.8734 - val_loss: 0.3838 - val_accuracy: 0.8654\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3585 - accuracy: 0.8750 - val_loss: 0.3856 - val_accuracy: 0.8642 \n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3584 - accuracy: 0.8747 - val_loss: 0.3839 - val_accuracy: 0.8646\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3571 - accuracy: 0.8739 - val_loss: 0.3884 - val_accuracy: 0.8656ss: 0.3576 - accura - ETA: 0s - loss: 0.3542 - accuracy\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3563 - accuracy: 0.8746 - val_loss: 0.3823 - val_accuracy: 0.8654\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3555 - accuracy: 0.8757 - val_loss: 0.3841 - val_accuracy: 0.8648\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3547 - accuracy: 0.8756 - val_loss: 0.3857 - val_accuracy: 0.8634: 0.3540 - accuracy: 0.87 - ETA: 0s - loss: 0.3540 - accuracy\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3543 - accuracy: 0.8759 - val_loss: 0.3817 - val_accuracy: 0.8666\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3535 - accuracy: 0.8765 - val_loss: 0.3834 - val_accuracy: 0.8650: 0.3538 - accuracy: 0.87\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3530 - accuracy: 0.8762 - val_loss: 0.3800 - val_accuracy: 0.8668\n",
      "18333/18333 [==============================] - 0s 20us/sample - loss: 0.3905 - accuracy: 0.8651\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.4015 - accuracy: 0.5900 - val_loss: 0.9679 - val_accuracy: 0.6964\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.8711 - accuracy: 0.7155 - val_loss: 0.7728 - val_accuracy: 0.7558\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.7395 - accuracy: 0.7571 - val_loss: 0.6869 - val_accuracy: 0.7786\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6720 - accuracy: 0.7780 - val_loss: 0.6377 - val_accuracy: 0.7942\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6289 - accuracy: 0.7921 - val_loss: 0.6046 - val_accuracy: 0.8068\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5984 - accuracy: 0.8028 - val_loss: 0.5789 - val_accuracy: 0.8126\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5753 - accuracy: 0.8088 - val_loss: 0.5590 - val_accuracy: 0.8230\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5572 - accuracy: 0.8135 - val_loss: 0.5428 - val_accuracy: 0.8244\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - ETA: 0s - loss: 0.5414 - accuracy: 0.8202 ETA: 0s - loss: 0 - 1s 33us/sample - loss: 0.5419 - accuracy: 0.8199 - val_loss: 0.5299 - val_accuracy: 0.8286\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5292 - accuracy: 0.8220 - val_loss: 0.5220 - val_accuracy: 0.82765298 - accuracy: 0.82\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5184 - accuracy: 0.8264 - val_loss: 0.5124 - val_accuracy: 0.8314\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5090 - accuracy: 0.8279 - val_loss: 0.5005 - val_accuracy: 0.8366\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5007 - accuracy: 0.8315 - val_loss: 0.4947 - val_accuracy: 0.8368\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4933 - accuracy: 0.8341 - val_loss: 0.4881 - val_accuracy: 0.8380\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4866 - accuracy: 0.8352 - val_loss: 0.4818 - val_accuracy: 0.8400\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4806 - accuracy: 0.8369 - val_loss: 0.4775 - val_accuracy: 0.8402\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4751 - accuracy: 0.8383 - val_loss: 0.4707 - val_accuracy: 0.8418\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4701 - accuracy: 0.8396 - val_loss: 0.4677 - val_accuracy: 0.8452\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4655 - accuracy: 0.8407 - val_loss: 0.4656 - val_accuracy: 0.8446\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4613 - accuracy: 0.8430 - val_loss: 0.4595 - val_accuracy: 0.845619 - accuracy: 0.\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4571 - accuracy: 0.8447 - val_loss: 0.4587 - val_accuracy: 0.8458\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4537 - accuracy: 0.8457 - val_loss: 0.4528 - val_accuracy: 0.8490\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4500 - accuracy: 0.8461 - val_loss: 0.4512 - val_accuracy: 0.8496\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4464 - accuracy: 0.8482 - val_loss: 0.4504 - val_accuracy: 0.85000.4461 - ac\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4434 - accuracy: 0.8481 - val_loss: 0.4467 - val_accuracy: 0.8500\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4403 - accuracy: 0.8490 - val_loss: 0.4428 - val_accuracy: 0.85144394 - accuracy: \n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4373 - accuracy: 0.8505 - val_loss: 0.4422 - val_accuracy: 0.8520\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4350 - accuracy: 0.8513 - val_loss: 0.4374 - val_accuracy: 0.8496\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4322 - accuracy: 0.8520 - val_loss: 0.4342 - val_accuracy: 0.8560\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4294 - accuracy: 0.8523 - val_loss: 0.4344 - val_accuracy: 0.8538\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4267 - accuracy: 0.8537 - val_loss: 0.4324 - val_accuracy: 0.85720.4318 -  - ETA: 0s - loss: 0.4271 - accuracy: \n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4247 - accuracy: 0.8541 - val_loss: 0.4306 - val_accuracy: 0.8564\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4224 - accuracy: 0.8546 - val_loss: 0.4270 - val_accuracy: 0.8590\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4204 - accuracy: 0.8552 - val_loss: 0.4255 - val_accuracy: 0.8586\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4183 - accuracy: 0.8572 - val_loss: 0.4241 - val_accuracy: 0.8590\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4157 - accuracy: 0.8569 - val_loss: 0.4228 - val_accuracy: 0.8570\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4136 - accuracy: 0.8578 - val_loss: 0.4326 - val_accuracy: 0.8542\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4123 - accuracy: 0.8585 - val_loss: 0.4228 - val_accuracy: 0.8590- loss: 0.4119 - accura\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4102 - accuracy: 0.8593 - val_loss: 0.4262 - val_accuracy: 0.8568\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4084 - accuracy: 0.8594 - val_loss: 0.4172 - val_accuracy: 0.8572\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4068 - accuracy: 0.8598 - val_loss: 0.4143 - val_accuracy: 0.8608\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4050 - accuracy: 0.8602 - val_loss: 0.4146 - val_accuracy: 0.8592\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4031 - accuracy: 0.8609 - val_loss: 0.4129 - val_accuracy: 0.8598.86\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4014 - accuracy: 0.8613 - val_loss: 0.4109 - val_accuracy: 0.8602\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4001 - accuracy: 0.8625 - val_loss: 0.4102 - val_accuracy: 0.8632\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.3981 - accuracy: 0.8627 - val_loss: 0.4105 - val_accuracy: 0.8638\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.3966 - accuracy: 0.8638 - val_loss: 0.4077 - val_accuracy: 0.8634\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3951 - accuracy: 0.8649 - val_loss: 0.4072 - val_accuracy: 0.8656\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3937 - accuracy: 0.8639 - val_loss: 0.4065 - val_accuracy: 0.8620\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.3920 - accuracy: 0.8649 - val_loss: 0.4046 - val_accuracy: 0.8626\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3911 - accuracy: 0.8642 - val_loss: 0.4034 - val_accuracy: 0.8646 - accuracy - ETA: 0s - loss: 0.3909 - accuracy\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3893 - accuracy: 0.8664 - val_loss: 0.4038 - val_accuracy: 0.8664l\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3882 - accuracy: 0.8665 - val_loss: 0.4029 - val_accuracy: 0.8634\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3866 - accuracy: 0.8678 - val_loss: 0.4005 - val_accuracy: 0.8648\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.3853 - accuracy: 0.8663 - val_loss: 0.4020 - val_accuracy: 0.8648\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.3837 - accuracy: 0.8678 - val_loss: 0.4001 - val_accuracy: 0.8660\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3824 - accuracy: 0.8681 - val_loss: 0.4006 - val_accuracy: 0.8636\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3813 - accuracy: 0.8680 - val_loss: 0.3980 - val_accuracy: 0.8662\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3802 - accuracy: 0.8680 - val_loss: 0.3999 - val_accuracy: 0.8660\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3787 - accuracy: 0.8697 - val_loss: 0.3977 - val_accuracy: 0.8668\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.3781 - accuracy: 0.8694 - val_loss: 0.3962 - val_accuracy: 0.8684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3764 - accuracy: 0.8693 - val_loss: 0.4042 - val_accuracy: 0.8648\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3755 - accuracy: 0.8704 - val_loss: 0.3939 - val_accuracy: 0.8682\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3741 - accuracy: 0.8710 - val_loss: 0.3959 - val_accuracy: 0.8668\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 3966s 108ms/sample - loss: 0.3729 - accuracy: 0.8715 - val_loss: 0.3967 - val_accuracy: 0.8686\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3722 - accuracy: 0.8714 - val_loss: 0.3951 - val_accuracy: 0.8678\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3711 - accuracy: 0.8713 - val_loss: 0.3922 - val_accuracy: 0.8678\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3701 - accuracy: 0.8728 - val_loss: 0.3919 - val_accuracy: 0.8664\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.3687 - accuracy: 0.8727 - val_loss: 0.3892 - val_accuracy: 0.8688\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.3678 - accuracy: 0.8721 - val_loss: 0.3913 - val_accuracy: 0.86783660 - accuracy: \n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.3669 - accuracy: 0.8723 - val_loss: 0.3926 - val_accuracy: 0.8704\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 3s 72us/sample - loss: 0.3660 - accuracy: 0.8732 - val_loss: 0.3894 - val_accuracy: 0.8692\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 5s 140us/sample - loss: 0.3649 - accuracy: 0.8734 - val_loss: 0.3890 - val_accuracy: 0.8700\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.3638 - accuracy: 0.8747 - val_loss: 0.3931 - val_accuracy: 0.8676\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 5s 140us/sample - loss: 0.3629 - accuracy: 0.8747 - val_loss: 0.3909 - val_accuracy: 0.8666\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.3617 - accuracy: 0.8750 - val_loss: 0.3861 - val_accuracy: 0.8688\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.3610 - accuracy: 0.8747 - val_loss: 0.3871 - val_accuracy: 0.8690\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.3597 - accuracy: 0.8758 - val_loss: 0.3852 - val_accuracy: 0.8696\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 5s 141us/sample - loss: 0.3592 - accuracy: 0.8760 - val_loss: 0.3862 - val_accuracy: 0.8708\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 5s 141us/sample - loss: 0.3582 - accuracy: 0.8758 - val_loss: 0.3852 - val_accuracy: 0.8668\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1027s 28ms/sample - loss: 0.3573 - accuracy: 0.8766 - val_loss: 0.3845 - val_accuracy: 0.8690\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 0.3565 - accuracy: 0.8764 - val_loss: 0.3864 - val_accuracy: 0.8694\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 2s 64us/sample - loss: 0.3554 - accuracy: 0.8776 - val_loss: 0.3842 - val_accuracy: 0.8720\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3548 - accuracy: 0.8778 - val_loss: 0.3808 - val_accuracy: 0.8702\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.3539 - accuracy: 0.8783 - val_loss: 0.3853 - val_accuracy: 0.8712\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.3528 - accuracy: 0.8770 - val_loss: 0.3809 - val_accuracy: 0.8718\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 2s 66us/sample - loss: 0.3522 - accuracy: 0.8786 - val_loss: 0.3843 - val_accuracy: 0.8692\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.3514 - accuracy: 0.8792 - val_loss: 0.3806 - val_accuracy: 0.8716\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.3506 - accuracy: 0.8794 - val_loss: 0.3820 - val_accuracy: 0.8716\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3497 - accuracy: 0.8782 - val_loss: 0.3864 - val_accuracy: 0.8726\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3489 - accuracy: 0.8792 - val_loss: 0.3811 - val_accuracy: 0.8730\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.3477 - accuracy: 0.8794 - val_loss: 0.3850 - val_accuracy: 0.8692\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.3472 - accuracy: 0.8797 - val_loss: 0.3799 - val_accuracy: 0.8712\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3466 - accuracy: 0.8804 - val_loss: 0.3846 - val_accuracy: 0.8712\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3457 - accuracy: 0.8804 - val_loss: 0.3821 - val_accuracy: 0.8748\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3445 - accuracy: 0.8799 - val_loss: 0.3819 - val_accuracy: 0.8698\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3442 - accuracy: 0.8806 - val_loss: 0.3789 - val_accuracy: 0.8700\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.3430 - accuracy: 0.8805 - val_loss: 0.3794 - val_accuracy: 0.8694\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3425 - accuracy: 0.8816 - val_loss: 0.3771 - val_accuracy: 0.8726\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3421 - accuracy: 0.8809 - val_loss: 0.3774 - val_accuracy: 0.8720\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.3819 - accuracy: 0.8681\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 2.0859 - accuracy: 0.2774 - val_loss: 1.8001 - val_accuracy: 0.4112\n",
      "Epoch 2/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 1.5472 - accuracy: 0.5084 - val_loss: 1.2919 - val_accuracy: 0.5870\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 1.1522 - accuracy: 0.6338 - val_loss: 1.0140 - val_accuracy: 0.6738\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.9528 - accuracy: 0.6807 - val_loss: 0.8776 - val_accuracy: 0.6984\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.8471 - accuracy: 0.7043 - val_loss: 0.8018 - val_accuracy: 0.7186\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - ETA: 0s - loss: 0.7832 - accuracy: 0.72 - 1s 32us/sample - loss: 0.7832 - accuracy: 0.7223 - val_loss: 0.7522 - val_accuracy: 0.7362\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.7394 - accuracy: 0.7366 - val_loss: 0.7153 - val_accuracy: 0.7502\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.7059 - accuracy: 0.7508 - val_loss: 0.6862 - val_accuracy: 0.7610\n",
      "Epoch 9/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.6790 - accuracy: 0.7631 - val_loss: 0.6614 - val_accuracy: 0.7704\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.6562 - accuracy: 0.7742 - val_loss: 0.6459 - val_accuracy: 0.7818\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.6364 - accuracy: 0.7818 - val_loss: 0.6235 - val_accuracy: 0.7836\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.6191 - accuracy: 0.7870 - val_loss: 0.6058 - val_accuracy: 0.7918\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.6040 - accuracy: 0.7932 - val_loss: 0.5944 - val_accuracy: 0.7940\n",
      "Epoch 14/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5910 - accuracy: 0.7970 - val_loss: 0.5836 - val_accuracy: 0.8018\n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5790 - accuracy: 0.8003 - val_loss: 0.5701 - val_accuracy: 0.8042\n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5684 - accuracy: 0.8039 - val_loss: 0.5621 - val_accuracy: 0.8048\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5588 - accuracy: 0.8064 - val_loss: 0.5518 - val_accuracy: 0.8098\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5505 - accuracy: 0.8093 - val_loss: 0.5425 - val_accuracy: 0.8148loss: 0.5518 - accuracy: \n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5429 - accuracy: 0.8119 - val_loss: 0.5381 - val_accuracy: 0.8148\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5361 - accuracy: 0.8144 - val_loss: 0.5284 - val_accuracy: 0.8210\n",
      "Epoch 21/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.5296 - accuracy: 0.8152 - val_loss: 0.5250 - val_accuracy: 0.8220\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5232 - accuracy: 0.8183 - val_loss: 0.5186 - val_accuracy: 0.8236\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5186 - accuracy: 0.8192 - val_loss: 0.5113 - val_accuracy: 0.8262\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5132 - accuracy: 0.8214 - val_loss: 0.5072 - val_accuracy: 0.8276\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5082 - accuracy: 0.8240 - val_loss: 0.5071 - val_accuracy: 0.8258\n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5039 - accuracy: 0.8240 - val_loss: 0.5002 - val_accuracy: 0.8300\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4997 - accuracy: 0.8254 - val_loss: 0.4975 - val_accuracy: 0.8334\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4958 - accuracy: 0.8267 - val_loss: 0.4937 - val_accuracy: 0.8342\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4922 - accuracy: 0.8283 - val_loss: 0.4921 - val_accuracy: 0.8322\n",
      "Epoch 30/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4889 - accuracy: 0.8301 - val_loss: 0.4861 - val_accuracy: 0.8384\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4855 - accuracy: 0.8303 - val_loss: 0.4860 - val_accuracy: 0.8346\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4826 - accuracy: 0.8320 - val_loss: 0.4794 - val_accuracy: 0.8398\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4794 - accuracy: 0.8328 - val_loss: 0.4787 - val_accuracy: 0.8392\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4767 - accuracy: 0.8330 - val_loss: 0.4766 - val_accuracy: 0.8394\n",
      "Epoch 35/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4735 - accuracy: 0.8346 - val_loss: 0.4754 - val_accuracy: 0.8398\n",
      "Epoch 36/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4712 - accuracy: 0.8357 - val_loss: 0.4763 - val_accuracy: 0.8374\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4689 - accuracy: 0.8368 - val_loss: 0.4692 - val_accuracy: 0.8418\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4663 - accuracy: 0.8377 - val_loss: 0.4685 - val_accuracy: 0.8416\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4639 - accuracy: 0.8373 - val_loss: 0.4643 - val_accuracy: 0.8452\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4615 - accuracy: 0.8387 - val_loss: 0.4639 - val_accuracy: 0.8440\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4593 - accuracy: 0.8402 - val_loss: 0.4625 - val_accuracy: 0.8440\n",
      "Epoch 42/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4570 - accuracy: 0.8408 - val_loss: 0.4588 - val_accuracy: 0.8462\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4551 - accuracy: 0.8417 - val_loss: 0.4603 - val_accuracy: 0.8432\n",
      "Epoch 44/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4533 - accuracy: 0.8425 - val_loss: 0.4562 - val_accuracy: 0.8462\n",
      "Epoch 45/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4514 - accuracy: 0.8429 - val_loss: 0.4550 - val_accuracy: 0.8464\n",
      "Epoch 46/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4497 - accuracy: 0.8441 - val_loss: 0.4574 - val_accuracy: 0.8468\n",
      "Epoch 47/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4474 - accuracy: 0.8444 - val_loss: 0.4518 - val_accuracy: 0.8490\n",
      "Epoch 48/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4459 - accuracy: 0.8450 - val_loss: 0.4506 - val_accuracy: 0.8496\n",
      "Epoch 49/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4444 - accuracy: 0.8463 - val_loss: 0.4508 - val_accuracy: 0.8488\n",
      "Epoch 50/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4416 - accuracy: 0.8471 - val_loss: 0.4491 - val_accuracy: 0.8484\n",
      "Epoch 51/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4409 - accuracy: 0.8474 - val_loss: 0.4468 - val_accuracy: 0.8496\n",
      "Epoch 52/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4393 - accuracy: 0.8493 - val_loss: 0.4463 - val_accuracy: 0.8528\n",
      "Epoch 53/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4377 - accuracy: 0.8484 - val_loss: 0.4473 - val_accuracy: 0.8478\n",
      "Epoch 54/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4363 - accuracy: 0.8489 - val_loss: 0.4408 - val_accuracy: 0.8518\n",
      "Epoch 55/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4344 - accuracy: 0.8505 - val_loss: 0.4424 - val_accuracy: 0.8502\n",
      "Epoch 56/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4331 - accuracy: 0.8514 - val_loss: 0.4397 - val_accuracy: 0.8530\n",
      "Epoch 57/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4316 - accuracy: 0.8516 - val_loss: 0.4379 - val_accuracy: 0.8544\n",
      "Epoch 58/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4302 - accuracy: 0.8521 - val_loss: 0.4375 - val_accuracy: 0.8534\n",
      "Epoch 59/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4287 - accuracy: 0.8540 - val_loss: 0.4373 - val_accuracy: 0.8526\n",
      "Epoch 60/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4275 - accuracy: 0.8527 - val_loss: 0.4391 - val_accuracy: 0.8550\n",
      "Epoch 61/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4261 - accuracy: 0.8532 - val_loss: 0.4379 - val_accuracy: 0.8514\n",
      "Epoch 62/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4251 - accuracy: 0.8536 - val_loss: 0.4350 - val_accuracy: 0.8524\n",
      "Epoch 63/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4235 - accuracy: 0.8549 - val_loss: 0.4322 - val_accuracy: 0.8556\n",
      "Epoch 64/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4225 - accuracy: 0.8551 - val_loss: 0.4317 - val_accuracy: 0.8536\n",
      "Epoch 65/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4212 - accuracy: 0.8540 - val_loss: 0.4366 - val_accuracy: 0.8558\n",
      "Epoch 66/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4204 - accuracy: 0.8555 - val_loss: 0.4289 - val_accuracy: 0.8574\n",
      "Epoch 67/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4186 - accuracy: 0.8559 - val_loss: 0.4302 - val_accuracy: 0.8566\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4174 - accuracy: 0.8559 - val_loss: 0.4324 - val_accuracy: 0.8544\n",
      "Epoch 69/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4164 - accuracy: 0.8569 - val_loss: 0.4284 - val_accuracy: 0.8570\n",
      "Epoch 70/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4152 - accuracy: 0.8577 - val_loss: 0.4288 - val_accuracy: 0.8534\n",
      "Epoch 71/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4144 - accuracy: 0.8578 - val_loss: 0.4271 - val_accuracy: 0.8544\n",
      "Epoch 72/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4128 - accuracy: 0.8577 - val_loss: 0.4266 - val_accuracy: 0.8548\n",
      "Epoch 73/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4122 - accuracy: 0.8586 - val_loss: 0.4261 - val_accuracy: 0.8554\n",
      "Epoch 74/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4109 - accuracy: 0.8581 - val_loss: 0.4233 - val_accuracy: 0.8574\n",
      "Epoch 75/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4099 - accuracy: 0.8589 - val_loss: 0.4236 - val_accuracy: 0.8580\n",
      "Epoch 76/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4091 - accuracy: 0.8596 - val_loss: 0.4270 - val_accuracy: 0.8546\n",
      "Epoch 77/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4082 - accuracy: 0.8592 - val_loss: 0.4234 - val_accuracy: 0.8534\n",
      "Epoch 78/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4068 - accuracy: 0.8605 - val_loss: 0.4236 - val_accuracy: 0.8572\n",
      "Epoch 79/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4060 - accuracy: 0.8607 - val_loss: 0.4189 - val_accuracy: 0.8598\n",
      "Epoch 80/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4048 - accuracy: 0.8597 - val_loss: 0.4221 - val_accuracy: 0.8562\n",
      "Epoch 81/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4042 - accuracy: 0.8619 - val_loss: 0.4199 - val_accuracy: 0.8578\n",
      "Epoch 82/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4034 - accuracy: 0.8614 - val_loss: 0.4173 - val_accuracy: 0.8578\n",
      "Epoch 83/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4020 - accuracy: 0.8615 - val_loss: 0.4205 - val_accuracy: 0.8574\n",
      "Epoch 84/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4011 - accuracy: 0.8617 - val_loss: 0.4219 - val_accuracy: 0.8602\n",
      "Epoch 85/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4004 - accuracy: 0.8622 - val_loss: 0.4154 - val_accuracy: 0.8598\n",
      "Epoch 86/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3992 - accuracy: 0.8622 - val_loss: 0.4142 - val_accuracy: 0.8612\n",
      "Epoch 87/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3985 - accuracy: 0.8631 - val_loss: 0.4190 - val_accuracy: 0.8560\n",
      "Epoch 88/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3975 - accuracy: 0.8638 - val_loss: 0.4146 - val_accuracy: 0.8616\n",
      "Epoch 89/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3966 - accuracy: 0.8635 - val_loss: 0.4154 - val_accuracy: 0.8602\n",
      "Epoch 90/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3961 - accuracy: 0.8633 - val_loss: 0.4137 - val_accuracy: 0.8588\n",
      "Epoch 91/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3950 - accuracy: 0.8642 - val_loss: 0.4135 - val_accuracy: 0.8580\n",
      "Epoch 92/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3943 - accuracy: 0.8645 - val_loss: 0.4121 - val_accuracy: 0.8622\n",
      "Epoch 93/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3937 - accuracy: 0.8644 - val_loss: 0.4142 - val_accuracy: 0.8608\n",
      "Epoch 94/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3926 - accuracy: 0.8652 - val_loss: 0.4097 - val_accuracy: 0.8600\n",
      "Epoch 95/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3920 - accuracy: 0.8654 - val_loss: 0.4182 - val_accuracy: 0.8548\n",
      "Epoch 96/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.3912 - accuracy: 0.8655 - val_loss: 0.4120 - val_accuracy: 0.8580\n",
      "Epoch 97/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.3903 - accuracy: 0.8662 - val_loss: 0.4069 - val_accuracy: 0.8614\n",
      "Epoch 98/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.3891 - accuracy: 0.8669 - val_loss: 0.4086 - val_accuracy: 0.8584\n",
      "Epoch 99/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.3884 - accuracy: 0.8663 - val_loss: 0.4076 - val_accuracy: 0.8596\n",
      "Epoch 100/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.3880 - accuracy: 0.8663 - val_loss: 0.4104 - val_accuracy: 0.8584\n",
      "18334/18334 [==============================] - 0s 20us/sample - loss: 0.4230 - accuracy: 0.8501\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 2.0957 - accuracy: 0.2345 - val_loss: 1.8599 - val_accuracy: 0.3458\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 1.6051 - accuracy: 0.4652 - val_loss: 1.3176 - val_accuracy: 0.6036\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.1549 - accuracy: 0.6486 - val_loss: 1.0094 - val_accuracy: 0.6822\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.9474 - accuracy: 0.6964 - val_loss: 0.8744 - val_accuracy: 0.7158\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.8436 - accuracy: 0.7231 - val_loss: 0.7935 - val_accuracy: 0.7344\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.7765 - accuracy: 0.7411 - val_loss: 0.7384 - val_accuracy: 0.7490\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.7280 - accuracy: 0.7535 - val_loss: 0.6947 - val_accuracy: 0.7602\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.6907 - accuracy: 0.7629 - val_loss: 0.6624 - val_accuracy: 0.7694\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6624 - accuracy: 0.7705 - val_loss: 0.6391 - val_accuracy: 0.7760\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6392 - accuracy: 0.7790 - val_loss: 0.6190 - val_accuracy: 0.7854\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6205 - accuracy: 0.7864 - val_loss: 0.6017 - val_accuracy: 0.7906\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6049 - accuracy: 0.7907 - val_loss: 0.5875 - val_accuracy: 0.7964\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5910 - accuracy: 0.7955 - val_loss: 0.5759 - val_accuracy: 0.7978\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5792 - accuracy: 0.7997 - val_loss: 0.5629 - val_accuracy: 0.8052\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5684 - accuracy: 0.8037 - val_loss: 0.5559 - val_accuracy: 0.8096\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5596 - accuracy: 0.8059 - val_loss: 0.5465 - val_accuracy: 0.8158\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5511 - accuracy: 0.8093 - val_loss: 0.5389 - val_accuracy: 0.8168\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5431 - accuracy: 0.8117 - val_loss: 0.5301 - val_accuracy: 0.8178\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5362 - accuracy: 0.8132 - val_loss: 0.5235 - val_accuracy: 0.8216\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5297 - accuracy: 0.8152 - val_loss: 0.5177 - val_accuracy: 0.8246\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5237 - accuracy: 0.8170 - val_loss: 0.5122 - val_accuracy: 0.8246\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5182 - accuracy: 0.8184 - val_loss: 0.5095 - val_accuracy: 0.8254\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5134 - accuracy: 0.8205 - val_loss: 0.5029 - val_accuracy: 0.8264\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5086 - accuracy: 0.8210 - val_loss: 0.4971 - val_accuracy: 0.8286\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5037 - accuracy: 0.8240 - val_loss: 0.4952 - val_accuracy: 0.8304\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4997 - accuracy: 0.8246 - val_loss: 0.4921 - val_accuracy: 0.8308s - loss: 0.4982 - accuracy: 0.82 - ETA: 0s - loss: 0.4973 - accuracy\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4955 - accuracy: 0.8252 - val_loss: 0.4897 - val_accuracy: 0.8296\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4921 - accuracy: 0.8255 - val_loss: 0.4890 - val_accuracy: 0.8310\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4884 - accuracy: 0.8263 - val_loss: 0.4803 - val_accuracy: 0.8320\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4848 - accuracy: 0.8293 - val_loss: 0.4778 - val_accuracy: 0.8330\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4817 - accuracy: 0.8295 - val_loss: 0.4745 - val_accuracy: 0.8376\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4785 - accuracy: 0.8311 - val_loss: 0.4725 - val_accuracy: 0.8378\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4758 - accuracy: 0.8318 - val_loss: 0.4692 - val_accuracy: 0.8384\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4732 - accuracy: 0.8334 - val_loss: 0.4656 - val_accuracy: 0.8382\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4700 - accuracy: 0.8339 - val_loss: 0.4642 - val_accuracy: 0.8384\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4676 - accuracy: 0.8343 - val_loss: 0.4644 - val_accuracy: 0.8410\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4650 - accuracy: 0.8353 - val_loss: 0.4616 - val_accuracy: 0.8438\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4628 - accuracy: 0.8356 - val_loss: 0.4582 - val_accuracy: 0.8440\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4601 - accuracy: 0.8364 - val_loss: 0.4556 - val_accuracy: 0.8446\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4582 - accuracy: 0.8381 - val_loss: 0.4542 - val_accuracy: 0.8458\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4562 - accuracy: 0.8389 - val_loss: 0.4503 - val_accuracy: 0.8452\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4538 - accuracy: 0.8391 - val_loss: 0.4541 - val_accuracy: 0.8422\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4523 - accuracy: 0.8396 - val_loss: 0.4476 - val_accuracy: 0.8486\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4500 - accuracy: 0.8408 - val_loss: 0.4494 - val_accuracy: 0.8472\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4482 - accuracy: 0.8416 - val_loss: 0.4438 - val_accuracy: 0.8516\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4463 - accuracy: 0.8429 - val_loss: 0.4468 - val_accuracy: 0.8484\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4449 - accuracy: 0.8433 - val_loss: 0.4438 - val_accuracy: 0.8486\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4429 - accuracy: 0.8431 - val_loss: 0.4419 - val_accuracy: 0.8516\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4413 - accuracy: 0.8438 - val_loss: 0.4384 - val_accuracy: 0.8522\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4399 - accuracy: 0.8447 - val_loss: 0.4370 - val_accuracy: 0.8534\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4381 - accuracy: 0.8450 - val_loss: 0.4371 - val_accuracy: 0.8544\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4364 - accuracy: 0.8459 - val_loss: 0.4340 - val_accuracy: 0.8534\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4347 - accuracy: 0.8469 - val_loss: 0.4370 - val_accuracy: 0.8504\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4335 - accuracy: 0.8471 - val_loss: 0.4315 - val_accuracy: 0.8560\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4323 - accuracy: 0.8469 - val_loss: 0.4332 - val_accuracy: 0.8558\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4309 - accuracy: 0.8476 - val_loss: 0.4329 - val_accuracy: 0.8548\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4288 - accuracy: 0.8478 - val_loss: 0.4308 - val_accuracy: 0.8566\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4282 - accuracy: 0.8479 - val_loss: 0.4289 - val_accuracy: 0.8584\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4269 - accuracy: 0.8491 - val_loss: 0.4290 - val_accuracy: 0.8568\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4257 - accuracy: 0.8484 - val_loss: 0.4282 - val_accuracy: 0.8560\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4245 - accuracy: 0.8510 - val_loss: 0.4252 - val_accuracy: 0.8604\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4236 - accuracy: 0.8505 - val_loss: 0.4273 - val_accuracy: 0.8570\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4218 - accuracy: 0.8513 - val_loss: 0.4231 - val_accuracy: 0.8600\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4208 - accuracy: 0.8517 - val_loss: 0.4270 - val_accuracy: 0.8562\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4200 - accuracy: 0.8516 - val_loss: 0.4241 - val_accuracy: 0.8584\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4192 - accuracy: 0.8511 - val_loss: 0.4238 - val_accuracy: 0.8594\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4175 - accuracy: 0.8526 - val_loss: 0.4257 - val_accuracy: 0.8592\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4166 - accuracy: 0.8532 - val_loss: 0.4230 - val_accuracy: 0.8578\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4153 - accuracy: 0.8530 - val_loss: 0.4250 - val_accuracy: 0.8562\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4148 - accuracy: 0.8539 - val_loss: 0.4210 - val_accuracy: 0.8596\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4138 - accuracy: 0.8539 - val_loss: 0.4202 - val_accuracy: 0.8616\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4131 - accuracy: 0.8542 - val_loss: 0.4178 - val_accuracy: 0.8616\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4119 - accuracy: 0.8553 - val_loss: 0.4179 - val_accuracy: 0.8620\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4107 - accuracy: 0.8543 - val_loss: 0.4205 - val_accuracy: 0.8610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4100 - accuracy: 0.8552 - val_loss: 0.4182 - val_accuracy: 0.8602\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4090 - accuracy: 0.8553 - val_loss: 0.4171 - val_accuracy: 0.8618\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4084 - accuracy: 0.8553 - val_loss: 0.4152 - val_accuracy: 0.8616\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4076 - accuracy: 0.8552 - val_loss: 0.4171 - val_accuracy: 0.8628\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4061 - accuracy: 0.8570 - val_loss: 0.4175 - val_accuracy: 0.8610\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4060 - accuracy: 0.8557 - val_loss: 0.4127 - val_accuracy: 0.8638\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4046 - accuracy: 0.8565 - val_loss: 0.4127 - val_accuracy: 0.8640\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4036 - accuracy: 0.8571 - val_loss: 0.4154 - val_accuracy: 0.8614\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4032 - accuracy: 0.8573 - val_loss: 0.4112 - val_accuracy: 0.8620\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4024 - accuracy: 0.8586 - val_loss: 0.4155 - val_accuracy: 0.8604\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4017 - accuracy: 0.8576 - val_loss: 0.4113 - val_accuracy: 0.8630\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4011 - accuracy: 0.8576 - val_loss: 0.4158 - val_accuracy: 0.8622\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3997 - accuracy: 0.8581 - val_loss: 0.4142 - val_accuracy: 0.8608\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.3996 - accuracy: 0.8590 - val_loss: 0.4105 - val_accuracy: 0.8632\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3984 - accuracy: 0.8590 - val_loss: 0.4118 - val_accuracy: 0.8640\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.3974 - accuracy: 0.8609 - val_loss: 0.4112 - val_accuracy: 0.8612\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3969 - accuracy: 0.8595 - val_loss: 0.4108 - val_accuracy: 0.8642loss: 0.3982 - accuracy: 0.85\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3965 - accuracy: 0.8595 - val_loss: 0.4118 - val_accuracy: 0.8628\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3956 - accuracy: 0.8601 - val_loss: 0.4077 - val_accuracy: 0.8644\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3948 - accuracy: 0.8611 - val_loss: 0.4082 - val_accuracy: 0.8634\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3943 - accuracy: 0.8607 - val_loss: 0.4107 - val_accuracy: 0.8632\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3936 - accuracy: 0.8614 - val_loss: 0.4048 - val_accuracy: 0.8640\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3929 - accuracy: 0.8614 - val_loss: 0.4053 - val_accuracy: 0.8646\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.3924 - accuracy: 0.8610 - val_loss: 0.4049 - val_accuracy: 0.8642\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3916 - accuracy: 0.8609 - val_loss: 0.4070 - val_accuracy: 0.8646\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.3905 - accuracy: 0.8622 - val_loss: 0.4048 - val_accuracy: 0.8664\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.4132 - accuracy: 0.8596\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 2.0925 - accuracy: 0.1584 - val_loss: 1.8585 - val_accuracy: 0.2666\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 1.5993 - accuracy: 0.4742 - val_loss: 1.3276 - val_accuracy: 0.6100\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 1.1775 - accuracy: 0.6373 - val_loss: 1.0399 - val_accuracy: 0.6752\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.9743 - accuracy: 0.6828 - val_loss: 0.8945 - val_accuracy: 0.7182\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.8619 - accuracy: 0.7074 - val_loss: 0.8096 - val_accuracy: 0.7336\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.7931 - accuracy: 0.7258 - val_loss: 0.7558 - val_accuracy: 0.7528\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.7455 - accuracy: 0.7406 - val_loss: 0.7132 - val_accuracy: 0.7666\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.7090 - accuracy: 0.7515 - val_loss: 0.6776 - val_accuracy: 0.7754\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6797 - accuracy: 0.7623 - val_loss: 0.6512 - val_accuracy: 0.7850\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6547 - accuracy: 0.7716 - val_loss: 0.6291 - val_accuracy: 0.7964\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6334 - accuracy: 0.7810 - val_loss: 0.6106 - val_accuracy: 0.7976\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6152 - accuracy: 0.7861 - val_loss: 0.5938 - val_accuracy: 0.8024\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5997 - accuracy: 0.7922 - val_loss: 0.5802 - val_accuracy: 0.80800.6042 - accuracy\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5857 - accuracy: 0.7963 - val_loss: 0.5640 - val_accuracy: 0.8140\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5741 - accuracy: 0.8010 - val_loss: 0.5583 - val_accuracy: 0.8174\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5640 - accuracy: 0.8040 - val_loss: 0.5438 - val_accuracy: 0.8206\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5546 - accuracy: 0.8084 - val_loss: 0.5360 - val_accuracy: 0.8232\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5470 - accuracy: 0.8108 - val_loss: 0.5313 - val_accuracy: 0.8222\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5396 - accuracy: 0.8144 - val_loss: 0.5218 - val_accuracy: 0.8252\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5327 - accuracy: 0.8165 - val_loss: 0.5164 - val_accuracy: 0.8288ss: 0.5393 \n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5266 - accuracy: 0.8176 - val_loss: 0.5145 - val_accuracy: 0.8286\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5218 - accuracy: 0.8199 - val_loss: 0.5098 - val_accuracy: 0.8266\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5162 - accuracy: 0.8215 - val_loss: 0.5054 - val_accuracy: 0.8282\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5113 - accuracy: 0.8237 - val_loss: 0.5054 - val_accuracy: 0.8294\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5070 - accuracy: 0.8248 - val_loss: 0.4929 - val_accuracy: 0.8340\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5024 - accuracy: 0.8256 - val_loss: 0.4900 - val_accuracy: 0.8360\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4984 - accuracy: 0.8260 - val_loss: 0.4860 - val_accuracy: 0.8352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4945 - accuracy: 0.8277 - val_loss: 0.4843 - val_accuracy: 0.8358\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4905 - accuracy: 0.8290 - val_loss: 0.4821 - val_accuracy: 0.8364\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4874 - accuracy: 0.8303 - val_loss: 0.4779 - val_accuracy: 0.8374\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4844 - accuracy: 0.8312 - val_loss: 0.4756 - val_accuracy: 0.8368\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4814 - accuracy: 0.8327 - val_loss: 0.4705 - val_accuracy: 0.8380\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4783 - accuracy: 0.8336 - val_loss: 0.4730 - val_accuracy: 0.8384\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4751 - accuracy: 0.8352 - val_loss: 0.4699 - val_accuracy: 0.8390\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4726 - accuracy: 0.8355 - val_loss: 0.4644 - val_accuracy: 0.8400\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4698 - accuracy: 0.8354 - val_loss: 0.4659 - val_accuracy: 0.8418\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4676 - accuracy: 0.8372 - val_loss: 0.4658 - val_accuracy: 0.8404\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4653 - accuracy: 0.8379 - val_loss: 0.4602 - val_accuracy: 0.8426\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4628 - accuracy: 0.8384 - val_loss: 0.4627 - val_accuracy: 0.8430\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4600 - accuracy: 0.8396 - val_loss: 0.4571 - val_accuracy: 0.8456\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4582 - accuracy: 0.8392 - val_loss: 0.4530 - val_accuracy: 0.8444\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4563 - accuracy: 0.8411 - val_loss: 0.4560 - val_accuracy: 0.8434\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4542 - accuracy: 0.8417 - val_loss: 0.4545 - val_accuracy: 0.8434\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4524 - accuracy: 0.8426 - val_loss: 0.4575 - val_accuracy: 0.8422\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4507 - accuracy: 0.8417 - val_loss: 0.4476 - val_accuracy: 0.8482\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4487 - accuracy: 0.8440 - val_loss: 0.4482 - val_accuracy: 0.8468\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4469 - accuracy: 0.8440 - val_loss: 0.4453 - val_accuracy: 0.8456\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4452 - accuracy: 0.8447 - val_loss: 0.4473 - val_accuracy: 0.8444\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4437 - accuracy: 0.8452 - val_loss: 0.4433 - val_accuracy: 0.8464\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4419 - accuracy: 0.8462 - val_loss: 0.4393 - val_accuracy: 0.8484\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4403 - accuracy: 0.8480 - val_loss: 0.4395 - val_accuracy: 0.8504\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4388 - accuracy: 0.8475 - val_loss: 0.4377 - val_accuracy: 0.8508\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4374 - accuracy: 0.8486 - val_loss: 0.4354 - val_accuracy: 0.8520\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4361 - accuracy: 0.8477 - val_loss: 0.4382 - val_accuracy: 0.8504\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4343 - accuracy: 0.8484 - val_loss: 0.4358 - val_accuracy: 0.8480\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4331 - accuracy: 0.8496 - val_loss: 0.4314 - val_accuracy: 0.8542\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4318 - accuracy: 0.8506 - val_loss: 0.4336 - val_accuracy: 0.8524\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4298 - accuracy: 0.8502 - val_loss: 0.4346 - val_accuracy: 0.8520\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4287 - accuracy: 0.8503 - val_loss: 0.4381 - val_accuracy: 0.8522\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4278 - accuracy: 0.8518 - val_loss: 0.4328 - val_accuracy: 0.8496\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4260 - accuracy: 0.8523 - val_loss: 0.4302 - val_accuracy: 0.8530\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4249 - accuracy: 0.8525 - val_loss: 0.4277 - val_accuracy: 0.8526\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4241 - accuracy: 0.8524 - val_loss: 0.4278 - val_accuracy: 0.8518\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4222 - accuracy: 0.8540 - val_loss: 0.4281 - val_accuracy: 0.8548\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4214 - accuracy: 0.8531 - val_loss: 0.4241 - val_accuracy: 0.8578\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4199 - accuracy: 0.8542 - val_loss: 0.4274 - val_accuracy: 0.8530\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4188 - accuracy: 0.8554 - val_loss: 0.4226 - val_accuracy: 0.8576\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4174 - accuracy: 0.8556 - val_loss: 0.4224 - val_accuracy: 0.8570\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4160 - accuracy: 0.8561 - val_loss: 0.4210 - val_accuracy: 0.8558\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4152 - accuracy: 0.8562 - val_loss: 0.4222 - val_accuracy: 0.8568\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4138 - accuracy: 0.8553 - val_loss: 0.4179 - val_accuracy: 0.8580\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4128 - accuracy: 0.8560 - val_loss: 0.4201 - val_accuracy: 0.8568\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4117 - accuracy: 0.8565 - val_loss: 0.4184 - val_accuracy: 0.8586\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4106 - accuracy: 0.8578 - val_loss: 0.4168 - val_accuracy: 0.8554\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4091 - accuracy: 0.8577 - val_loss: 0.4184 - val_accuracy: 0.8582\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4085 - accuracy: 0.8580 - val_loss: 0.4177 - val_accuracy: 0.8584\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4073 - accuracy: 0.8580 - val_loss: 0.4163 - val_accuracy: 0.8560\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4064 - accuracy: 0.8584 - val_loss: 0.4158 - val_accuracy: 0.8568\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4051 - accuracy: 0.8596 - val_loss: 0.4163 - val_accuracy: 0.8572\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4039 - accuracy: 0.8589 - val_loss: 0.4120 - val_accuracy: 0.8602\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4033 - accuracy: 0.8593 - val_loss: 0.4143 - val_accuracy: 0.8602\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4026 - accuracy: 0.8597 - val_loss: 0.4138 - val_accuracy: 0.8576\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4016 - accuracy: 0.8593 - val_loss: 0.4099 - val_accuracy: 0.8604\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4005 - accuracy: 0.8603 - val_loss: 0.4116 - val_accuracy: 0.8590\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3994 - accuracy: 0.8608 - val_loss: 0.4121 - val_accuracy: 0.8572\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3988 - accuracy: 0.8616 - val_loss: 0.4082 - val_accuracy: 0.8594\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3980 - accuracy: 0.8611 - val_loss: 0.4117 - val_accuracy: 0.8550\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3975 - accuracy: 0.8619 - val_loss: 0.4092 - val_accuracy: 0.8596\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3967 - accuracy: 0.8619 - val_loss: 0.4079 - val_accuracy: 0.8596\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3956 - accuracy: 0.8619 - val_loss: 0.4137 - val_accuracy: 0.8550\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3941 - accuracy: 0.8628 - val_loss: 0.4073 - val_accuracy: 0.8598\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3943 - accuracy: 0.8617 - val_loss: 0.4060 - val_accuracy: 0.8576\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3931 - accuracy: 0.8632 - val_loss: 0.4097 - val_accuracy: 0.8606\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3925 - accuracy: 0.8631 - val_loss: 0.4082 - val_accuracy: 0.8576\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.3916 - accuracy: 0.8629 - val_loss: 0.4044 - val_accuracy: 0.8596\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3907 - accuracy: 0.8637 - val_loss: 0.4062 - val_accuracy: 0.8602\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3904 - accuracy: 0.8634 - val_loss: 0.4058 - val_accuracy: 0.8586\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3897 - accuracy: 0.8635 - val_loss: 0.4043 - val_accuracy: 0.8602\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3887 - accuracy: 0.8643 - val_loss: 0.4036 - val_accuracy: 0.8602\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3881 - accuracy: 0.8644 - val_loss: 0.4019 - val_accuracy: 0.8604\n",
      "18333/18333 [==============================] - 0s 19us/sample - loss: 0.4165 - accuracy: 0.8557\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 1.4382 - accuracy: 0.5716 - val_loss: 1.0438 - val_accuracy: 0.6920\n",
      "Epoch 2/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.9476 - accuracy: 0.7071 - val_loss: 0.8594 - val_accuracy: 0.7384\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.8255 - accuracy: 0.7406 - val_loss: 0.7778 - val_accuracy: 0.7584\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.7616 - accuracy: 0.7593 - val_loss: 0.7281 - val_accuracy: 0.7754\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.7197 - accuracy: 0.7714 - val_loss: 0.6947 - val_accuracy: 0.7840\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.6893 - accuracy: 0.7794 - val_loss: 0.6686 - val_accuracy: 0.7910\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.6658 - accuracy: 0.7862 - val_loss: 0.6470 - val_accuracy: 0.7956\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.6470 - accuracy: 0.7924 - val_loss: 0.6301 - val_accuracy: 0.8010\n",
      "Epoch 9/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.6313 - accuracy: 0.7972 - val_loss: 0.6165 - val_accuracy: 0.8040\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.6180 - accuracy: 0.8017 - val_loss: 0.6051 - val_accuracy: 0.8082\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.6067 - accuracy: 0.8053 - val_loss: 0.5947 - val_accuracy: 0.8120\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.5964 - accuracy: 0.8066 - val_loss: 0.5873 - val_accuracy: 0.8144\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5877 - accuracy: 0.8108 - val_loss: 0.5774 - val_accuracy: 0.8170\n",
      "Epoch 14/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5799 - accuracy: 0.8124 - val_loss: 0.5704 - val_accuracy: 0.8188\n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5726 - accuracy: 0.8153 - val_loss: 0.5656 - val_accuracy: 0.8202s - loss: 0.5717 - accuracy: 0.\n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5661 - accuracy: 0.8172 - val_loss: 0.5572 - val_accuracy: 0.8230\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5602 - accuracy: 0.8188 - val_loss: 0.5520 - val_accuracy: 0.8266\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5546 - accuracy: 0.8205 - val_loss: 0.5476 - val_accuracy: 0.8304\n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5496 - accuracy: 0.8215 - val_loss: 0.5429 - val_accuracy: 0.8302\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5449 - accuracy: 0.8223 - val_loss: 0.5387 - val_accuracy: 0.8298\n",
      "Epoch 21/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5406 - accuracy: 0.8236 - val_loss: 0.5340 - val_accuracy: 0.8308\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5365 - accuracy: 0.8250 - val_loss: 0.5299 - val_accuracy: 0.8346\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5327 - accuracy: 0.8260 - val_loss: 0.5268 - val_accuracy: 0.8334\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5291 - accuracy: 0.8269 - val_loss: 0.5236 - val_accuracy: 0.8358\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5259 - accuracy: 0.8277 - val_loss: 0.5208 - val_accuracy: 0.8372\n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5225 - accuracy: 0.8279 - val_loss: 0.5168 - val_accuracy: 0.8376\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5196 - accuracy: 0.8293 - val_loss: 0.5143 - val_accuracy: 0.8384\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5167 - accuracy: 0.8298 - val_loss: 0.5121 - val_accuracy: 0.8382\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5139 - accuracy: 0.8304 - val_loss: 0.5102 - val_accuracy: 0.8414\n",
      "Epoch 30/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5113 - accuracy: 0.8310 - val_loss: 0.5070 - val_accuracy: 0.8388\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.5089 - accuracy: 0.8313 - val_loss: 0.5045 - val_accuracy: 0.8408\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5064 - accuracy: 0.8323 - val_loss: 0.5021 - val_accuracy: 0.8394\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5042 - accuracy: 0.8333 - val_loss: 0.5000 - val_accuracy: 0.8394\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5020 - accuracy: 0.8337 - val_loss: 0.4983 - val_accuracy: 0.8432\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4998 - accuracy: 0.8345 - val_loss: 0.5005 - val_accuracy: 0.8414\n",
      "Epoch 36/100\n",
      "36666/36666 [==============================] - ETA: 0s - loss: 0.4976 - accuracy: 0.83 - 1s 27us/sample - loss: 0.4980 - accuracy: 0.8347 - val_loss: 0.4956 - val_accuracy: 0.8414\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4960 - accuracy: 0.8346 - val_loss: 0.4931 - val_accuracy: 0.8418\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4942 - accuracy: 0.8357 - val_loss: 0.4923 - val_accuracy: 0.8418 - accuracy\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4924 - accuracy: 0.8364 - val_loss: 0.4910 - val_accuracy: 0.8434\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4907 - accuracy: 0.8375 - val_loss: 0.4883 - val_accuracy: 0.8434\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4889 - accuracy: 0.8372 - val_loss: 0.4873 - val_accuracy: 0.8444\n",
      "Epoch 42/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4875 - accuracy: 0.8381 - val_loss: 0.4861 - val_accuracy: 0.8450\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4859 - accuracy: 0.8388 - val_loss: 0.4845 - val_accuracy: 0.8470\n",
      "Epoch 44/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4843 - accuracy: 0.8392 - val_loss: 0.4826 - val_accuracy: 0.8464\n",
      "Epoch 45/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4827 - accuracy: 0.8392 - val_loss: 0.4828 - val_accuracy: 0.8456\n",
      "Epoch 46/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4816 - accuracy: 0.8399 - val_loss: 0.4798 - val_accuracy: 0.8458\n",
      "Epoch 47/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4801 - accuracy: 0.8407 - val_loss: 0.4792 - val_accuracy: 0.8464\n",
      "Epoch 48/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4787 - accuracy: 0.8411 - val_loss: 0.4781 - val_accuracy: 0.8478- loss: 0\n",
      "Epoch 49/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4774 - accuracy: 0.8414 - val_loss: 0.4782 - val_accuracy: 0.8478\n",
      "Epoch 50/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4763 - accuracy: 0.8416 - val_loss: 0.4768 - val_accuracy: 0.8474\n",
      "Epoch 51/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4750 - accuracy: 0.8417 - val_loss: 0.4747 - val_accuracy: 0.8490\n",
      "Epoch 52/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4739 - accuracy: 0.8425 - val_loss: 0.4735 - val_accuracy: 0.8486\n",
      "Epoch 53/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4726 - accuracy: 0.8427 - val_loss: 0.4732 - val_accuracy: 0.8468\n",
      "Epoch 54/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4715 - accuracy: 0.8434 - val_loss: 0.4726 - val_accuracy: 0.8478\n",
      "Epoch 55/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4704 - accuracy: 0.8436 - val_loss: 0.4728 - val_accuracy: 0.8476\n",
      "Epoch 56/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4694 - accuracy: 0.8439 - val_loss: 0.4704 - val_accuracy: 0.8480\n",
      "Epoch 57/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4682 - accuracy: 0.8447 - val_loss: 0.4693 - val_accuracy: 0.8484\n",
      "Epoch 58/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4673 - accuracy: 0.8444 - val_loss: 0.4677 - val_accuracy: 0.8496\n",
      "Epoch 59/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4663 - accuracy: 0.8449 - val_loss: 0.4675 - val_accuracy: 0.8486\n",
      "Epoch 60/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4652 - accuracy: 0.8448 - val_loss: 0.4663 - val_accuracy: 0.8502\n",
      "Epoch 61/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4642 - accuracy: 0.8451 - val_loss: 0.4673 - val_accuracy: 0.8480\n",
      "Epoch 62/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4635 - accuracy: 0.8459 - val_loss: 0.4648 - val_accuracy: 0.8500\n",
      "Epoch 63/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4624 - accuracy: 0.8462 - val_loss: 0.4646 - val_accuracy: 0.8488\n",
      "Epoch 64/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4616 - accuracy: 0.8465 - val_loss: 0.4637 - val_accuracy: 0.8496\n",
      "Epoch 65/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4607 - accuracy: 0.8469 - val_loss: 0.4626 - val_accuracy: 0.8498\n",
      "Epoch 66/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4599 - accuracy: 0.8463 - val_loss: 0.4617 - val_accuracy: 0.8508- loss: 0.4633 - accuracy: 0. - ETA: 0s - loss: 0.4606 - accuracy: 0.84\n",
      "Epoch 67/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4591 - accuracy: 0.8472 - val_loss: 0.4615 - val_accuracy: 0.8502\n",
      "Epoch 68/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4582 - accuracy: 0.8464 - val_loss: 0.4607 - val_accuracy: 0.8504\n",
      "Epoch 69/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4574 - accuracy: 0.8475 - val_loss: 0.4601 - val_accuracy: 0.8502\n",
      "Epoch 70/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4566 - accuracy: 0.8477 - val_loss: 0.4590 - val_accuracy: 0.8506\n",
      "Epoch 71/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4560 - accuracy: 0.8476 - val_loss: 0.4586 - val_accuracy: 0.8502\n",
      "Epoch 72/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4552 - accuracy: 0.8486 - val_loss: 0.4576 - val_accuracy: 0.8508\n",
      "Epoch 73/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4544 - accuracy: 0.8484 - val_loss: 0.4575 - val_accuracy: 0.8510\n",
      "Epoch 74/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4536 - accuracy: 0.8492 - val_loss: 0.4565 - val_accuracy: 0.8516\n",
      "Epoch 75/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4529 - accuracy: 0.8491 - val_loss: 0.4574 - val_accuracy: 0.8514\n",
      "Epoch 76/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4522 - accuracy: 0.8499 - val_loss: 0.4555 - val_accuracy: 0.8522\n",
      "Epoch 77/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4516 - accuracy: 0.8495 - val_loss: 0.4549 - val_accuracy: 0.8532\n",
      "Epoch 78/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4508 - accuracy: 0.8494 - val_loss: 0.4546 - val_accuracy: 0.8516\n",
      "Epoch 79/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4502 - accuracy: 0.8502 - val_loss: 0.4533 - val_accuracy: 0.8516\n",
      "Epoch 80/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4495 - accuracy: 0.8505 - val_loss: 0.4532 - val_accuracy: 0.8524\n",
      "Epoch 81/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4490 - accuracy: 0.8503 - val_loss: 0.4524 - val_accuracy: 0.8516\n",
      "Epoch 82/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4483 - accuracy: 0.8505 - val_loss: 0.4522 - val_accuracy: 0.8516s - loss: 0\n",
      "Epoch 83/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4476 - accuracy: 0.8507 - val_loss: 0.4522 - val_accuracy: 0.8518\n",
      "Epoch 84/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4472 - accuracy: 0.8511 - val_loss: 0.4512 - val_accuracy: 0.8534\n",
      "Epoch 85/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4464 - accuracy: 0.8508 - val_loss: 0.4514 - val_accuracy: 0.8508ss: 0.4473 - accura\n",
      "Epoch 86/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4459 - accuracy: 0.8519 - val_loss: 0.4523 - val_accuracy: 0.8520\n",
      "Epoch 87/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4451 - accuracy: 0.8516 - val_loss: 0.4505 - val_accuracy: 0.8522\n",
      "Epoch 88/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4447 - accuracy: 0.8516 - val_loss: 0.4494 - val_accuracy: 0.8532\n",
      "Epoch 89/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4442 - accuracy: 0.8515 - val_loss: 0.4491 - val_accuracy: 0.8520- loss: 0\n",
      "Epoch 90/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4436 - accuracy: 0.8516 - val_loss: 0.4485 - val_accuracy: 0.8518\n",
      "Epoch 91/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4430 - accuracy: 0.8524 - val_loss: 0.4483 - val_accuracy: 0.8536\n",
      "Epoch 92/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4425 - accuracy: 0.8520 - val_loss: 0.4473 - val_accuracy: 0.8528\n",
      "Epoch 93/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4421 - accuracy: 0.8521 - val_loss: 0.4472 - val_accuracy: 0.8530\n",
      "Epoch 94/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4414 - accuracy: 0.8526 - val_loss: 0.4474 - val_accuracy: 0.8518: 0.4382 - accura\n",
      "Epoch 95/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4410 - accuracy: 0.8525 - val_loss: 0.4469 - val_accuracy: 0.8524\n",
      "Epoch 96/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4405 - accuracy: 0.8526 - val_loss: 0.4461 - val_accuracy: 0.8526\n",
      "Epoch 97/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4399 - accuracy: 0.8534 - val_loss: 0.4468 - val_accuracy: 0.8520\n",
      "Epoch 98/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4394 - accuracy: 0.8532 - val_loss: 0.4453 - val_accuracy: 0.8530\n",
      "Epoch 99/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4389 - accuracy: 0.8530 - val_loss: 0.4469 - val_accuracy: 0.8546\n",
      "Epoch 100/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4384 - accuracy: 0.8528 - val_loss: 0.4453 - val_accuracy: 0.8540\n",
      "18334/18334 [==============================] - 0s 19us/sample - loss: 0.4599 - accuracy: 0.8411\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.3893 - accuracy: 0.5911 - val_loss: 1.0313 - val_accuracy: 0.6840\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.9408 - accuracy: 0.7012 - val_loss: 0.8558 - val_accuracy: 0.7266\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 27us/sample - loss: 0.8241 - accuracy: 0.7338 - val_loss: 0.7763 - val_accuracy: 0.7506\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.7620 - accuracy: 0.7541 - val_loss: 0.7276 - val_accuracy: 0.7672\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.7207 - accuracy: 0.7669 - val_loss: 0.6945 - val_accuracy: 0.7792\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6908 - accuracy: 0.7774 - val_loss: 0.6680 - val_accuracy: 0.7844ccuracy: \n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.6674 - accuracy: 0.7851 - val_loss: 0.6484 - val_accuracy: 0.7894\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.6487 - accuracy: 0.7907 - val_loss: 0.6313 - val_accuracy: 0.7958\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.6329 - accuracy: 0.7959 - val_loss: 0.6180 - val_accuracy: 0.7992\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 27us/sample - loss: 0.6197 - accuracy: 0.7992 - val_loss: 0.6060 - val_accuracy: 0.8048\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 27us/sample - loss: 0.6083 - accuracy: 0.8028 - val_loss: 0.5952 - val_accuracy: 0.8078\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5983 - accuracy: 0.8057 - val_loss: 0.5858 - val_accuracy: 0.8110\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5892 - accuracy: 0.8082 - val_loss: 0.5780 - val_accuracy: 0.8160\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5814 - accuracy: 0.8108 - val_loss: 0.5715 - val_accuracy: 0.8172\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5741 - accuracy: 0.8141 - val_loss: 0.5643 - val_accuracy: 0.8172\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5677 - accuracy: 0.8141 - val_loss: 0.5583 - val_accuracy: 0.8182\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5617 - accuracy: 0.8166 - val_loss: 0.5536 - val_accuracy: 0.8232\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5565 - accuracy: 0.8188 - val_loss: 0.5477 - val_accuracy: 0.8244\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5514 - accuracy: 0.8194 - val_loss: 0.5437 - val_accuracy: 0.8286\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5466 - accuracy: 0.8206 - val_loss: 0.5399 - val_accuracy: 0.8270\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5425 - accuracy: 0.8216 - val_loss: 0.5350 - val_accuracy: 0.8282\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5382 - accuracy: 0.8228 - val_loss: 0.5313 - val_accuracy: 0.8286\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5345 - accuracy: 0.8238 - val_loss: 0.5279 - val_accuracy: 0.8310\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5308 - accuracy: 0.8250 - val_loss: 0.5251 - val_accuracy: 0.8314\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5277 - accuracy: 0.8251 - val_loss: 0.5225 - val_accuracy: 0.8316\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5245 - accuracy: 0.8257 - val_loss: 0.5189 - val_accuracy: 0.8336\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5216 - accuracy: 0.8271 - val_loss: 0.5160 - val_accuracy: 0.8346\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5186 - accuracy: 0.8276 - val_loss: 0.5133 - val_accuracy: 0.8348\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5159 - accuracy: 0.8283 - val_loss: 0.5109 - val_accuracy: 0.8350\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5131 - accuracy: 0.8293 - val_loss: 0.5096 - val_accuracy: 0.8350\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5110 - accuracy: 0.8304 - val_loss: 0.5069 - val_accuracy: 0.8350\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5086 - accuracy: 0.8301 - val_loss: 0.5054 - val_accuracy: 0.8344loss: 0.505\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5063 - accuracy: 0.8312 - val_loss: 0.5038 - val_accuracy: 0.8354\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5041 - accuracy: 0.8314 - val_loss: 0.5002 - val_accuracy: 0.8374\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5022 - accuracy: 0.8327 - val_loss: 0.4989 - val_accuracy: 0.8384\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5001 - accuracy: 0.8325 - val_loss: 0.4969 - val_accuracy: 0.8390\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4983 - accuracy: 0.8334 - val_loss: 0.4952 - val_accuracy: 0.8376\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4965 - accuracy: 0.8326 - val_loss: 0.4939 - val_accuracy: 0.8380\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4946 - accuracy: 0.8343 - val_loss: 0.4927 - val_accuracy: 0.8394\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4930 - accuracy: 0.8349 - val_loss: 0.4914 - val_accuracy: 0.8394\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4914 - accuracy: 0.8350 - val_loss: 0.4894 - val_accuracy: 0.8410\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4899 - accuracy: 0.8351 - val_loss: 0.4882 - val_accuracy: 0.8390- loss: 0.4839 - accuracy: 0.83 - ETA: 0s - loss: 0.483\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4883 - accuracy: 0.8356 - val_loss: 0.4868 - val_accuracy: 0.8428\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4866 - accuracy: 0.8363 - val_loss: 0.4859 - val_accuracy: 0.8412\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4853 - accuracy: 0.8366 - val_loss: 0.4846 - val_accuracy: 0.8414\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4840 - accuracy: 0.8363 - val_loss: 0.4833 - val_accuracy: 0.8424\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4825 - accuracy: 0.8370 - val_loss: 0.4816 - val_accuracy: 0.8438\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4811 - accuracy: 0.8375 - val_loss: 0.4808 - val_accuracy: 0.8434\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4800 - accuracy: 0.8377 - val_loss: 0.4801 - val_accuracy: 0.8442\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4788 - accuracy: 0.8381 - val_loss: 0.4788 - val_accuracy: 0.8428\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - ETA: 0s - loss: 0.4790 - accuracy: 0.83 - 1s 32us/sample - loss: 0.4776 - accuracy: 0.8382 - val_loss: 0.4774 - val_accuracy: 0.8454\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4762 - accuracy: 0.8387 - val_loss: 0.4763 - val_accuracy: 0.8454\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4753 - accuracy: 0.8393 - val_loss: 0.4756 - val_accuracy: 0.8452\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4742 - accuracy: 0.8394 - val_loss: 0.4750 - val_accuracy: 0.8462\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4730 - accuracy: 0.8403 - val_loss: 0.4749 - val_accuracy: 0.8458\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4719 - accuracy: 0.8399 - val_loss: 0.4735 - val_accuracy: 0.8472\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4710 - accuracy: 0.8411 - val_loss: 0.4719 - val_accuracy: 0.8468\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4700 - accuracy: 0.8404 - val_loss: 0.4709 - val_accuracy: 0.8474\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4691 - accuracy: 0.8413 - val_loss: 0.4700 - val_accuracy: 0.8478\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4681 - accuracy: 0.8417 - val_loss: 0.4700 - val_accuracy: 0.8466\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4672 - accuracy: 0.8411 - val_loss: 0.4687 - val_accuracy: 0.8474\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4661 - accuracy: 0.8420 - val_loss: 0.4675 - val_accuracy: 0.8474\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4653 - accuracy: 0.8416 - val_loss: 0.4675 - val_accuracy: 0.8472s - loss: 0.4561 - \n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4644 - accuracy: 0.8420 - val_loss: 0.4668 - val_accuracy: 0.8486\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4635 - accuracy: 0.8432 - val_loss: 0.4656 - val_accuracy: 0.8482\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4626 - accuracy: 0.8437 - val_loss: 0.4654 - val_accuracy: 0.8490\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4619 - accuracy: 0.8431 - val_loss: 0.4644 - val_accuracy: 0.8482\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4612 - accuracy: 0.8439 - val_loss: 0.4640 - val_accuracy: 0.8498\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4603 - accuracy: 0.8441 - val_loss: 0.4641 - val_accuracy: 0.8490\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4595 - accuracy: 0.8439 - val_loss: 0.4632 - val_accuracy: 0.8498\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4587 - accuracy: 0.8442 - val_loss: 0.4621 - val_accuracy: 0.8490\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4581 - accuracy: 0.8446 - val_loss: 0.4618 - val_accuracy: 0.8476\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4573 - accuracy: 0.8446 - val_loss: 0.4605 - val_accuracy: 0.8490\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4567 - accuracy: 0.8451 - val_loss: 0.4603 - val_accuracy: 0.8476\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4560 - accuracy: 0.8449 - val_loss: 0.4595 - val_accuracy: 0.8502\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4554 - accuracy: 0.8451 - val_loss: 0.4588 - val_accuracy: 0.8500\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4546 - accuracy: 0.8451 - val_loss: 0.4584 - val_accuracy: 0.8512\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4539 - accuracy: 0.8457 - val_loss: 0.4582 - val_accuracy: 0.8510\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4532 - accuracy: 0.8454 - val_loss: 0.4569 - val_accuracy: 0.8490\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4525 - accuracy: 0.8459 - val_loss: 0.4575 - val_accuracy: 0.8486\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4519 - accuracy: 0.8457 - val_loss: 0.4558 - val_accuracy: 0.8508loss: 0.4521 - accuracy - ETA: 0s - loss: 0.4477 - \n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4514 - accuracy: 0.8462 - val_loss: 0.4558 - val_accuracy: 0.8518\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4508 - accuracy: 0.8466 - val_loss: 0.4549 - val_accuracy: 0.8506\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4503 - accuracy: 0.8467 - val_loss: 0.4548 - val_accuracy: 0.8518\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4496 - accuracy: 0.8472 - val_loss: 0.4546 - val_accuracy: 0.8498\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4489 - accuracy: 0.8474 - val_loss: 0.4537 - val_accuracy: 0.8506\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4485 - accuracy: 0.8475 - val_loss: 0.4538 - val_accuracy: 0.8508\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4479 - accuracy: 0.8478 - val_loss: 0.4537 - val_accuracy: 0.8508\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4474 - accuracy: 0.8478 - val_loss: 0.4528 - val_accuracy: 0.8512\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4468 - accuracy: 0.8483 - val_loss: 0.4520 - val_accuracy: 0.8520\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4464 - accuracy: 0.8480 - val_loss: 0.4518 - val_accuracy: 0.8498\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4457 - accuracy: 0.8475 - val_loss: 0.4511 - val_accuracy: 0.8500\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4449 - accuracy: 0.8483 - val_loss: 0.4509 - val_accuracy: 0.8508\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4447 - accuracy: 0.8487 - val_loss: 0.4512 - val_accuracy: 0.8510\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4442 - accuracy: 0.8486 - val_loss: 0.4507 - val_accuracy: 0.8522\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4438 - accuracy: 0.8489 - val_loss: 0.4497 - val_accuracy: 0.8522\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4431 - accuracy: 0.8493 - val_loss: 0.4494 - val_accuracy: 0.8524\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4426 - accuracy: 0.8492 - val_loss: 0.4502 - val_accuracy: 0.8504\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4423 - accuracy: 0.8498 - val_loss: 0.4485 - val_accuracy: 0.8532\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4417 - accuracy: 0.8495 - val_loss: 0.4482 - val_accuracy: 0.8534\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 0.4534 - accuracy: 0.8485\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 1.4018 - accuracy: 0.5846 - val_loss: 1.0323 - val_accuracy: 0.6834\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.9466 - accuracy: 0.7000 - val_loss: 0.8566 - val_accuracy: 0.7266\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.8285 - accuracy: 0.7341 - val_loss: 0.7789 - val_accuracy: 0.7530\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.7657 - accuracy: 0.7566 - val_loss: 0.7276 - val_accuracy: 0.7726\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7237 - accuracy: 0.7703 - val_loss: 0.6953 - val_accuracy: 0.7794\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6936 - accuracy: 0.7802 - val_loss: 0.6689 - val_accuracy: 0.7902\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6698 - accuracy: 0.7886 - val_loss: 0.6486 - val_accuracy: 0.7978\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6506 - accuracy: 0.7937 - val_loss: 0.6316 - val_accuracy: 0.8028\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.6348 - accuracy: 0.7977 - val_loss: 0.6166 - val_accuracy: 0.8064\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.6211 - accuracy: 0.8022 - val_loss: 0.6062 - val_accuracy: 0.8096\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6095 - accuracy: 0.8056 - val_loss: 0.5956 - val_accuracy: 0.8096\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5993 - accuracy: 0.8079 - val_loss: 0.5862 - val_accuracy: 0.8164\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5903 - accuracy: 0.8099 - val_loss: 0.5779 - val_accuracy: 0.8166\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5822 - accuracy: 0.8119 - val_loss: 0.5706 - val_accuracy: 0.8172\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5749 - accuracy: 0.8145 - val_loss: 0.5631 - val_accuracy: 0.8220\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5681 - accuracy: 0.8157 - val_loss: 0.5587 - val_accuracy: 0.8236\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5620 - accuracy: 0.8179 - val_loss: 0.5517 - val_accuracy: 0.8262\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5567 - accuracy: 0.8189 - val_loss: 0.5470 - val_accuracy: 0.8276\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5515 - accuracy: 0.8204 - val_loss: 0.5435 - val_accuracy: 0.8290\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5468 - accuracy: 0.8216 - val_loss: 0.5394 - val_accuracy: 0.8308\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5422 - accuracy: 0.8226 - val_loss: 0.5346 - val_accuracy: 0.8306\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5382 - accuracy: 0.8248 - val_loss: 0.5309 - val_accuracy: 0.8328\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5345 - accuracy: 0.8253 - val_loss: 0.5272 - val_accuracy: 0.8348\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5308 - accuracy: 0.8263 - val_loss: 0.5244 - val_accuracy: 0.8358\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5273 - accuracy: 0.8266 - val_loss: 0.5221 - val_accuracy: 0.8356\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5242 - accuracy: 0.8283 - val_loss: 0.5179 - val_accuracy: 0.8364\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5211 - accuracy: 0.8297 - val_loss: 0.5161 - val_accuracy: 0.8368\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5183 - accuracy: 0.8298 - val_loss: 0.5136 - val_accuracy: 0.8372\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5156 - accuracy: 0.8300 - val_loss: 0.5102 - val_accuracy: 0.8378\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5130 - accuracy: 0.8307 - val_loss: 0.5080 - val_accuracy: 0.8390\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5104 - accuracy: 0.8318 - val_loss: 0.5084 - val_accuracy: 0.8366\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5081 - accuracy: 0.8324 - val_loss: 0.5039 - val_accuracy: 0.8394\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5059 - accuracy: 0.8322 - val_loss: 0.5016 - val_accuracy: 0.8400\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5035 - accuracy: 0.8337 - val_loss: 0.5001 - val_accuracy: 0.8396\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5016 - accuracy: 0.8346 - val_loss: 0.4977 - val_accuracy: 0.8416\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4997 - accuracy: 0.8352 - val_loss: 0.4965 - val_accuracy: 0.8414\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4978 - accuracy: 0.8351 - val_loss: 0.4941 - val_accuracy: 0.8430\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4958 - accuracy: 0.8355 - val_loss: 0.4927 - val_accuracy: 0.8420\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4941 - accuracy: 0.8360 - val_loss: 0.4927 - val_accuracy: 0.8406\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4922 - accuracy: 0.8361 - val_loss: 0.4922 - val_accuracy: 0.8410\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4907 - accuracy: 0.8370 - val_loss: 0.4892 - val_accuracy: 0.8430\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4891 - accuracy: 0.8372 - val_loss: 0.4868 - val_accuracy: 0.8426\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4876 - accuracy: 0.8372 - val_loss: 0.4859 - val_accuracy: 0.8428\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4861 - accuracy: 0.8379 - val_loss: 0.4848 - val_accuracy: 0.8430\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4846 - accuracy: 0.8381 - val_loss: 0.4834 - val_accuracy: 0.8440\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4833 - accuracy: 0.8388 - val_loss: 0.4828 - val_accuracy: 0.8432\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4819 - accuracy: 0.8390 - val_loss: 0.4816 - val_accuracy: 0.8432\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4806 - accuracy: 0.8398 - val_loss: 0.4805 - val_accuracy: 0.8422 accura\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4793 - accuracy: 0.8400 - val_loss: 0.4785 - val_accuracy: 0.8450\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4781 - accuracy: 0.8396 - val_loss: 0.4773 - val_accuracy: 0.8446\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4770 - accuracy: 0.8402 - val_loss: 0.4766 - val_accuracy: 0.8442\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4757 - accuracy: 0.8413 - val_loss: 0.4751 - val_accuracy: 0.8454\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4745 - accuracy: 0.8411 - val_loss: 0.4746 - val_accuracy: 0.8448\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4734 - accuracy: 0.8416 - val_loss: 0.4733 - val_accuracy: 0.8466\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4723 - accuracy: 0.8425 - val_loss: 0.4731 - val_accuracy: 0.8454\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4713 - accuracy: 0.8421 - val_loss: 0.4720 - val_accuracy: 0.8452\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4703 - accuracy: 0.8426 - val_loss: 0.4712 - val_accuracy: 0.8450\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4691 - accuracy: 0.8426 - val_loss: 0.4709 - val_accuracy: 0.8458\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4682 - accuracy: 0.8433 - val_loss: 0.4694 - val_accuracy: 0.8468\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4673 - accuracy: 0.8437 - val_loss: 0.4691 - val_accuracy: 0.8480\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4664 - accuracy: 0.8439 - val_loss: 0.4681 - val_accuracy: 0.8484\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4654 - accuracy: 0.8443 - val_loss: 0.4687 - val_accuracy: 0.8474\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4645 - accuracy: 0.8448 - val_loss: 0.4660 - val_accuracy: 0.8478\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4637 - accuracy: 0.8454 - val_loss: 0.4662 - val_accuracy: 0.8488\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4627 - accuracy: 0.8449 - val_loss: 0.4657 - val_accuracy: 0.8482\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4620 - accuracy: 0.8449 - val_loss: 0.4639 - val_accuracy: 0.8482\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4609 - accuracy: 0.8457 - val_loss: 0.4634 - val_accuracy: 0.8480\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4604 - accuracy: 0.8454 - val_loss: 0.4633 - val_accuracy: 0.8492\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4596 - accuracy: 0.8458 - val_loss: 0.4627 - val_accuracy: 0.8486\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4587 - accuracy: 0.8458 - val_loss: 0.4623 - val_accuracy: 0.8494\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4580 - accuracy: 0.8466 - val_loss: 0.4623 - val_accuracy: 0.8494\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4573 - accuracy: 0.8465 - val_loss: 0.4602 - val_accuracy: 0.8482\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4566 - accuracy: 0.8473 - val_loss: 0.4602 - val_accuracy: 0.8510\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4558 - accuracy: 0.8462 - val_loss: 0.4594 - val_accuracy: 0.8516\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4551 - accuracy: 0.8464 - val_loss: 0.4597 - val_accuracy: 0.8496\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4544 - accuracy: 0.8471 - val_loss: 0.4582 - val_accuracy: 0.8510\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4538 - accuracy: 0.8477 - val_loss: 0.4573 - val_accuracy: 0.8504\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4529 - accuracy: 0.8474 - val_loss: 0.4575 - val_accuracy: 0.8482\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4523 - accuracy: 0.8474 - val_loss: 0.4561 - val_accuracy: 0.8498\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4518 - accuracy: 0.8482 - val_loss: 0.4567 - val_accuracy: 0.8516\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4512 - accuracy: 0.8478 - val_loss: 0.4562 - val_accuracy: 0.8506\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4505 - accuracy: 0.8479 - val_loss: 0.4563 - val_accuracy: 0.8506\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4500 - accuracy: 0.8487 - val_loss: 0.4545 - val_accuracy: 0.8530\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4493 - accuracy: 0.8482 - val_loss: 0.4543 - val_accuracy: 0.8518\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4488 - accuracy: 0.8485 - val_loss: 0.4537 - val_accuracy: 0.8540\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4482 - accuracy: 0.8488 - val_loss: 0.4537 - val_accuracy: 0.8516\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4476 - accuracy: 0.8490 - val_loss: 0.4524 - val_accuracy: 0.8542\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4470 - accuracy: 0.8492 - val_loss: 0.4522 - val_accuracy: 0.8510\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4465 - accuracy: 0.8496 - val_loss: 0.4534 - val_accuracy: 0.8518\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4460 - accuracy: 0.8493 - val_loss: 0.4519 - val_accuracy: 0.8510\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4454 - accuracy: 0.8500 - val_loss: 0.4529 - val_accuracy: 0.8522\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4449 - accuracy: 0.8499 - val_loss: 0.4506 - val_accuracy: 0.8526\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4443 - accuracy: 0.8500 - val_loss: 0.4503 - val_accuracy: 0.8548\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4439 - accuracy: 0.8506 - val_loss: 0.4495 - val_accuracy: 0.8538\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4433 - accuracy: 0.8507 - val_loss: 0.4505 - val_accuracy: 0.8508\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4429 - accuracy: 0.8504 - val_loss: 0.4495 - val_accuracy: 0.8534\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4423 - accuracy: 0.8504 - val_loss: 0.4489 - val_accuracy: 0.8530\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4418 - accuracy: 0.8509 - val_loss: 0.4477 - val_accuracy: 0.8532\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4414 - accuracy: 0.8511 - val_loss: 0.4479 - val_accuracy: 0.8556\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4410 - accuracy: 0.8506 - val_loss: 0.4476 - val_accuracy: 0.8554\n",
      "18333/18333 [==============================] - 0s 20us/sample - loss: 0.4544 - accuracy: 0.8449\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.6838 - accuracy: 0.5180 - val_loss: 1.2790 - val_accuracy: 0.6608\n",
      "Epoch 2/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 1.1419 - accuracy: 0.6739 - val_loss: 1.0248 - val_accuracy: 0.6884\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.9736 - accuracy: 0.7000 - val_loss: 0.9123 - val_accuracy: 0.7124\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.8875 - accuracy: 0.7205 - val_loss: 0.8457 - val_accuracy: 0.7296\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.8324 - accuracy: 0.7368 - val_loss: 0.8012 - val_accuracy: 0.7432\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.7930 - accuracy: 0.7488 - val_loss: 0.7675 - val_accuracy: 0.7576\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.7628 - accuracy: 0.7568 - val_loss: 0.7404 - val_accuracy: 0.7680\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.7386 - accuracy: 0.7647 - val_loss: 0.7191 - val_accuracy: 0.7718\n",
      "Epoch 9/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.7184 - accuracy: 0.7715 - val_loss: 0.7016 - val_accuracy: 0.7828\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.7014 - accuracy: 0.7778 - val_loss: 0.6862 - val_accuracy: 0.7860- loss: 0.7019 - accura\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.6867 - accuracy: 0.7829 - val_loss: 0.6730 - val_accuracy: 0.7900\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.6740 - accuracy: 0.7868 - val_loss: 0.6605 - val_accuracy: 0.7956\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.6626 - accuracy: 0.7902 - val_loss: 0.6501 - val_accuracy: 0.7980\n",
      "Epoch 14/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.6524 - accuracy: 0.7942 - val_loss: 0.6415 - val_accuracy: 0.7998\n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.6432 - accuracy: 0.7959 - val_loss: 0.6320 - val_accuracy: 0.8012\n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.6349 - accuracy: 0.7980 - val_loss: 0.6250 - val_accuracy: 0.8052\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.6273 - accuracy: 0.8006 - val_loss: 0.6180 - val_accuracy: 0.8060ss: 0.6287 - accu\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.6203 - accuracy: 0.8021 - val_loss: 0.6111 - val_accuracy: 0.8092\n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.6139 - accuracy: 0.8042 - val_loss: 0.6048 - val_accuracy: 0.8094\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.6078 - accuracy: 0.8053 - val_loss: 0.5998 - val_accuracy: 0.8106\n",
      "Epoch 21/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.6024 - accuracy: 0.8072 - val_loss: 0.5951 - val_accuracy: 0.8120\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5972 - accuracy: 0.8083 - val_loss: 0.5899 - val_accuracy: 0.8124\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5923 - accuracy: 0.8094 - val_loss: 0.5849 - val_accuracy: 0.8154\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5878 - accuracy: 0.8108 - val_loss: 0.5811 - val_accuracy: 0.8164\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5834 - accuracy: 0.8125 - val_loss: 0.5761 - val_accuracy: 0.8160\n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5795 - accuracy: 0.8127 - val_loss: 0.5730 - val_accuracy: 0.8176\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5755 - accuracy: 0.8144 - val_loss: 0.5686 - val_accuracy: 0.8186\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5719 - accuracy: 0.8148 - val_loss: 0.5665 - val_accuracy: 0.8204\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5684 - accuracy: 0.8160 - val_loss: 0.5632 - val_accuracy: 0.8200\n",
      "Epoch 30/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5652 - accuracy: 0.8166 - val_loss: 0.5595 - val_accuracy: 0.8230\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5620 - accuracy: 0.8172 - val_loss: 0.5561 - val_accuracy: 0.8228\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5590 - accuracy: 0.8184 - val_loss: 0.5543 - val_accuracy: 0.8236\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5562 - accuracy: 0.8197 - val_loss: 0.5506 - val_accuracy: 0.8236\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5534 - accuracy: 0.8201 - val_loss: 0.5485 - val_accuracy: 0.8250\n",
      "Epoch 35/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5507 - accuracy: 0.8211 - val_loss: 0.5458 - val_accuracy: 0.8252\n",
      "Epoch 36/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5482 - accuracy: 0.8214 - val_loss: 0.5434 - val_accuracy: 0.8264\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5457 - accuracy: 0.8220 - val_loss: 0.5409 - val_accuracy: 0.8266\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5435 - accuracy: 0.8226 - val_loss: 0.5391 - val_accuracy: 0.8266\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5412 - accuracy: 0.8232 - val_loss: 0.5367 - val_accuracy: 0.8276\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5388 - accuracy: 0.8245 - val_loss: 0.5358 - val_accuracy: 0.8272\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5369 - accuracy: 0.8243 - val_loss: 0.5329 - val_accuracy: 0.8278\n",
      "Epoch 42/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5349 - accuracy: 0.8248 - val_loss: 0.5309 - val_accuracy: 0.8278\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5329 - accuracy: 0.8258 - val_loss: 0.5293 - val_accuracy: 0.8290\n",
      "Epoch 44/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5311 - accuracy: 0.8264 - val_loss: 0.5277 - val_accuracy: 0.8298\n",
      "Epoch 45/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5292 - accuracy: 0.8271 - val_loss: 0.5258 - val_accuracy: 0.8318\n",
      "Epoch 46/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5274 - accuracy: 0.8268 - val_loss: 0.5243 - val_accuracy: 0.8314- loss: 0.529\n",
      "Epoch 47/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5257 - accuracy: 0.8275 - val_loss: 0.5226 - val_accuracy: 0.8322\n",
      "Epoch 48/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5240 - accuracy: 0.8279 - val_loss: 0.5210 - val_accuracy: 0.8324\n",
      "Epoch 49/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5224 - accuracy: 0.8287 - val_loss: 0.5194 - val_accuracy: 0.8328y: 0.\n",
      "Epoch 50/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5207 - accuracy: 0.8291 - val_loss: 0.5187 - val_accuracy: 0.8324\n",
      "Epoch 51/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5192 - accuracy: 0.8291 - val_loss: 0.5162 - val_accuracy: 0.8324\n",
      "Epoch 52/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5178 - accuracy: 0.8305 - val_loss: 0.5146 - val_accuracy: 0.8336\n",
      "Epoch 53/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5163 - accuracy: 0.8303 - val_loss: 0.5136 - val_accuracy: 0.8334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5148 - accuracy: 0.8310 - val_loss: 0.5121 - val_accuracy: 0.8332\n",
      "Epoch 55/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5135 - accuracy: 0.8309 - val_loss: 0.5114 - val_accuracy: 0.8324\n",
      "Epoch 56/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5121 - accuracy: 0.8310 - val_loss: 0.5096 - val_accuracy: 0.8350\n",
      "Epoch 57/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5108 - accuracy: 0.8323 - val_loss: 0.5091 - val_accuracy: 0.8354\n",
      "Epoch 58/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5095 - accuracy: 0.8323 - val_loss: 0.5078 - val_accuracy: 0.8342\n",
      "Epoch 59/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5083 - accuracy: 0.8322 - val_loss: 0.5061 - val_accuracy: 0.8366\n",
      "Epoch 60/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5071 - accuracy: 0.8330 - val_loss: 0.5048 - val_accuracy: 0.8354\n",
      "Epoch 61/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5059 - accuracy: 0.8331 - val_loss: 0.5041 - val_accuracy: 0.8374\n",
      "Epoch 62/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5047 - accuracy: 0.8332 - val_loss: 0.5029 - val_accuracy: 0.8364\n",
      "Epoch 63/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5035 - accuracy: 0.8339 - val_loss: 0.5017 - val_accuracy: 0.8364\n",
      "Epoch 64/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5024 - accuracy: 0.8336 - val_loss: 0.5011 - val_accuracy: 0.8364\n",
      "Epoch 65/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5014 - accuracy: 0.8342 - val_loss: 0.4997 - val_accuracy: 0.8366\n",
      "Epoch 66/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5002 - accuracy: 0.8349 - val_loss: 0.4987 - val_accuracy: 0.8376\n",
      "Epoch 67/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4992 - accuracy: 0.8350 - val_loss: 0.4979 - val_accuracy: 0.8356\n",
      "Epoch 68/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4982 - accuracy: 0.8354 - val_loss: 0.4971 - val_accuracy: 0.8378\n",
      "Epoch 69/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4972 - accuracy: 0.8349 - val_loss: 0.4965 - val_accuracy: 0.8378\n",
      "Epoch 70/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4961 - accuracy: 0.8362 - val_loss: 0.4955 - val_accuracy: 0.8382\n",
      "Epoch 71/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4952 - accuracy: 0.8357 - val_loss: 0.4942 - val_accuracy: 0.8388\n",
      "Epoch 72/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4943 - accuracy: 0.8364 - val_loss: 0.4936 - val_accuracy: 0.8402\n",
      "Epoch 73/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4934 - accuracy: 0.8366 - val_loss: 0.4932 - val_accuracy: 0.8382\n",
      "Epoch 74/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4925 - accuracy: 0.8372 - val_loss: 0.4926 - val_accuracy: 0.8400\n",
      "Epoch 75/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4916 - accuracy: 0.8369 - val_loss: 0.4912 - val_accuracy: 0.8398\n",
      "Epoch 76/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4906 - accuracy: 0.8369 - val_loss: 0.4912 - val_accuracy: 0.8398\n",
      "Epoch 77/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4898 - accuracy: 0.8380 - val_loss: 0.4899 - val_accuracy: 0.8418\n",
      "Epoch 78/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4890 - accuracy: 0.8369 - val_loss: 0.4886 - val_accuracy: 0.8406\n",
      "Epoch 79/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4881 - accuracy: 0.8385 - val_loss: 0.4884 - val_accuracy: 0.8408\n",
      "Epoch 80/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4873 - accuracy: 0.8384 - val_loss: 0.4883 - val_accuracy: 0.8412\n",
      "Epoch 81/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4865 - accuracy: 0.8386 - val_loss: 0.4868 - val_accuracy: 0.8412\n",
      "Epoch 82/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4857 - accuracy: 0.8392 - val_loss: 0.4867 - val_accuracy: 0.8414\n",
      "Epoch 83/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4850 - accuracy: 0.8390 - val_loss: 0.4852 - val_accuracy: 0.8422\n",
      "Epoch 84/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4841 - accuracy: 0.8395 - val_loss: 0.4846 - val_accuracy: 0.8424\n",
      "Epoch 85/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4835 - accuracy: 0.8394 - val_loss: 0.4840 - val_accuracy: 0.8420\n",
      "Epoch 86/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4827 - accuracy: 0.8396 - val_loss: 0.4831 - val_accuracy: 0.8422\n",
      "Epoch 87/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4819 - accuracy: 0.8397 - val_loss: 0.4832 - val_accuracy: 0.8426\n",
      "Epoch 88/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4812 - accuracy: 0.8401 - val_loss: 0.4825 - val_accuracy: 0.8414\n",
      "Epoch 89/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4805 - accuracy: 0.8403 - val_loss: 0.4811 - val_accuracy: 0.8428\n",
      "Epoch 90/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4799 - accuracy: 0.8402 - val_loss: 0.4809 - val_accuracy: 0.8428\n",
      "Epoch 91/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4792 - accuracy: 0.8411 - val_loss: 0.4805 - val_accuracy: 0.8422\n",
      "Epoch 92/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4785 - accuracy: 0.8405 - val_loss: 0.4794 - val_accuracy: 0.8430\n",
      "Epoch 93/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4778 - accuracy: 0.8411 - val_loss: 0.4790 - val_accuracy: 0.8438\n",
      "Epoch 94/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4772 - accuracy: 0.8414 - val_loss: 0.4787 - val_accuracy: 0.8438\n",
      "Epoch 95/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4766 - accuracy: 0.8415 - val_loss: 0.4776 - val_accuracy: 0.8426\n",
      "Epoch 96/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4759 - accuracy: 0.8420 - val_loss: 0.4775 - val_accuracy: 0.8440\n",
      "Epoch 97/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4753 - accuracy: 0.8420 - val_loss: 0.4767 - val_accuracy: 0.8448\n",
      "Epoch 98/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4746 - accuracy: 0.8420 - val_loss: 0.4761 - val_accuracy: 0.8442\n",
      "Epoch 99/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4741 - accuracy: 0.8426 - val_loss: 0.4757 - val_accuracy: 0.8452\n",
      "Epoch 100/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4735 - accuracy: 0.8423 - val_loss: 0.4753 - val_accuracy: 0.8454\n",
      "18334/18334 [==============================] - 0s 22us/sample - loss: 0.4900 - accuracy: 0.8334\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.6658 - accuracy: 0.5080 - val_loss: 1.2837 - val_accuracy: 0.6468\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 1.1531 - accuracy: 0.6602 - val_loss: 1.0378 - val_accuracy: 0.6792\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.9895 - accuracy: 0.6870 - val_loss: 0.9271 - val_accuracy: 0.7068\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.9040 - accuracy: 0.7074 - val_loss: 0.8607 - val_accuracy: 0.7276\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.8490 - accuracy: 0.7231 - val_loss: 0.8153 - val_accuracy: 0.7414\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.8091 - accuracy: 0.7361 - val_loss: 0.7803 - val_accuracy: 0.7506\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.7786 - accuracy: 0.7462 - val_loss: 0.7543 - val_accuracy: 0.7600\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.7540 - accuracy: 0.7545 - val_loss: 0.7315 - val_accuracy: 0.7664\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.7334 - accuracy: 0.7613 - val_loss: 0.7132 - val_accuracy: 0.7746\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.7160 - accuracy: 0.7679 - val_loss: 0.6973 - val_accuracy: 0.7788\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7010 - accuracy: 0.7722 - val_loss: 0.6837 - val_accuracy: 0.7834\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6877 - accuracy: 0.7770 - val_loss: 0.6722 - val_accuracy: 0.7844\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6761 - accuracy: 0.7801 - val_loss: 0.6610 - val_accuracy: 0.7898\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6654 - accuracy: 0.7838 - val_loss: 0.6509 - val_accuracy: 0.7956\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6559 - accuracy: 0.7878 - val_loss: 0.6422 - val_accuracy: 0.7968\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6474 - accuracy: 0.7900 - val_loss: 0.6341 - val_accuracy: 0.8006\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6393 - accuracy: 0.7934 - val_loss: 0.6277 - val_accuracy: 0.7998\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6321 - accuracy: 0.7955 - val_loss: 0.6199 - val_accuracy: 0.8062\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6253 - accuracy: 0.7975 - val_loss: 0.6139 - val_accuracy: 0.8078\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6191 - accuracy: 0.7998 - val_loss: 0.6080 - val_accuracy: 0.8108\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6133 - accuracy: 0.8009 - val_loss: 0.6021 - val_accuracy: 0.8120\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.6078 - accuracy: 0.8024 - val_loss: 0.5968 - val_accuracy: 0.8134\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.6028 - accuracy: 0.8036 - val_loss: 0.5930 - val_accuracy: 0.8138\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5980 - accuracy: 0.8048 - val_loss: 0.5879 - val_accuracy: 0.8152\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5935 - accuracy: 0.8067 - val_loss: 0.5839 - val_accuracy: 0.8160\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5891 - accuracy: 0.8083 - val_loss: 0.5795 - val_accuracy: 0.8170\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5852 - accuracy: 0.8084 - val_loss: 0.5758 - val_accuracy: 0.8176\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5814 - accuracy: 0.8107 - val_loss: 0.5724 - val_accuracy: 0.8186\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5777 - accuracy: 0.8109 - val_loss: 0.5689 - val_accuracy: 0.8188\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5742 - accuracy: 0.8122 - val_loss: 0.5655 - val_accuracy: 0.8208\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5709 - accuracy: 0.8130 - val_loss: 0.5625 - val_accuracy: 0.8214\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5677 - accuracy: 0.8143 - val_loss: 0.5600 - val_accuracy: 0.8226\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5648 - accuracy: 0.8154 - val_loss: 0.5568 - val_accuracy: 0.8220\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5619 - accuracy: 0.8161 - val_loss: 0.5540 - val_accuracy: 0.8228\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5591 - accuracy: 0.8170 - val_loss: 0.5517 - val_accuracy: 0.8238\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5564 - accuracy: 0.8165 - val_loss: 0.5491 - val_accuracy: 0.8264\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5539 - accuracy: 0.8178 - val_loss: 0.5474 - val_accuracy: 0.8260\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5514 - accuracy: 0.8187 - val_loss: 0.5445 - val_accuracy: 0.8256\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5491 - accuracy: 0.8196 - val_loss: 0.5423 - val_accuracy: 0.8274\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5468 - accuracy: 0.8207 - val_loss: 0.5404 - val_accuracy: 0.8290\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5445 - accuracy: 0.8204 - val_loss: 0.5384 - val_accuracy: 0.8292\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5424 - accuracy: 0.8217 - val_loss: 0.5361 - val_accuracy: 0.8292\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5403 - accuracy: 0.8215 - val_loss: 0.5342 - val_accuracy: 0.8294\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5383 - accuracy: 0.8226 - val_loss: 0.5323 - val_accuracy: 0.8308\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5364 - accuracy: 0.8229 - val_loss: 0.5303 - val_accuracy: 0.8310s - loss: 0.5370 - ac\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5345 - accuracy: 0.8229 - val_loss: 0.5290 - val_accuracy: 0.8326\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5326 - accuracy: 0.8237 - val_loss: 0.5272 - val_accuracy: 0.8322\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5310 - accuracy: 0.8248 - val_loss: 0.5252 - val_accuracy: 0.8310\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5292 - accuracy: 0.8249 - val_loss: 0.5237 - val_accuracy: 0.8314\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5276 - accuracy: 0.8253 - val_loss: 0.5224 - val_accuracy: 0.8314\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5260 - accuracy: 0.8256 - val_loss: 0.5211 - val_accuracy: 0.8336\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5244 - accuracy: 0.8262 - val_loss: 0.5195 - val_accuracy: 0.8320\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5229 - accuracy: 0.8262 - val_loss: 0.5182 - val_accuracy: 0.8342\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5215 - accuracy: 0.8266 - val_loss: 0.5168 - val_accuracy: 0.8328\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5200 - accuracy: 0.8273 - val_loss: 0.5155 - val_accuracy: 0.8328\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5185 - accuracy: 0.8272 - val_loss: 0.5145 - val_accuracy: 0.834488 - accuracy: 0.\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5172 - accuracy: 0.8277 - val_loss: 0.5126 - val_accuracy: 0.8350\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5159 - accuracy: 0.8279 - val_loss: 0.5113 - val_accuracy: 0.8352\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5146 - accuracy: 0.8282 - val_loss: 0.5105 - val_accuracy: 0.8344\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5133 - accuracy: 0.8286 - val_loss: 0.5089 - val_accuracy: 0.8364\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5120 - accuracy: 0.8290 - val_loss: 0.5078 - val_accuracy: 0.8352ss: 0.5131 - ac\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5108 - accuracy: 0.8289 - val_loss: 0.5070 - val_accuracy: 0.8366\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5096 - accuracy: 0.8292 - val_loss: 0.5058 - val_accuracy: 0.8368\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5084 - accuracy: 0.8301 - val_loss: 0.5049 - val_accuracy: 0.8354\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5074 - accuracy: 0.8301 - val_loss: 0.5041 - val_accuracy: 0.8352\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5062 - accuracy: 0.8306 - val_loss: 0.5030 - val_accuracy: 0.8358\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5051 - accuracy: 0.8304 - val_loss: 0.5026 - val_accuracy: 0.8358ss: 0.5052 - ac\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5041 - accuracy: 0.8309 - val_loss: 0.5010 - val_accuracy: 0.8370\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5031 - accuracy: 0.8319 - val_loss: 0.4998 - val_accuracy: 0.8374\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5019 - accuracy: 0.8316 - val_loss: 0.4986 - val_accuracy: 0.8374\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5010 - accuracy: 0.8317 - val_loss: 0.4981 - val_accuracy: 0.8372\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5000 - accuracy: 0.8323 - val_loss: 0.4973 - val_accuracy: 0.8378\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4991 - accuracy: 0.8321 - val_loss: 0.4963 - val_accuracy: 0.8384\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4981 - accuracy: 0.8327 - val_loss: 0.4955 - val_accuracy: 0.8358\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4971 - accuracy: 0.8334 - val_loss: 0.4948 - val_accuracy: 0.8374\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4963 - accuracy: 0.8333 - val_loss: 0.4940 - val_accuracy: 0.8384\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4954 - accuracy: 0.8336 - val_loss: 0.4927 - val_accuracy: 0.8374\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4945 - accuracy: 0.8330 - val_loss: 0.4921 - val_accuracy: 0.8376\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4936 - accuracy: 0.8336 - val_loss: 0.4918 - val_accuracy: 0.8390\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4928 - accuracy: 0.8338 - val_loss: 0.4907 - val_accuracy: 0.8386\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4920 - accuracy: 0.8342 - val_loss: 0.4902 - val_accuracy: 0.8392\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4912 - accuracy: 0.8338 - val_loss: 0.4895 - val_accuracy: 0.8386\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4904 - accuracy: 0.8343 - val_loss: 0.4888 - val_accuracy: 0.8402\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4895 - accuracy: 0.8350 - val_loss: 0.4877 - val_accuracy: 0.8392\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4887 - accuracy: 0.8354 - val_loss: 0.4872 - val_accuracy: 0.8412\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4881 - accuracy: 0.8357 - val_loss: 0.4862 - val_accuracy: 0.8400\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4873 - accuracy: 0.8363 - val_loss: 0.4857 - val_accuracy: 0.8402\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4865 - accuracy: 0.8359 - val_loss: 0.4849 - val_accuracy: 0.8414\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4858 - accuracy: 0.8369 - val_loss: 0.4851 - val_accuracy: 0.8404\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4851 - accuracy: 0.8370 - val_loss: 0.4836 - val_accuracy: 0.8414\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4844 - accuracy: 0.8367 - val_loss: 0.4830 - val_accuracy: 0.8408\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4836 - accuracy: 0.8368 - val_loss: 0.4829 - val_accuracy: 0.8402\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4830 - accuracy: 0.8374 - val_loss: 0.4820 - val_accuracy: 0.8414\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4823 - accuracy: 0.8375 - val_loss: 0.4810 - val_accuracy: 0.8408\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4816 - accuracy: 0.8379 - val_loss: 0.4810 - val_accuracy: 0.8412\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4809 - accuracy: 0.8377 - val_loss: 0.4802 - val_accuracy: 0.8412\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4803 - accuracy: 0.8383 - val_loss: 0.4797 - val_accuracy: 0.8422\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4797 - accuracy: 0.8388 - val_loss: 0.4790 - val_accuracy: 0.8412\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4790 - accuracy: 0.8388 - val_loss: 0.4790 - val_accuracy: 0.8416\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4785 - accuracy: 0.8385 - val_loss: 0.4783 - val_accuracy: 0.8428\n",
      "18333/18333 [==============================] - 0s 19us/sample - loss: 0.4844 - accuracy: 0.8396\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.6077 - accuracy: 0.5095 - val_loss: 1.2546 - val_accuracy: 0.6540\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 1.1387 - accuracy: 0.6632 - val_loss: 1.0223 - val_accuracy: 0.6866\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.9811 - accuracy: 0.6915 - val_loss: 0.9142 - val_accuracy: 0.7156\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.8973 - accuracy: 0.7120 - val_loss: 0.8490 - val_accuracy: 0.7310\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.8429 - accuracy: 0.7293 - val_loss: 0.8042 - val_accuracy: 0.7454\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.8034 - accuracy: 0.7417 - val_loss: 0.7708 - val_accuracy: 0.7572\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7728 - accuracy: 0.7515 - val_loss: 0.7451 - val_accuracy: 0.7656\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.7485 - accuracy: 0.7597 - val_loss: 0.7222 - val_accuracy: 0.7750\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.7281 - accuracy: 0.7669 - val_loss: 0.7047 - val_accuracy: 0.7786\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.7108 - accuracy: 0.7728 - val_loss: 0.6888 - val_accuracy: 0.7828\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.6957 - accuracy: 0.7779 - val_loss: 0.6753 - val_accuracy: 0.7856\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.6826 - accuracy: 0.7827 - val_loss: 0.6635 - val_accuracy: 0.7908\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6708 - accuracy: 0.7868 - val_loss: 0.6533 - val_accuracy: 0.7918\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6605 - accuracy: 0.7893 - val_loss: 0.6436 - val_accuracy: 0.7972\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6510 - accuracy: 0.7923 - val_loss: 0.6346 - val_accuracy: 0.7990\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6424 - accuracy: 0.7950 - val_loss: 0.6270 - val_accuracy: 0.8002\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6346 - accuracy: 0.7974 - val_loss: 0.6192 - val_accuracy: 0.8020\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.6274 - accuracy: 0.7994 - val_loss: 0.6129 - val_accuracy: 0.8050\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6207 - accuracy: 0.8014 - val_loss: 0.6072 - val_accuracy: 0.8056\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.6146 - accuracy: 0.8031 - val_loss: 0.6015 - val_accuracy: 0.8086\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6087 - accuracy: 0.8050 - val_loss: 0.5965 - val_accuracy: 0.8108\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.6035 - accuracy: 0.8063 - val_loss: 0.5910 - val_accuracy: 0.8102\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5983 - accuracy: 0.8076 - val_loss: 0.5867 - val_accuracy: 0.8140\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5937 - accuracy: 0.8094 - val_loss: 0.5819 - val_accuracy: 0.8142\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5891 - accuracy: 0.8109 - val_loss: 0.5789 - val_accuracy: 0.8152\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5849 - accuracy: 0.8118 - val_loss: 0.5738 - val_accuracy: 0.8166\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5810 - accuracy: 0.8130 - val_loss: 0.5702 - val_accuracy: 0.8174\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5771 - accuracy: 0.8134 - val_loss: 0.5672 - val_accuracy: 0.8170\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5736 - accuracy: 0.8150 - val_loss: 0.5635 - val_accuracy: 0.8196\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5702 - accuracy: 0.8147 - val_loss: 0.5609 - val_accuracy: 0.8200\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5668 - accuracy: 0.8165 - val_loss: 0.5574 - val_accuracy: 0.8216\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5638 - accuracy: 0.8165 - val_loss: 0.5547 - val_accuracy: 0.8216\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5608 - accuracy: 0.8180 - val_loss: 0.5523 - val_accuracy: 0.8232\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5580 - accuracy: 0.8186 - val_loss: 0.5496 - val_accuracy: 0.8236\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5552 - accuracy: 0.8185 - val_loss: 0.5468 - val_accuracy: 0.8248\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5527 - accuracy: 0.8198 - val_loss: 0.5445 - val_accuracy: 0.8264\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5501 - accuracy: 0.8202 - val_loss: 0.5423 - val_accuracy: 0.8272\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5476 - accuracy: 0.8212 - val_loss: 0.5403 - val_accuracy: 0.8260\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5452 - accuracy: 0.8216 - val_loss: 0.5371 - val_accuracy: 0.8284\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5431 - accuracy: 0.8235 - val_loss: 0.5353 - val_accuracy: 0.8292\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5409 - accuracy: 0.8231 - val_loss: 0.5340 - val_accuracy: 0.8282\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5389 - accuracy: 0.8230 - val_loss: 0.5318 - val_accuracy: 0.8298\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5369 - accuracy: 0.8241 - val_loss: 0.5309 - val_accuracy: 0.8292\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5349 - accuracy: 0.8243 - val_loss: 0.5279 - val_accuracy: 0.8320\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5331 - accuracy: 0.8251 - val_loss: 0.5266 - val_accuracy: 0.8310\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5312 - accuracy: 0.8253 - val_loss: 0.5249 - val_accuracy: 0.8314\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5294 - accuracy: 0.8265 - val_loss: 0.5239 - val_accuracy: 0.8310\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5277 - accuracy: 0.8265 - val_loss: 0.5219 - val_accuracy: 0.8314\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5260 - accuracy: 0.8271 - val_loss: 0.5199 - val_accuracy: 0.8332\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5244 - accuracy: 0.8275 - val_loss: 0.5186 - val_accuracy: 0.8338\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5229 - accuracy: 0.8281 - val_loss: 0.5170 - val_accuracy: 0.8342\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5212 - accuracy: 0.8275 - val_loss: 0.5157 - val_accuracy: 0.8332\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5198 - accuracy: 0.8283 - val_loss: 0.5145 - val_accuracy: 0.8334\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5184 - accuracy: 0.8292 - val_loss: 0.5135 - val_accuracy: 0.8344\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5169 - accuracy: 0.8294 - val_loss: 0.5122 - val_accuracy: 0.8346\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5156 - accuracy: 0.8292 - val_loss: 0.5107 - val_accuracy: 0.8350\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5143 - accuracy: 0.8300 - val_loss: 0.5095 - val_accuracy: 0.8356\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5128 - accuracy: 0.8302 - val_loss: 0.5086 - val_accuracy: 0.8352\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5116 - accuracy: 0.8306 - val_loss: 0.5080 - val_accuracy: 0.8346\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5104 - accuracy: 0.8311 - val_loss: 0.5065 - val_accuracy: 0.8358\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5092 - accuracy: 0.8316 - val_loss: 0.5053 - val_accuracy: 0.8366\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5080 - accuracy: 0.8313 - val_loss: 0.5042 - val_accuracy: 0.8376\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5067 - accuracy: 0.8321 - val_loss: 0.5029 - val_accuracy: 0.8370\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5056 - accuracy: 0.8319 - val_loss: 0.5020 - val_accuracy: 0.8376\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5045 - accuracy: 0.8321 - val_loss: 0.5014 - val_accuracy: 0.8362- loss: 0.5050 - accuracy: \n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5035 - accuracy: 0.8324 - val_loss: 0.4999 - val_accuracy: 0.8384\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5024 - accuracy: 0.8321 - val_loss: 0.4992 - val_accuracy: 0.8380\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5014 - accuracy: 0.8326 - val_loss: 0.4979 - val_accuracy: 0.8386\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5004 - accuracy: 0.8337 - val_loss: 0.4974 - val_accuracy: 0.8382\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4994 - accuracy: 0.8335 - val_loss: 0.4964 - val_accuracy: 0.8384\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4983 - accuracy: 0.8345 - val_loss: 0.4950 - val_accuracy: 0.8398\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4974 - accuracy: 0.8339 - val_loss: 0.4947 - val_accuracy: 0.8394\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4963 - accuracy: 0.8346 - val_loss: 0.4937 - val_accuracy: 0.8402\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4953 - accuracy: 0.8346 - val_loss: 0.4926 - val_accuracy: 0.8404\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4946 - accuracy: 0.8347 - val_loss: 0.4923 - val_accuracy: 0.8394\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4937 - accuracy: 0.8353 - val_loss: 0.4915 - val_accuracy: 0.8394\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4928 - accuracy: 0.8357 - val_loss: 0.4907 - val_accuracy: 0.8400\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4920 - accuracy: 0.8353 - val_loss: 0.4899 - val_accuracy: 0.8406\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - ETA: 0s - loss: 0.4917 - accuracy: 0.83 - 1s 29us/sample - loss: 0.4911 - accuracy: 0.8361 - val_loss: 0.4891 - val_accuracy: 0.8406\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4904 - accuracy: 0.8361 - val_loss: 0.4883 - val_accuracy: 0.8402\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4895 - accuracy: 0.8366 - val_loss: 0.4878 - val_accuracy: 0.8412\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4887 - accuracy: 0.8369 - val_loss: 0.4874 - val_accuracy: 0.8396\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4879 - accuracy: 0.8365 - val_loss: 0.4865 - val_accuracy: 0.8402\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4872 - accuracy: 0.8370 - val_loss: 0.4855 - val_accuracy: 0.8410\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4864 - accuracy: 0.8371 - val_loss: 0.4847 - val_accuracy: 0.8416\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4857 - accuracy: 0.8376 - val_loss: 0.4844 - val_accuracy: 0.8412\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4848 - accuracy: 0.8378 - val_loss: 0.4841 - val_accuracy: 0.8420\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4843 - accuracy: 0.8382 - val_loss: 0.4832 - val_accuracy: 0.8412\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4835 - accuracy: 0.8386 - val_loss: 0.4824 - val_accuracy: 0.8414\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4828 - accuracy: 0.8383 - val_loss: 0.4814 - val_accuracy: 0.8432\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4821 - accuracy: 0.8384 - val_loss: 0.4813 - val_accuracy: 0.8418\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4813 - accuracy: 0.8387 - val_loss: 0.4809 - val_accuracy: 0.8408\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4807 - accuracy: 0.8388 - val_loss: 0.4798 - val_accuracy: 0.8420\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4801 - accuracy: 0.8392 - val_loss: 0.4795 - val_accuracy: 0.8430\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4795 - accuracy: 0.8394 - val_loss: 0.4787 - val_accuracy: 0.8428\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4788 - accuracy: 0.8394 - val_loss: 0.4785 - val_accuracy: 0.8422\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4782 - accuracy: 0.8394 - val_loss: 0.4773 - val_accuracy: 0.8434\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4775 - accuracy: 0.8398 - val_loss: 0.4771 - val_accuracy: 0.8454\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4770 - accuracy: 0.8396 - val_loss: 0.4765 - val_accuracy: 0.8436\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4763 - accuracy: 0.8399 - val_loss: 0.4762 - val_accuracy: 0.8438\n",
      "18333/18333 [==============================] - 0s 18us/sample - loss: 0.4846 - accuracy: 0.8361\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 2.1468 - accuracy: 0.2494 - val_loss: 1.9956 - val_accuracy: 0.3286\n",
      "Epoch 2/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 1.8773 - accuracy: 0.3871 - val_loss: 1.7585 - val_accuracy: 0.4396\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 1.6575 - accuracy: 0.4831 - val_loss: 1.5518 - val_accuracy: 0.5294\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 1.4702 - accuracy: 0.5559 - val_loss: 1.3765 - val_accuracy: 0.5836\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 1.3115 - accuracy: 0.5979 - val_loss: 1.2365 - val_accuracy: 0.6178\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 1.1946 - accuracy: 0.6278 - val_loss: 1.1388 - val_accuracy: 0.6474\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 1.1110 - accuracy: 0.6519 - val_loss: 1.0676 - val_accuracy: 0.6708\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 1.0485 - accuracy: 0.6687 - val_loss: 1.0130 - val_accuracy: 0.6864\n",
      "Epoch 9/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.9994 - accuracy: 0.6822 - val_loss: 0.9692 - val_accuracy: 0.6932\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.9595 - accuracy: 0.6936 - val_loss: 0.9329 - val_accuracy: 0.7004\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.9261 - accuracy: 0.7024 - val_loss: 0.9027 - val_accuracy: 0.7106\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.8973 - accuracy: 0.7094 - val_loss: 0.8760 - val_accuracy: 0.7178\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.8722 - accuracy: 0.7177 - val_loss: 0.8528 - val_accuracy: 0.7230\n",
      "Epoch 14/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.8500 - accuracy: 0.7246 - val_loss: 0.8318 - val_accuracy: 0.7294\n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.8300 - accuracy: 0.7300 - val_loss: 0.8128 - val_accuracy: 0.7348\n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.8117 - accuracy: 0.7349 - val_loss: 0.7949 - val_accuracy: 0.7414\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.7949 - accuracy: 0.7402 - val_loss: 0.7797 - val_accuracy: 0.7460\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.7796 - accuracy: 0.7458 - val_loss: 0.7658 - val_accuracy: 0.7480\n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.7658 - accuracy: 0.7492 - val_loss: 0.7524 - val_accuracy: 0.7538\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.7532 - accuracy: 0.7530 - val_loss: 0.7399 - val_accuracy: 0.7592\n",
      "Epoch 21/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.7414 - accuracy: 0.7580 - val_loss: 0.7298 - val_accuracy: 0.7624\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.7307 - accuracy: 0.7610 - val_loss: 0.7188 - val_accuracy: 0.7654\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.7206 - accuracy: 0.7648 - val_loss: 0.7087 - val_accuracy: 0.7696\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.7111 - accuracy: 0.7675 - val_loss: 0.6999 - val_accuracy: 0.7724\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.7022 - accuracy: 0.7708 - val_loss: 0.6911 - val_accuracy: 0.7764\n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.6939 - accuracy: 0.7744 - val_loss: 0.6826 - val_accuracy: 0.7796\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.6859 - accuracy: 0.7763 - val_loss: 0.6752 - val_accuracy: 0.7812\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.6785 - accuracy: 0.7788 - val_loss: 0.6684 - val_accuracy: 0.7824\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.6714 - accuracy: 0.7806 - val_loss: 0.6612 - val_accuracy: 0.7858\n",
      "Epoch 30/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.6646 - accuracy: 0.7840 - val_loss: 0.6551 - val_accuracy: 0.7862\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.6583 - accuracy: 0.7844 - val_loss: 0.6489 - val_accuracy: 0.7890\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.6522 - accuracy: 0.7870 - val_loss: 0.6426 - val_accuracy: 0.7912\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.6462 - accuracy: 0.7890 - val_loss: 0.6370 - val_accuracy: 0.7916\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.6407 - accuracy: 0.7906 - val_loss: 0.6318 - val_accuracy: 0.7966\n",
      "Epoch 35/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.6353 - accuracy: 0.7921 - val_loss: 0.6264 - val_accuracy: 0.7966\n",
      "Epoch 36/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.6303 - accuracy: 0.7942 - val_loss: 0.6218 - val_accuracy: 0.7994\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.6255 - accuracy: 0.7956 - val_loss: 0.6172 - val_accuracy: 0.7998\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.6209 - accuracy: 0.7965 - val_loss: 0.6125 - val_accuracy: 0.8016\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.6164 - accuracy: 0.7978 - val_loss: 0.6091 - val_accuracy: 0.8026\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.6123 - accuracy: 0.7995 - val_loss: 0.6047 - val_accuracy: 0.8028\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.6082 - accuracy: 0.8004 - val_loss: 0.6006 - val_accuracy: 0.8034\n",
      "Epoch 42/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.6043 - accuracy: 0.8020 - val_loss: 0.5967 - val_accuracy: 0.8044\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.6006 - accuracy: 0.8031 - val_loss: 0.5936 - val_accuracy: 0.8058\n",
      "Epoch 44/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5971 - accuracy: 0.8040 - val_loss: 0.5895 - val_accuracy: 0.8064\n",
      "Epoch 45/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5936 - accuracy: 0.8044 - val_loss: 0.5861 - val_accuracy: 0.8082\n",
      "Epoch 46/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5903 - accuracy: 0.8061 - val_loss: 0.5833 - val_accuracy: 0.8100\n",
      "Epoch 47/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.5871 - accuracy: 0.8071 - val_loss: 0.5802 - val_accuracy: 0.80900.5902 - ac\n",
      "Epoch 48/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.5840 - accuracy: 0.8080 - val_loss: 0.5777 - val_accuracy: 0.8114\n",
      "Epoch 49/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5810 - accuracy: 0.8089 - val_loss: 0.5743 - val_accuracy: 0.8116\n",
      "Epoch 50/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5781 - accuracy: 0.8101 - val_loss: 0.5723 - val_accuracy: 0.8118\n",
      "Epoch 51/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5753 - accuracy: 0.8105 - val_loss: 0.5687 - val_accuracy: 0.8128\n",
      "Epoch 52/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5727 - accuracy: 0.8112 - val_loss: 0.5666 - val_accuracy: 0.8140\n",
      "Epoch 53/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5699 - accuracy: 0.8118 - val_loss: 0.5634 - val_accuracy: 0.8144\n",
      "Epoch 54/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5675 - accuracy: 0.8125 - val_loss: 0.5612 - val_accuracy: 0.8146\n",
      "Epoch 55/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.5650 - accuracy: 0.8130 - val_loss: 0.5590 - val_accuracy: 0.8146\n",
      "Epoch 56/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5626 - accuracy: 0.8144 - val_loss: 0.5565 - val_accuracy: 0.8164\n",
      "Epoch 57/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5603 - accuracy: 0.8145 - val_loss: 0.5537 - val_accuracy: 0.8172\n",
      "Epoch 58/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.5579 - accuracy: 0.8155 - val_loss: 0.5517 - val_accuracy: 0.8190s - loss: 0.5626 - accuracy - ETA: 0s - loss: 0.558\n",
      "Epoch 59/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.5558 - accuracy: 0.8155 - val_loss: 0.5497 - val_accuracy: 0.8184\n",
      "Epoch 60/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5537 - accuracy: 0.8163 - val_loss: 0.5478 - val_accuracy: 0.8194\n",
      "Epoch 61/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5516 - accuracy: 0.8164 - val_loss: 0.5457 - val_accuracy: 0.8186\n",
      "Epoch 62/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.5495 - accuracy: 0.8173 - val_loss: 0.5436 - val_accuracy: 0.8206\n",
      "Epoch 63/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5475 - accuracy: 0.8178 - val_loss: 0.5417 - val_accuracy: 0.8208\n",
      "Epoch 64/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.5456 - accuracy: 0.8185 - val_loss: 0.5400 - val_accuracy: 0.8224\n",
      "Epoch 65/100\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.5436 - accuracy: 0.8187 - val_loss: 0.5374 - val_accuracy: 0.8236\n",
      "Epoch 66/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5419 - accuracy: 0.8184 - val_loss: 0.5357 - val_accuracy: 0.8250\n",
      "Epoch 67/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5400 - accuracy: 0.8197 - val_loss: 0.5355 - val_accuracy: 0.8224\n",
      "Epoch 68/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5383 - accuracy: 0.8203 - val_loss: 0.5326 - val_accuracy: 0.8242\n",
      "Epoch 69/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5366 - accuracy: 0.8209 - val_loss: 0.5314 - val_accuracy: 0.8244\n",
      "Epoch 70/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5349 - accuracy: 0.8212 - val_loss: 0.5293 - val_accuracy: 0.8252\n",
      "Epoch 71/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5333 - accuracy: 0.8218 - val_loss: 0.5274 - val_accuracy: 0.8268\n",
      "Epoch 72/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5315 - accuracy: 0.8213 - val_loss: 0.5262 - val_accuracy: 0.8268\n",
      "Epoch 73/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5300 - accuracy: 0.8219 - val_loss: 0.5247 - val_accuracy: 0.8264\n",
      "Epoch 74/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5286 - accuracy: 0.8229 - val_loss: 0.5232 - val_accuracy: 0.8272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5270 - accuracy: 0.8228 - val_loss: 0.5228 - val_accuracy: 0.8262\n",
      "Epoch 76/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5254 - accuracy: 0.8235 - val_loss: 0.5204 - val_accuracy: 0.8282\n",
      "Epoch 77/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5241 - accuracy: 0.8243 - val_loss: 0.5192 - val_accuracy: 0.8288\n",
      "Epoch 78/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5227 - accuracy: 0.8245 - val_loss: 0.5179 - val_accuracy: 0.8290\n",
      "Epoch 79/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5213 - accuracy: 0.8254 - val_loss: 0.5165 - val_accuracy: 0.8290\n",
      "Epoch 80/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5199 - accuracy: 0.8244 - val_loss: 0.5152 - val_accuracy: 0.8300\n",
      "Epoch 81/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5186 - accuracy: 0.8256 - val_loss: 0.5135 - val_accuracy: 0.8298\n",
      "Epoch 82/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5173 - accuracy: 0.8256 - val_loss: 0.5126 - val_accuracy: 0.8292\n",
      "Epoch 83/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5159 - accuracy: 0.8262 - val_loss: 0.5118 - val_accuracy: 0.8304\n",
      "Epoch 84/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5147 - accuracy: 0.8265 - val_loss: 0.5100 - val_accuracy: 0.8306\n",
      "Epoch 85/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5135 - accuracy: 0.8266 - val_loss: 0.5089 - val_accuracy: 0.8306\n",
      "Epoch 86/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5122 - accuracy: 0.8272 - val_loss: 0.5083 - val_accuracy: 0.8308\n",
      "Epoch 87/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5110 - accuracy: 0.8277 - val_loss: 0.5073 - val_accuracy: 0.8308\n",
      "Epoch 88/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5099 - accuracy: 0.8279 - val_loss: 0.5056 - val_accuracy: 0.8328\n",
      "Epoch 89/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5087 - accuracy: 0.8282 - val_loss: 0.5045 - val_accuracy: 0.8320\n",
      "Epoch 90/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5076 - accuracy: 0.8279 - val_loss: 0.5036 - val_accuracy: 0.8330\n",
      "Epoch 91/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5064 - accuracy: 0.8287 - val_loss: 0.5024 - val_accuracy: 0.8326\n",
      "Epoch 92/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5053 - accuracy: 0.8288 - val_loss: 0.5028 - val_accuracy: 0.8314\n",
      "Epoch 93/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5043 - accuracy: 0.8289 - val_loss: 0.5004 - val_accuracy: 0.8346\n",
      "Epoch 94/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5032 - accuracy: 0.8293 - val_loss: 0.4995 - val_accuracy: 0.8348\n",
      "Epoch 95/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5021 - accuracy: 0.8300 - val_loss: 0.4987 - val_accuracy: 0.8340\n",
      "Epoch 96/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5012 - accuracy: 0.8304 - val_loss: 0.4974 - val_accuracy: 0.8362\n",
      "Epoch 97/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5001 - accuracy: 0.8302 - val_loss: 0.4968 - val_accuracy: 0.8364\n",
      "Epoch 98/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4991 - accuracy: 0.8309 - val_loss: 0.4957 - val_accuracy: 0.8368\n",
      "Epoch 99/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4981 - accuracy: 0.8309 - val_loss: 0.4946 - val_accuracy: 0.8370\n",
      "Epoch 100/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4971 - accuracy: 0.8311 - val_loss: 0.4938 - val_accuracy: 0.8382\n",
      "18334/18334 [==============================] - 0s 21us/sample - loss: 0.5112 - accuracy: 0.8238\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 2.2140 - accuracy: 0.1594 - val_loss: 2.1341 - val_accuracy: 0.2356\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 2.0615 - accuracy: 0.3047 - val_loss: 1.9673 - val_accuracy: 0.3936\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.8810 - accuracy: 0.4346 - val_loss: 1.7793 - val_accuracy: 0.4662\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 1.7068 - accuracy: 0.4937 - val_loss: 1.6144 - val_accuracy: 0.5202\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 1.5465 - accuracy: 0.5285 - val_loss: 1.4524 - val_accuracy: 0.5502\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 1.3987 - accuracy: 0.5565 - val_loss: 1.3173 - val_accuracy: 0.6086\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 1.2793 - accuracy: 0.6068 - val_loss: 1.2105 - val_accuracy: 0.6462\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 1.1850 - accuracy: 0.6295 - val_loss: 1.1262 - val_accuracy: 0.6606\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.1108 - accuracy: 0.6408 - val_loss: 1.0601 - val_accuracy: 0.6712\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0525 - accuracy: 0.6495 - val_loss: 1.0078 - val_accuracy: 0.6808\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.0058 - accuracy: 0.6581 - val_loss: 0.9657 - val_accuracy: 0.6840\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.9679 - accuracy: 0.6648 - val_loss: 0.9312 - val_accuracy: 0.6902\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.9361 - accuracy: 0.6730 - val_loss: 0.9021 - val_accuracy: 0.6966\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.9090 - accuracy: 0.6796 - val_loss: 0.8770 - val_accuracy: 0.7042\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.8853 - accuracy: 0.6863 - val_loss: 0.8547 - val_accuracy: 0.7092\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.8645 - accuracy: 0.6935 - val_loss: 0.8353 - val_accuracy: 0.7170\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.8458 - accuracy: 0.6989 - val_loss: 0.8179 - val_accuracy: 0.7236\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.8289 - accuracy: 0.7047 - val_loss: 0.8018 - val_accuracy: 0.7298\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.8133 - accuracy: 0.7116 - val_loss: 0.7875 - val_accuracy: 0.7342\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7991 - accuracy: 0.7165 - val_loss: 0.7738 - val_accuracy: 0.7410\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.7857 - accuracy: 0.7223 - val_loss: 0.7612 - val_accuracy: 0.7442\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7734 - accuracy: 0.7276 - val_loss: 0.7497 - val_accuracy: 0.7484\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7620 - accuracy: 0.7323 - val_loss: 0.7387 - val_accuracy: 0.7526\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.7511 - accuracy: 0.7370 - val_loss: 0.7285 - val_accuracy: 0.7548\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.7410 - accuracy: 0.7403 - val_loss: 0.7187 - val_accuracy: 0.7598\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.7313 - accuracy: 0.7452 - val_loss: 0.7101 - val_accuracy: 0.7628\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7223 - accuracy: 0.7487 - val_loss: 0.7016 - val_accuracy: 0.7642\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.7136 - accuracy: 0.7526 - val_loss: 0.6933 - val_accuracy: 0.7708\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.7055 - accuracy: 0.7553 - val_loss: 0.6855 - val_accuracy: 0.7738\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6977 - accuracy: 0.7587 - val_loss: 0.6779 - val_accuracy: 0.7772\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6902 - accuracy: 0.7621 - val_loss: 0.6713 - val_accuracy: 0.7802\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6832 - accuracy: 0.7643 - val_loss: 0.6645 - val_accuracy: 0.7822\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6764 - accuracy: 0.7661 - val_loss: 0.6579 - val_accuracy: 0.7838\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6700 - accuracy: 0.7689 - val_loss: 0.6517 - val_accuracy: 0.7882\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6638 - accuracy: 0.7717 - val_loss: 0.6460 - val_accuracy: 0.7894\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6579 - accuracy: 0.7733 - val_loss: 0.6406 - val_accuracy: 0.7904\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6524 - accuracy: 0.7752 - val_loss: 0.6352 - val_accuracy: 0.7922\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6472 - accuracy: 0.7764 - val_loss: 0.6306 - val_accuracy: 0.7946\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6422 - accuracy: 0.7787 - val_loss: 0.6255 - val_accuracy: 0.7958\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6374 - accuracy: 0.7798 - val_loss: 0.6210 - val_accuracy: 0.7966\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6329 - accuracy: 0.7815 - val_loss: 0.6173 - val_accuracy: 0.7960\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6286 - accuracy: 0.7827 - val_loss: 0.6128 - val_accuracy: 0.7990\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6244 - accuracy: 0.7846 - val_loss: 0.6086 - val_accuracy: 0.8006\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.6203 - accuracy: 0.7853 - val_loss: 0.6049 - val_accuracy: 0.8020\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6165 - accuracy: 0.7863 - val_loss: 0.6021 - val_accuracy: 0.8006\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6128 - accuracy: 0.7880 - val_loss: 0.5986 - val_accuracy: 0.8028\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6095 - accuracy: 0.7894 - val_loss: 0.5944 - val_accuracy: 0.8026\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6059 - accuracy: 0.7892 - val_loss: 0.5915 - val_accuracy: 0.8052\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6027 - accuracy: 0.7905 - val_loss: 0.5891 - val_accuracy: 0.8036\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5996 - accuracy: 0.7921 - val_loss: 0.5850 - val_accuracy: 0.8068\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5965 - accuracy: 0.7934 - val_loss: 0.5827 - val_accuracy: 0.8050\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5937 - accuracy: 0.7937 - val_loss: 0.5801 - val_accuracy: 0.8072\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5908 - accuracy: 0.7951 - val_loss: 0.5773 - val_accuracy: 0.8072\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5881 - accuracy: 0.7952 - val_loss: 0.5751 - val_accuracy: 0.8086\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5853 - accuracy: 0.7965 - val_loss: 0.5716 - val_accuracy: 0.8110\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5828 - accuracy: 0.7979 - val_loss: 0.5698 - val_accuracy: 0.8110\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5803 - accuracy: 0.7981 - val_loss: 0.5672 - val_accuracy: 0.8120\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5778 - accuracy: 0.7992 - val_loss: 0.5650 - val_accuracy: 0.8134\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5755 - accuracy: 0.7996 - val_loss: 0.5620 - val_accuracy: 0.8140\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5732 - accuracy: 0.8008 - val_loss: 0.5603 - val_accuracy: 0.8158\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5709 - accuracy: 0.8019 - val_loss: 0.5583 - val_accuracy: 0.8148\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5687 - accuracy: 0.8024 - val_loss: 0.5562 - val_accuracy: 0.8186\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5666 - accuracy: 0.8035 - val_loss: 0.5541 - val_accuracy: 0.8172\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5644 - accuracy: 0.8046 - val_loss: 0.5522 - val_accuracy: 0.8186\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5624 - accuracy: 0.8048 - val_loss: 0.5505 - val_accuracy: 0.8188\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5603 - accuracy: 0.8057 - val_loss: 0.5484 - val_accuracy: 0.8190\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5582 - accuracy: 0.8059 - val_loss: 0.5470 - val_accuracy: 0.8192\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5563 - accuracy: 0.8070 - val_loss: 0.5448 - val_accuracy: 0.8212\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5543 - accuracy: 0.8077 - val_loss: 0.5427 - val_accuracy: 0.8202\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5524 - accuracy: 0.8084 - val_loss: 0.5421 - val_accuracy: 0.8202\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5506 - accuracy: 0.8093 - val_loss: 0.5390 - val_accuracy: 0.8202\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5487 - accuracy: 0.8090 - val_loss: 0.5375 - val_accuracy: 0.8202\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5469 - accuracy: 0.8097 - val_loss: 0.5362 - val_accuracy: 0.8210\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5453 - accuracy: 0.8104 - val_loss: 0.5345 - val_accuracy: 0.8224\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5435 - accuracy: 0.8117 - val_loss: 0.5328 - val_accuracy: 0.8224\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5419 - accuracy: 0.8124 - val_loss: 0.5312 - val_accuracy: 0.8222\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5403 - accuracy: 0.8125 - val_loss: 0.5299 - val_accuracy: 0.8244\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5387 - accuracy: 0.8131 - val_loss: 0.5282 - val_accuracy: 0.8244\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5372 - accuracy: 0.8134 - val_loss: 0.5265 - val_accuracy: 0.8232\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5357 - accuracy: 0.8140 - val_loss: 0.5252 - val_accuracy: 0.8244\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5342 - accuracy: 0.8145 - val_loss: 0.5238 - val_accuracy: 0.8244\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5327 - accuracy: 0.8149 - val_loss: 0.5229 - val_accuracy: 0.8252\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5313 - accuracy: 0.8152 - val_loss: 0.5217 - val_accuracy: 0.8260\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5299 - accuracy: 0.8160 - val_loss: 0.5202 - val_accuracy: 0.8260\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5285 - accuracy: 0.8160 - val_loss: 0.5192 - val_accuracy: 0.8270\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5271 - accuracy: 0.8167 - val_loss: 0.5180 - val_accuracy: 0.8272\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5258 - accuracy: 0.8173 - val_loss: 0.5160 - val_accuracy: 0.8272\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5245 - accuracy: 0.8175 - val_loss: 0.5157 - val_accuracy: 0.8272\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5232 - accuracy: 0.8185 - val_loss: 0.5140 - val_accuracy: 0.8274\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5219 - accuracy: 0.8183 - val_loss: 0.5129 - val_accuracy: 0.8282\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5206 - accuracy: 0.8184 - val_loss: 0.5117 - val_accuracy: 0.8286\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5196 - accuracy: 0.8187 - val_loss: 0.5106 - val_accuracy: 0.8270\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5183 - accuracy: 0.8195 - val_loss: 0.5096 - val_accuracy: 0.8276\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5170 - accuracy: 0.8195 - val_loss: 0.5082 - val_accuracy: 0.8278\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5158 - accuracy: 0.8198 - val_loss: 0.5076 - val_accuracy: 0.8282\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5148 - accuracy: 0.8201 - val_loss: 0.5064 - val_accuracy: 0.8284\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5136 - accuracy: 0.8203 - val_loss: 0.5054 - val_accuracy: 0.8284\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5125 - accuracy: 0.8204 - val_loss: 0.5044 - val_accuracy: 0.8290\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5114 - accuracy: 0.8214 - val_loss: 0.5033 - val_accuracy: 0.8298\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5103 - accuracy: 0.8211 - val_loss: 0.5019 - val_accuracy: 0.8298\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 0.5124 - accuracy: 0.8293\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 2.1703 - accuracy: 0.2325 - val_loss: 2.0320 - val_accuracy: 0.3244\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.9197 - accuracy: 0.3965 - val_loss: 1.7988 - val_accuracy: 0.4710\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.7035 - accuracy: 0.5031 - val_loss: 1.6010 - val_accuracy: 0.5384\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.5288 - accuracy: 0.5480 - val_loss: 1.4377 - val_accuracy: 0.5822\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.3748 - accuracy: 0.5913 - val_loss: 1.2891 - val_accuracy: 0.6322\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.2352 - accuracy: 0.6327 - val_loss: 1.1629 - val_accuracy: 0.6598\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 1.1264 - accuracy: 0.6512 - val_loss: 1.0721 - val_accuracy: 0.6732\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 1.0487 - accuracy: 0.6621 - val_loss: 1.0064 - val_accuracy: 0.6816loss: 1.0510 - accuracy: 0.\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.9913 - accuracy: 0.6750 - val_loss: 0.9561 - val_accuracy: 0.6898\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.9471 - accuracy: 0.6861 - val_loss: 0.9171 - val_accuracy: 0.7010\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.9119 - accuracy: 0.6946 - val_loss: 0.8850 - val_accuracy: 0.7102\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.8829 - accuracy: 0.7030 - val_loss: 0.8585 - val_accuracy: 0.7142\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.8582 - accuracy: 0.7104 - val_loss: 0.8361 - val_accuracy: 0.7204\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.8371 - accuracy: 0.7175 - val_loss: 0.8157 - val_accuracy: 0.7278\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.8184 - accuracy: 0.7241 - val_loss: 0.7980 - val_accuracy: 0.7338\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.8017 - accuracy: 0.7295 - val_loss: 0.7827 - val_accuracy: 0.7416\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7868 - accuracy: 0.7350 - val_loss: 0.7682 - val_accuracy: 0.7452\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7731 - accuracy: 0.7415 - val_loss: 0.7546 - val_accuracy: 0.7504\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.7605 - accuracy: 0.7457 - val_loss: 0.7428 - val_accuracy: 0.7556\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.7488 - accuracy: 0.7499 - val_loss: 0.7318 - val_accuracy: 0.7590\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.7381 - accuracy: 0.7551 - val_loss: 0.7209 - val_accuracy: 0.7634\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.7280 - accuracy: 0.7589 - val_loss: 0.7118 - val_accuracy: 0.7626\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.7186 - accuracy: 0.7624 - val_loss: 0.7023 - val_accuracy: 0.7714\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.7097 - accuracy: 0.7658 - val_loss: 0.6941 - val_accuracy: 0.7748s - loss: 0.7106 - accuracy: 0.76\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.7013 - accuracy: 0.7675 - val_loss: 0.6858 - val_accuracy: 0.7786\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6933 - accuracy: 0.7716 - val_loss: 0.6775 - val_accuracy: 0.7812\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6859 - accuracy: 0.7748 - val_loss: 0.6708 - val_accuracy: 0.7800\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.6788 - accuracy: 0.7771 - val_loss: 0.6651 - val_accuracy: 0.7822\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6720 - accuracy: 0.7792 - val_loss: 0.6576 - val_accuracy: 0.7860\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6656 - accuracy: 0.7820 - val_loss: 0.6511 - val_accuracy: 0.7884\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6596 - accuracy: 0.7836 - val_loss: 0.6445 - val_accuracy: 0.7908\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6538 - accuracy: 0.7850 - val_loss: 0.6399 - val_accuracy: 0.7908\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6482 - accuracy: 0.7875 - val_loss: 0.6335 - val_accuracy: 0.7968\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6430 - accuracy: 0.7896 - val_loss: 0.6290 - val_accuracy: 0.7940\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6380 - accuracy: 0.7905 - val_loss: 0.6238 - val_accuracy: 0.7980\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6330 - accuracy: 0.7919 - val_loss: 0.6202 - val_accuracy: 0.7980\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6284 - accuracy: 0.7939 - val_loss: 0.6144 - val_accuracy: 0.8004\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6241 - accuracy: 0.7944 - val_loss: 0.6102 - val_accuracy: 0.8036\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6197 - accuracy: 0.7963 - val_loss: 0.6061 - val_accuracy: 0.8034\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6157 - accuracy: 0.7968 - val_loss: 0.6022 - val_accuracy: 0.8046\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6118 - accuracy: 0.7988 - val_loss: 0.5984 - val_accuracy: 0.8056\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6079 - accuracy: 0.7994 - val_loss: 0.5947 - val_accuracy: 0.8064\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6043 - accuracy: 0.8008 - val_loss: 0.5916 - val_accuracy: 0.8056\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6008 - accuracy: 0.8017 - val_loss: 0.5879 - val_accuracy: 0.8092\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5974 - accuracy: 0.8018 - val_loss: 0.5849 - val_accuracy: 0.8078\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5941 - accuracy: 0.8027 - val_loss: 0.5819 - val_accuracy: 0.8098\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5910 - accuracy: 0.8036 - val_loss: 0.5783 - val_accuracy: 0.8112\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5879 - accuracy: 0.8049 - val_loss: 0.5758 - val_accuracy: 0.8100\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5850 - accuracy: 0.8050 - val_loss: 0.5727 - val_accuracy: 0.8112\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5821 - accuracy: 0.8059 - val_loss: 0.5704 - val_accuracy: 0.8112\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5794 - accuracy: 0.8068 - val_loss: 0.5671 - val_accuracy: 0.8144\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.5766 - accuracy: 0.8073 - val_loss: 0.5655 - val_accuracy: 0.8124\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5740 - accuracy: 0.8079 - val_loss: 0.5620 - val_accuracy: 0.8146\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5714 - accuracy: 0.8089 - val_loss: 0.5599 - val_accuracy: 0.8134\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5689 - accuracy: 0.8092 - val_loss: 0.5575 - val_accuracy: 0.8148\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5666 - accuracy: 0.8104 - val_loss: 0.5547 - val_accuracy: 0.8160\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5642 - accuracy: 0.8113 - val_loss: 0.5524 - val_accuracy: 0.8178\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5620 - accuracy: 0.8117 - val_loss: 0.5511 - val_accuracy: 0.8168\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5596 - accuracy: 0.8117 - val_loss: 0.5486 - val_accuracy: 0.8166\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5576 - accuracy: 0.8129 - val_loss: 0.5463 - val_accuracy: 0.8172\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5555 - accuracy: 0.8135 - val_loss: 0.5441 - val_accuracy: 0.8186\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5536 - accuracy: 0.8132 - val_loss: 0.5423 - val_accuracy: 0.8190\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5516 - accuracy: 0.8136 - val_loss: 0.5406 - val_accuracy: 0.8188\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5496 - accuracy: 0.8147 - val_loss: 0.5395 - val_accuracy: 0.8182\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5477 - accuracy: 0.8147 - val_loss: 0.5382 - val_accuracy: 0.8204\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5460 - accuracy: 0.8155 - val_loss: 0.5356 - val_accuracy: 0.8224\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5442 - accuracy: 0.8163 - val_loss: 0.5329 - val_accuracy: 0.8240\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5424 - accuracy: 0.8169 - val_loss: 0.5330 - val_accuracy: 0.8220\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5408 - accuracy: 0.8171 - val_loss: 0.5302 - val_accuracy: 0.8244\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5392 - accuracy: 0.8177 - val_loss: 0.5288 - val_accuracy: 0.8220\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5375 - accuracy: 0.8186 - val_loss: 0.5268 - val_accuracy: 0.8256\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5359 - accuracy: 0.8186 - val_loss: 0.5256 - val_accuracy: 0.8262\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.5345 - accuracy: 0.8193 - val_loss: 0.5245 - val_accuracy: 0.8264\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5330 - accuracy: 0.8199 - val_loss: 0.5227 - val_accuracy: 0.8272\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5315 - accuracy: 0.8201 - val_loss: 0.5217 - val_accuracy: 0.8270\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5300 - accuracy: 0.8210 - val_loss: 0.5202 - val_accuracy: 0.8266\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5287 - accuracy: 0.8214 - val_loss: 0.5184 - val_accuracy: 0.8286\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5273 - accuracy: 0.8217 - val_loss: 0.5173 - val_accuracy: 0.8260\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5259 - accuracy: 0.8227 - val_loss: 0.5174 - val_accuracy: 0.8258\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5246 - accuracy: 0.8228 - val_loss: 0.5157 - val_accuracy: 0.8254\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5233 - accuracy: 0.8229 - val_loss: 0.5141 - val_accuracy: 0.8276\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5221 - accuracy: 0.8228 - val_loss: 0.5131 - val_accuracy: 0.8290\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5208 - accuracy: 0.8239 - val_loss: 0.5113 - val_accuracy: 0.8300\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5196 - accuracy: 0.8247 - val_loss: 0.5101 - val_accuracy: 0.8312\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5185 - accuracy: 0.8246 - val_loss: 0.5087 - val_accuracy: 0.8314\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5172 - accuracy: 0.8251 - val_loss: 0.5098 - val_accuracy: 0.8306\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5161 - accuracy: 0.8255 - val_loss: 0.5070 - val_accuracy: 0.8330\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5150 - accuracy: 0.8262 - val_loss: 0.5071 - val_accuracy: 0.8288\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5139 - accuracy: 0.8260 - val_loss: 0.5050 - val_accuracy: 0.8316\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5128 - accuracy: 0.8258 - val_loss: 0.5041 - val_accuracy: 0.8322\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5117 - accuracy: 0.8264 - val_loss: 0.5029 - val_accuracy: 0.8326\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5106 - accuracy: 0.8268 - val_loss: 0.5022 - val_accuracy: 0.8324\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5096 - accuracy: 0.8268 - val_loss: 0.5010 - val_accuracy: 0.8342\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5088 - accuracy: 0.8271 - val_loss: 0.4999 - val_accuracy: 0.8338\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5077 - accuracy: 0.8277 - val_loss: 0.4996 - val_accuracy: 0.8338\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5067 - accuracy: 0.8277 - val_loss: 0.4993 - val_accuracy: 0.8340\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5057 - accuracy: 0.8282 - val_loss: 0.4983 - val_accuracy: 0.8344\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5048 - accuracy: 0.8285 - val_loss: 0.4970 - val_accuracy: 0.8352\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5039 - accuracy: 0.8284 - val_loss: 0.4955 - val_accuracy: 0.8368\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5029 - accuracy: 0.8293 - val_loss: 0.4950 - val_accuracy: 0.8356\n",
      "18333/18333 [==============================] - 0s 27us/sample - loss: 0.5114 - accuracy: 0.8266\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 2s 59us/sample - loss: 2.0642 - accuracy: 0.3481 - val_loss: 1.7694 - val_accuracy: 0.5120\n",
      "Epoch 2/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 1.4460 - accuracy: 0.6164 - val_loss: 1.1596 - val_accuracy: 0.6510\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 1.0184 - accuracy: 0.6691 - val_loss: 0.9053 - val_accuracy: 0.6942\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.8546 - accuracy: 0.7063 - val_loss: 0.7976 - val_accuracy: 0.7214\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.7745 - accuracy: 0.7317 - val_loss: 0.7334 - val_accuracy: 0.7466\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.7226 - accuracy: 0.7510 - val_loss: 0.6912 - val_accuracy: 0.7650\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.6837 - accuracy: 0.7642 - val_loss: 0.6558 - val_accuracy: 0.7784\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.6533 - accuracy: 0.7752 - val_loss: 0.6283 - val_accuracy: 0.7888\n",
      "Epoch 9/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.6282 - accuracy: 0.7851 - val_loss: 0.6097 - val_accuracy: 0.7916\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.6069 - accuracy: 0.7917 - val_loss: 0.5886 - val_accuracy: 0.7984\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.5891 - accuracy: 0.7987 - val_loss: 0.5783 - val_accuracy: 0.8066\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.5740 - accuracy: 0.8033 - val_loss: 0.5614 - val_accuracy: 0.8098\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.5603 - accuracy: 0.8084 - val_loss: 0.5498 - val_accuracy: 0.8154\n",
      "Epoch 14/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.5488 - accuracy: 0.8116 - val_loss: 0.5378 - val_accuracy: 0.8200\n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.5385 - accuracy: 0.8150 - val_loss: 0.5246 - val_accuracy: 0.8222\n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.5290 - accuracy: 0.8185 - val_loss: 0.5179 - val_accuracy: 0.8268\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.5210 - accuracy: 0.8220 - val_loss: 0.5110 - val_accuracy: 0.8276\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.5134 - accuracy: 0.8252 - val_loss: 0.5069 - val_accuracy: 0.8264\n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.5063 - accuracy: 0.8268 - val_loss: 0.4976 - val_accuracy: 0.8346\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.5003 - accuracy: 0.8284 - val_loss: 0.4956 - val_accuracy: 0.8290\n",
      "Epoch 21/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.4943 - accuracy: 0.8300 - val_loss: 0.4893 - val_accuracy: 0.8338\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.4888 - accuracy: 0.8324 - val_loss: 0.4793 - val_accuracy: 0.8394\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.4836 - accuracy: 0.8340 - val_loss: 0.4831 - val_accuracy: 0.8342\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.4783 - accuracy: 0.8352 - val_loss: 0.4752 - val_accuracy: 0.8378\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.4742 - accuracy: 0.8372 - val_loss: 0.4695 - val_accuracy: 0.8392\n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.4702 - accuracy: 0.8382 - val_loss: 0.4701 - val_accuracy: 0.8368\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.4661 - accuracy: 0.8387 - val_loss: 0.4703 - val_accuracy: 0.8394\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.4616 - accuracy: 0.8407 - val_loss: 0.4630 - val_accuracy: 0.8424\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.4580 - accuracy: 0.8423 - val_loss: 0.4595 - val_accuracy: 0.8426\n",
      "Epoch 30/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.4553 - accuracy: 0.8418 - val_loss: 0.4526 - val_accuracy: 0.8450\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.4512 - accuracy: 0.8436 - val_loss: 0.4507 - val_accuracy: 0.8450\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.4484 - accuracy: 0.8450 - val_loss: 0.4465 - val_accuracy: 0.8468\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.4453 - accuracy: 0.8452 - val_loss: 0.4428 - val_accuracy: 0.8500\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.4426 - accuracy: 0.8458 - val_loss: 0.4433 - val_accuracy: 0.8490\n",
      "Epoch 35/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.4391 - accuracy: 0.8479 - val_loss: 0.4408 - val_accuracy: 0.8506\n",
      "Epoch 36/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.4367 - accuracy: 0.8487 - val_loss: 0.4377 - val_accuracy: 0.8510\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.4342 - accuracy: 0.8496 - val_loss: 0.4351 - val_accuracy: 0.8498\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.4316 - accuracy: 0.8501 - val_loss: 0.4336 - val_accuracy: 0.8536\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.4293 - accuracy: 0.8514 - val_loss: 0.4308 - val_accuracy: 0.8538\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.4264 - accuracy: 0.8512 - val_loss: 0.4334 - val_accuracy: 0.8530\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.4249 - accuracy: 0.8522 - val_loss: 0.4305 - val_accuracy: 0.8526\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.4224 - accuracy: 0.8525 - val_loss: 0.4352 - val_accuracy: 0.8526\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.4200 - accuracy: 0.8546 - val_loss: 0.4229 - val_accuracy: 0.8554\n",
      "Epoch 44/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.4177 - accuracy: 0.8549 - val_loss: 0.4238 - val_accuracy: 0.8546\n",
      "Epoch 45/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.4161 - accuracy: 0.8548 - val_loss: 0.4246 - val_accuracy: 0.8558\n",
      "Epoch 46/100\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 0.4141 - accuracy: 0.8553 - val_loss: 0.4235 - val_accuracy: 0.8558\n",
      "Epoch 47/100\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 0.4121 - accuracy: 0.8558 - val_loss: 0.4149 - val_accuracy: 0.8572\n",
      "Epoch 48/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.4104 - accuracy: 0.8565 - val_loss: 0.4209 - val_accuracy: 0.8576\n",
      "Epoch 49/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.4086 - accuracy: 0.8578 - val_loss: 0.4142 - val_accuracy: 0.8594\n",
      "Epoch 50/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.4068 - accuracy: 0.8589 - val_loss: 0.4170 - val_accuracy: 0.8590\n",
      "Epoch 51/100\n",
      "36666/36666 [==============================] - 2s 55us/sample - loss: 0.4050 - accuracy: 0.8599 - val_loss: 0.4203 - val_accuracy: 0.8546\n",
      "Epoch 52/100\n",
      "36666/36666 [==============================] - 2s 56us/sample - loss: 0.4033 - accuracy: 0.8598 - val_loss: 0.4187 - val_accuracy: 0.8554\n",
      "Epoch 53/100\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 0.4014 - accuracy: 0.8597 - val_loss: 0.4094 - val_accuracy: 0.8600\n",
      "Epoch 54/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3998 - accuracy: 0.8611 - val_loss: 0.4069 - val_accuracy: 0.8612\n",
      "Epoch 55/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.3983 - accuracy: 0.8604 - val_loss: 0.4086 - val_accuracy: 0.8618\n",
      "Epoch 56/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3968 - accuracy: 0.8610 - val_loss: 0.4053 - val_accuracy: 0.8638\n",
      "Epoch 57/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.3948 - accuracy: 0.8628 - val_loss: 0.4061 - val_accuracy: 0.8604\n",
      "Epoch 58/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3939 - accuracy: 0.8631 - val_loss: 0.4029 - val_accuracy: 0.8622\n",
      "Epoch 59/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.3923 - accuracy: 0.8633 - val_loss: 0.4016 - val_accuracy: 0.8620\n",
      "Epoch 60/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3901 - accuracy: 0.8643 - val_loss: 0.4057 - val_accuracy: 0.8608\n",
      "Epoch 61/100\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.3889 - accuracy: 0.8648 - val_loss: 0.4038 - val_accuracy: 0.8614\n",
      "Epoch 62/100\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.3877 - accuracy: 0.8649 - val_loss: 0.4008 - val_accuracy: 0.8634\n",
      "Epoch 63/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3867 - accuracy: 0.8655 - val_loss: 0.4019 - val_accuracy: 0.8632\n",
      "Epoch 64/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.3853 - accuracy: 0.8667 - val_loss: 0.3976 - val_accuracy: 0.8638\n",
      "Epoch 65/100\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 0.3836 - accuracy: 0.8670 - val_loss: 0.3956 - val_accuracy: 0.8650\n",
      "Epoch 66/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3825 - accuracy: 0.8675 - val_loss: 0.3983 - val_accuracy: 0.8664\n",
      "Epoch 67/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3811 - accuracy: 0.8674 - val_loss: 0.3953 - val_accuracy: 0.8630\n",
      "Epoch 68/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.3798 - accuracy: 0.8678 - val_loss: 0.3985 - val_accuracy: 0.8614\n",
      "Epoch 69/100\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 0.3785 - accuracy: 0.8679 - val_loss: 0.3972 - val_accuracy: 0.8644\n",
      "Epoch 70/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.3771 - accuracy: 0.8695 - val_loss: 0.3917 - val_accuracy: 0.8678\n",
      "Epoch 71/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3759 - accuracy: 0.8690 - val_loss: 0.3924 - val_accuracy: 0.8658\n",
      "Epoch 72/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.3745 - accuracy: 0.8695 - val_loss: 0.3919 - val_accuracy: 0.8690: 0.375\n",
      "Epoch 73/100\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.3733 - accuracy: 0.8700 - val_loss: 0.4072 - val_accuracy: 0.8612\n",
      "Epoch 74/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3723 - accuracy: 0.8707 - val_loss: 0.3970 - val_accuracy: 0.8626\n",
      "Epoch 75/100\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.3709 - accuracy: 0.8714 - val_loss: 0.3982 - val_accuracy: 0.8614\n",
      "Epoch 76/100\n",
      "36666/36666 [==============================] - 2s 55us/sample - loss: 0.3697 - accuracy: 0.8710 - val_loss: 0.3870 - val_accuracy: 0.8658\n",
      "Epoch 77/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3692 - accuracy: 0.8709 - val_loss: 0.3879 - val_accuracy: 0.8650\n",
      "Epoch 78/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3677 - accuracy: 0.8718 - val_loss: 0.3882 - val_accuracy: 0.8676\n",
      "Epoch 79/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.3667 - accuracy: 0.8729 - val_loss: 0.3862 - val_accuracy: 0.8704\n",
      "Epoch 80/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3655 - accuracy: 0.8727 - val_loss: 0.3862 - val_accuracy: 0.8668\n",
      "Epoch 81/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3646 - accuracy: 0.8729 - val_loss: 0.3906 - val_accuracy: 0.8670\n",
      "Epoch 82/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3631 - accuracy: 0.8733 - val_loss: 0.3971 - val_accuracy: 0.8642\n",
      "Epoch 83/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.3622 - accuracy: 0.8735 - val_loss: 0.3839 - val_accuracy: 0.8716\n",
      "Epoch 84/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.3609 - accuracy: 0.8744 - val_loss: 0.3828 - val_accuracy: 0.8716\n",
      "Epoch 85/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3601 - accuracy: 0.8739 - val_loss: 0.3847 - val_accuracy: 0.8664\n",
      "Epoch 86/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.3592 - accuracy: 0.8752 - val_loss: 0.3838 - val_accuracy: 0.8698\n",
      "Epoch 87/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.3578 - accuracy: 0.8759 - val_loss: 0.3853 - val_accuracy: 0.8708\n",
      "Epoch 88/100\n",
      "36666/36666 [==============================] - 2s 57us/sample - loss: 0.3569 - accuracy: 0.8758 - val_loss: 0.3794 - val_accuracy: 0.8708\n",
      "Epoch 89/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.3564 - accuracy: 0.8756 - val_loss: 0.3785 - val_accuracy: 0.8706\n",
      "Epoch 90/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.3550 - accuracy: 0.8773 - val_loss: 0.3773 - val_accuracy: 0.8728\n",
      "Epoch 91/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.3541 - accuracy: 0.8761 - val_loss: 0.3758 - val_accuracy: 0.8702\n",
      "Epoch 92/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3530 - accuracy: 0.8757 - val_loss: 0.3786 - val_accuracy: 0.8738\n",
      "Epoch 93/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3522 - accuracy: 0.8769 - val_loss: 0.3761 - val_accuracy: 0.8718\n",
      "Epoch 94/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.3509 - accuracy: 0.8779 - val_loss: 0.3839 - val_accuracy: 0.8722\n",
      "Epoch 95/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.3506 - accuracy: 0.8777 - val_loss: 0.3756 - val_accuracy: 0.8712\n",
      "Epoch 96/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.3495 - accuracy: 0.8776 - val_loss: 0.3778 - val_accuracy: 0.8722\n",
      "Epoch 97/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3485 - accuracy: 0.8780 - val_loss: 0.3735 - val_accuracy: 0.8732\n",
      "Epoch 98/100\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 0.3478 - accuracy: 0.8787 - val_loss: 0.3757 - val_accuracy: 0.8722\n",
      "Epoch 99/100\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 0.3463 - accuracy: 0.8788 - val_loss: 0.3791 - val_accuracy: 0.8716\n",
      "Epoch 100/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3453 - accuracy: 0.8794 - val_loss: 0.3718 - val_accuracy: 0.8744\n",
      "18334/18334 [==============================] - 1s 33us/sample - loss: 0.3861 - accuracy: 0.8627\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 2.0738 - accuracy: 0.3269 - val_loss: 1.7547 - val_accuracy: 0.5312\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.4369 - accuracy: 0.5882 - val_loss: 1.1592 - val_accuracy: 0.6434\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 1.0387 - accuracy: 0.6558 - val_loss: 0.9217 - val_accuracy: 0.6818\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.8814 - accuracy: 0.6818 - val_loss: 0.8188 - val_accuracy: 0.7026\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.8035 - accuracy: 0.7073 - val_loss: 0.7604 - val_accuracy: 0.7230\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 2s 59us/sample - loss: 0.7537 - accuracy: 0.7285 - val_loss: 0.7188 - val_accuracy: 0.7488\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.7160 - accuracy: 0.7487 - val_loss: 0.6876 - val_accuracy: 0.7584\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.6850 - accuracy: 0.7633 - val_loss: 0.6578 - val_accuracy: 0.7744\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.6581 - accuracy: 0.7746 - val_loss: 0.6327 - val_accuracy: 0.7858\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.6342 - accuracy: 0.7834 - val_loss: 0.6139 - val_accuracy: 0.7928\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.6139 - accuracy: 0.7899 - val_loss: 0.5927 - val_accuracy: 0.8012\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.5957 - accuracy: 0.7952 - val_loss: 0.5835 - val_accuracy: 0.8052\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.5799 - accuracy: 0.8010 - val_loss: 0.5611 - val_accuracy: 0.8124\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.5658 - accuracy: 0.8065 - val_loss: 0.5524 - val_accuracy: 0.8126\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.5535 - accuracy: 0.8109 - val_loss: 0.5378 - val_accuracy: 0.8168\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.5423 - accuracy: 0.8121 - val_loss: 0.5301 - val_accuracy: 0.8184\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.5322 - accuracy: 0.8154 - val_loss: 0.5203 - val_accuracy: 0.8220\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.5230 - accuracy: 0.8192 - val_loss: 0.5122 - val_accuracy: 0.8268\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.5154 - accuracy: 0.8219 - val_loss: 0.5069 - val_accuracy: 0.8278\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.5082 - accuracy: 0.8243 - val_loss: 0.4981 - val_accuracy: 0.8328\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.5014 - accuracy: 0.8255 - val_loss: 0.4935 - val_accuracy: 0.8332\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4955 - accuracy: 0.8271 - val_loss: 0.4885 - val_accuracy: 0.8350\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.4900 - accuracy: 0.8278 - val_loss: 0.4854 - val_accuracy: 0.8342\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.4847 - accuracy: 0.8303 - val_loss: 0.4782 - val_accuracy: 0.8368\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 2s 60us/sample - loss: 0.4799 - accuracy: 0.8318 - val_loss: 0.4753 - val_accuracy: 0.8410\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4753 - accuracy: 0.8340 - val_loss: 0.4725 - val_accuracy: 0.8412\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4706 - accuracy: 0.8345 - val_loss: 0.4653 - val_accuracy: 0.8410\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4670 - accuracy: 0.8354 - val_loss: 0.4605 - val_accuracy: 0.8438\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4632 - accuracy: 0.8361 - val_loss: 0.4595 - val_accuracy: 0.8464\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.4590 - accuracy: 0.8370 - val_loss: 0.4569 - val_accuracy: 0.8462\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4550 - accuracy: 0.8394 - val_loss: 0.4559 - val_accuracy: 0.8456\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4521 - accuracy: 0.8403 - val_loss: 0.4539 - val_accuracy: 0.8470\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4495 - accuracy: 0.8416 - val_loss: 0.4468 - val_accuracy: 0.8496\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.4461 - accuracy: 0.8431 - val_loss: 0.4515 - val_accuracy: 0.8476\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 2s 62us/sample - loss: 0.4426 - accuracy: 0.8437 - val_loss: 0.4449 - val_accuracy: 0.8522\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.4399 - accuracy: 0.8447 - val_loss: 0.4379 - val_accuracy: 0.8514\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4375 - accuracy: 0.8466 - val_loss: 0.4408 - val_accuracy: 0.8498\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4348 - accuracy: 0.8468 - val_loss: 0.4441 - val_accuracy: 0.8462\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4326 - accuracy: 0.8477 - val_loss: 0.4327 - val_accuracy: 0.8526\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4300 - accuracy: 0.8494 - val_loss: 0.4306 - val_accuracy: 0.8528\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.4268 - accuracy: 0.8492 - val_loss: 0.4269 - val_accuracy: 0.8538\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.4250 - accuracy: 0.8499 - val_loss: 0.4268 - val_accuracy: 0.8556\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4223 - accuracy: 0.8508 - val_loss: 0.4332 - val_accuracy: 0.8502\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.4201 - accuracy: 0.8525 - val_loss: 0.4249 - val_accuracy: 0.8562\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4180 - accuracy: 0.8531 - val_loss: 0.4207 - val_accuracy: 0.8564\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4155 - accuracy: 0.8539 - val_loss: 0.4182 - val_accuracy: 0.8564\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4140 - accuracy: 0.8550 - val_loss: 0.4218 - val_accuracy: 0.8540\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4116 - accuracy: 0.8556 - val_loss: 0.4135 - val_accuracy: 0.8584\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4096 - accuracy: 0.8558 - val_loss: 0.4140 - val_accuracy: 0.8596\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4079 - accuracy: 0.8577 - val_loss: 0.4198 - val_accuracy: 0.8534\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4056 - accuracy: 0.8575 - val_loss: 0.4132 - val_accuracy: 0.8602\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4039 - accuracy: 0.8582 - val_loss: 0.4119 - val_accuracy: 0.8570\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4017 - accuracy: 0.8588 - val_loss: 0.4077 - val_accuracy: 0.8614\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4007 - accuracy: 0.8580 - val_loss: 0.4071 - val_accuracy: 0.8608\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.3992 - accuracy: 0.8590 - val_loss: 0.4062 - val_accuracy: 0.8608\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3971 - accuracy: 0.8601 - val_loss: 0.4119 - val_accuracy: 0.8590\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3955 - accuracy: 0.8602 - val_loss: 0.4110 - val_accuracy: 0.8620\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3943 - accuracy: 0.8613 - val_loss: 0.4064 - val_accuracy: 0.8592\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3925 - accuracy: 0.8616 - val_loss: 0.4031 - val_accuracy: 0.8598\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3907 - accuracy: 0.8625 - val_loss: 0.4026 - val_accuracy: 0.8614\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3892 - accuracy: 0.8625 - val_loss: 0.4033 - val_accuracy: 0.8632\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3880 - accuracy: 0.8625 - val_loss: 0.3983 - val_accuracy: 0.8638\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3862 - accuracy: 0.8645 - val_loss: 0.3947 - val_accuracy: 0.8648\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3850 - accuracy: 0.8641 - val_loss: 0.3952 - val_accuracy: 0.8644\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3834 - accuracy: 0.8648 - val_loss: 0.3918 - val_accuracy: 0.8670\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3825 - accuracy: 0.8660 - val_loss: 0.3962 - val_accuracy: 0.8630\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3808 - accuracy: 0.8651 - val_loss: 0.3921 - val_accuracy: 0.8662\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3796 - accuracy: 0.8674 - val_loss: 0.3897 - val_accuracy: 0.8658\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3780 - accuracy: 0.8676 - val_loss: 0.3900 - val_accuracy: 0.8670\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3772 - accuracy: 0.8673 - val_loss: 0.3902 - val_accuracy: 0.8684\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3758 - accuracy: 0.8680 - val_loss: 0.3874 - val_accuracy: 0.8656\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3748 - accuracy: 0.8688 - val_loss: 0.3882 - val_accuracy: 0.8660\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3733 - accuracy: 0.8693 - val_loss: 0.3871 - val_accuracy: 0.8650\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3719 - accuracy: 0.8696 - val_loss: 0.3928 - val_accuracy: 0.8652\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3708 - accuracy: 0.8699 - val_loss: 0.3889 - val_accuracy: 0.8666\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3694 - accuracy: 0.8700 - val_loss: 0.3853 - val_accuracy: 0.8658\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3684 - accuracy: 0.8706 - val_loss: 0.3933 - val_accuracy: 0.8630\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3671 - accuracy: 0.8725 - val_loss: 0.3868 - val_accuracy: 0.8698\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3665 - accuracy: 0.8725 - val_loss: 0.3841 - val_accuracy: 0.8652\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3649 - accuracy: 0.8714 - val_loss: 0.3804 - val_accuracy: 0.8672\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3640 - accuracy: 0.8726 - val_loss: 0.3828 - val_accuracy: 0.8656\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3632 - accuracy: 0.8723 - val_loss: 0.3857 - val_accuracy: 0.8660\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3618 - accuracy: 0.8742 - val_loss: 0.3836 - val_accuracy: 0.8690\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3612 - accuracy: 0.8743 - val_loss: 0.3864 - val_accuracy: 0.8632\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 2s 59us/sample - loss: 0.3593 - accuracy: 0.8736 - val_loss: 0.3787 - val_accuracy: 0.8688\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 0.3589 - accuracy: 0.8737 - val_loss: 0.3785 - val_accuracy: 0.8702\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.3577 - accuracy: 0.8746 - val_loss: 0.3778 - val_accuracy: 0.8684\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3564 - accuracy: 0.8744 - val_loss: 0.3794 - val_accuracy: 0.8674\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3556 - accuracy: 0.8757 - val_loss: 0.3751 - val_accuracy: 0.8700\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.3544 - accuracy: 0.8760 - val_loss: 0.3743 - val_accuracy: 0.8698\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3534 - accuracy: 0.8754 - val_loss: 0.3756 - val_accuracy: 0.8686\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3524 - accuracy: 0.8765 - val_loss: 0.3787 - val_accuracy: 0.8714\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3521 - accuracy: 0.8763 - val_loss: 0.3797 - val_accuracy: 0.8694\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3508 - accuracy: 0.8772 - val_loss: 0.3732 - val_accuracy: 0.8704\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3491 - accuracy: 0.8780 - val_loss: 0.3724 - val_accuracy: 0.8712\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3490 - accuracy: 0.8780 - val_loss: 0.3788 - val_accuracy: 0.8682\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3481 - accuracy: 0.8782 - val_loss: 0.3843 - val_accuracy: 0.8644\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.3472 - accuracy: 0.8787 - val_loss: 0.3691 - val_accuracy: 0.8700\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3462 - accuracy: 0.8791 - val_loss: 0.3799 - val_accuracy: 0.8700\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3447 - accuracy: 0.8786 - val_loss: 0.3751 - val_accuracy: 0.8672\n",
      "18333/18333 [==============================] - 1s 29us/sample - loss: 0.3817 - accuracy: 0.8689\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 2.0235 - accuracy: 0.3224 - val_loss: 1.7289 - val_accuracy: 0.5682\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.4245 - accuracy: 0.6297 - val_loss: 1.1585 - val_accuracy: 0.6738\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 1.0283 - accuracy: 0.6768 - val_loss: 0.9144 - val_accuracy: 0.6898\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.8638 - accuracy: 0.7068 - val_loss: 0.8056 - val_accuracy: 0.7254\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.7819 - accuracy: 0.7298 - val_loss: 0.7440 - val_accuracy: 0.7446\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.7290 - accuracy: 0.7483 - val_loss: 0.6991 - val_accuracy: 0.7576\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6899 - accuracy: 0.7622 - val_loss: 0.6652 - val_accuracy: 0.7714\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6584 - accuracy: 0.7726 - val_loss: 0.6375 - val_accuracy: 0.7772\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6317 - accuracy: 0.7835 - val_loss: 0.6089 - val_accuracy: 0.7882\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.6087 - accuracy: 0.7907 - val_loss: 0.5935 - val_accuracy: 0.7974\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.5892 - accuracy: 0.7973 - val_loss: 0.5714 - val_accuracy: 0.8042\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.5720 - accuracy: 0.8027 - val_loss: 0.5575 - val_accuracy: 0.8108\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.5573 - accuracy: 0.8079 - val_loss: 0.5417 - val_accuracy: 0.8152\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.5438 - accuracy: 0.8121 - val_loss: 0.5286 - val_accuracy: 0.8184\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.5325 - accuracy: 0.8160 - val_loss: 0.5176 - val_accuracy: 0.8238\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.5216 - accuracy: 0.8198 - val_loss: 0.5111 - val_accuracy: 0.8254\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.5121 - accuracy: 0.8222 - val_loss: 0.4994 - val_accuracy: 0.8278\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.5038 - accuracy: 0.8259 - val_loss: 0.4947 - val_accuracy: 0.8280\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.4959 - accuracy: 0.8273 - val_loss: 0.4875 - val_accuracy: 0.8334\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4894 - accuracy: 0.8298 - val_loss: 0.4850 - val_accuracy: 0.8344\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4824 - accuracy: 0.8324 - val_loss: 0.4745 - val_accuracy: 0.8386\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4768 - accuracy: 0.8337 - val_loss: 0.4707 - val_accuracy: 0.8406\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.4716 - accuracy: 0.8367 - val_loss: 0.4678 - val_accuracy: 0.8402\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4666 - accuracy: 0.8372 - val_loss: 0.4645 - val_accuracy: 0.8370\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4622 - accuracy: 0.8383 - val_loss: 0.4552 - val_accuracy: 0.8418\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4580 - accuracy: 0.8388 - val_loss: 0.4599 - val_accuracy: 0.8424\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4542 - accuracy: 0.8402 - val_loss: 0.4522 - val_accuracy: 0.8448\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4504 - accuracy: 0.8431 - val_loss: 0.4529 - val_accuracy: 0.8432\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4467 - accuracy: 0.8440 - val_loss: 0.4523 - val_accuracy: 0.8428\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4435 - accuracy: 0.8439 - val_loss: 0.4426 - val_accuracy: 0.8464\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.4398 - accuracy: 0.8456 - val_loss: 0.4413 - val_accuracy: 0.8458\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.4370 - accuracy: 0.8470 - val_loss: 0.4379 - val_accuracy: 0.8478\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.4342 - accuracy: 0.8473 - val_loss: 0.4481 - val_accuracy: 0.8438\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.4319 - accuracy: 0.8475 - val_loss: 0.4307 - val_accuracy: 0.8502\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.4286 - accuracy: 0.8500 - val_loss: 0.4354 - val_accuracy: 0.8510\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.4257 - accuracy: 0.8510 - val_loss: 0.4284 - val_accuracy: 0.8506\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.4238 - accuracy: 0.8513 - val_loss: 0.4250 - val_accuracy: 0.8556\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4215 - accuracy: 0.8521 - val_loss: 0.4292 - val_accuracy: 0.8504\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.4191 - accuracy: 0.8529 - val_loss: 0.4250 - val_accuracy: 0.8524\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.4163 - accuracy: 0.8540 - val_loss: 0.4264 - val_accuracy: 0.8516\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.4139 - accuracy: 0.8536 - val_loss: 0.4225 - val_accuracy: 0.8572\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.4122 - accuracy: 0.8550 - val_loss: 0.4144 - val_accuracy: 0.8560\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4102 - accuracy: 0.8565 - val_loss: 0.4166 - val_accuracy: 0.8546\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.4079 - accuracy: 0.8561 - val_loss: 0.4153 - val_accuracy: 0.8576\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.4060 - accuracy: 0.8573 - val_loss: 0.4103 - val_accuracy: 0.8574\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 0.4039 - accuracy: 0.8582 - val_loss: 0.4079 - val_accuracy: 0.8582\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.4022 - accuracy: 0.8581 - val_loss: 0.4086 - val_accuracy: 0.8592\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.4006 - accuracy: 0.8591 - val_loss: 0.4118 - val_accuracy: 0.8586s - loss: 0.4034 - accu\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.3986 - accuracy: 0.8600 - val_loss: 0.4060 - val_accuracy: 0.8602\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.3965 - accuracy: 0.8598 - val_loss: 0.4091 - val_accuracy: 0.8626\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.3953 - accuracy: 0.8610 - val_loss: 0.4121 - val_accuracy: 0.8596\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.3926 - accuracy: 0.8622 - val_loss: 0.4050 - val_accuracy: 0.8596\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.3914 - accuracy: 0.8622 - val_loss: 0.4001 - val_accuracy: 0.8624\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.3899 - accuracy: 0.8623 - val_loss: 0.4037 - val_accuracy: 0.8614\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.3881 - accuracy: 0.8630 - val_loss: 0.4016 - val_accuracy: 0.8604\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 2s 60us/sample - loss: 0.3867 - accuracy: 0.8635 - val_loss: 0.3968 - val_accuracy: 0.8640\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 2s 60us/sample - loss: 0.3852 - accuracy: 0.8636 - val_loss: 0.4023 - val_accuracy: 0.8630\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 0.3838 - accuracy: 0.8645 - val_loss: 0.4075 - val_accuracy: 0.8588\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.3825 - accuracy: 0.8659 - val_loss: 0.3966 - val_accuracy: 0.8644\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.3812 - accuracy: 0.8650 - val_loss: 0.3988 - val_accuracy: 0.8648\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.3796 - accuracy: 0.8666 - val_loss: 0.3934 - val_accuracy: 0.8640\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.3780 - accuracy: 0.8667 - val_loss: 0.3907 - val_accuracy: 0.8666\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3765 - accuracy: 0.8674 - val_loss: 0.3916 - val_accuracy: 0.8646\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3754 - accuracy: 0.8674 - val_loss: 0.3966 - val_accuracy: 0.8656\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3739 - accuracy: 0.8692 - val_loss: 0.3904 - val_accuracy: 0.8656\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.3727 - accuracy: 0.8682 - val_loss: 0.3991 - val_accuracy: 0.8618\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3720 - accuracy: 0.8687 - val_loss: 0.3891 - val_accuracy: 0.8650\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3708 - accuracy: 0.8684 - val_loss: 0.3918 - val_accuracy: 0.8652\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.3694 - accuracy: 0.8705 - val_loss: 0.3868 - val_accuracy: 0.8668\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.3678 - accuracy: 0.8699 - val_loss: 0.3871 - val_accuracy: 0.8668\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3667 - accuracy: 0.8707 - val_loss: 0.3956 - val_accuracy: 0.8638\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3657 - accuracy: 0.8707 - val_loss: 0.3902 - val_accuracy: 0.8686\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3643 - accuracy: 0.8711 - val_loss: 0.3867 - val_accuracy: 0.8672\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3630 - accuracy: 0.8734 - val_loss: 0.3883 - val_accuracy: 0.8660\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3619 - accuracy: 0.8731 - val_loss: 0.3850 - val_accuracy: 0.8652\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3609 - accuracy: 0.8731 - val_loss: 0.3840 - val_accuracy: 0.8636\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3595 - accuracy: 0.8744 - val_loss: 0.3896 - val_accuracy: 0.8642\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3590 - accuracy: 0.8738 - val_loss: 0.3795 - val_accuracy: 0.8674\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3579 - accuracy: 0.8739 - val_loss: 0.3794 - val_accuracy: 0.8666\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3564 - accuracy: 0.8754 - val_loss: 0.3854 - val_accuracy: 0.8652\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3558 - accuracy: 0.8745 - val_loss: 0.3769 - val_accuracy: 0.8682\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3549 - accuracy: 0.8745 - val_loss: 0.3804 - val_accuracy: 0.8692\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3534 - accuracy: 0.8753 - val_loss: 0.3784 - val_accuracy: 0.8684\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3520 - accuracy: 0.8768 - val_loss: 0.3778 - val_accuracy: 0.8676\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3515 - accuracy: 0.8766 - val_loss: 0.3778 - val_accuracy: 0.8680\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3506 - accuracy: 0.8768 - val_loss: 0.3784 - val_accuracy: 0.8674\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3494 - accuracy: 0.8774 - val_loss: 0.3788 - val_accuracy: 0.8684\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.3484 - accuracy: 0.8765 - val_loss: 0.3752 - val_accuracy: 0.8698\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.3472 - accuracy: 0.8793 - val_loss: 0.3759 - val_accuracy: 0.8700\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.3459 - accuracy: 0.8782 - val_loss: 0.3724 - val_accuracy: 0.8696\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 2s 60us/sample - loss: 0.3452 - accuracy: 0.8782 - val_loss: 0.3734 - val_accuracy: 0.8678\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 2s 59us/sample - loss: 0.3446 - accuracy: 0.8784 - val_loss: 0.3800 - val_accuracy: 0.8692\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 0.3434 - accuracy: 0.8794 - val_loss: 0.3725 - val_accuracy: 0.8688\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.3425 - accuracy: 0.8794 - val_loss: 0.3773 - val_accuracy: 0.8712\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.3410 - accuracy: 0.8807 - val_loss: 0.3768 - val_accuracy: 0.8710\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 0.3407 - accuracy: 0.8805 - val_loss: 0.3707 - val_accuracy: 0.8712\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.3395 - accuracy: 0.8811 - val_loss: 0.3773 - val_accuracy: 0.8654\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.3385 - accuracy: 0.8810 - val_loss: 0.3703 - val_accuracy: 0.8730\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.3377 - accuracy: 0.8810 - val_loss: 0.3702 - val_accuracy: 0.8684\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.3370 - accuracy: 0.8814 - val_loss: 0.3780 - val_accuracy: 0.8650\n",
      "18333/18333 [==============================] - 1s 34us/sample - loss: 0.3868 - accuracy: 0.8654\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 1.7151 - accuracy: 0.4942 - val_loss: 1.3135 - val_accuracy: 0.6552\n",
      "Epoch 2/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.1758 - accuracy: 0.6593 - val_loss: 1.0557 - val_accuracy: 0.6854\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.0023 - accuracy: 0.6852 - val_loss: 0.9397 - val_accuracy: 0.7030\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.9119 - accuracy: 0.7057 - val_loss: 0.8691 - val_accuracy: 0.7224\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.8536 - accuracy: 0.7247 - val_loss: 0.8204 - val_accuracy: 0.7442\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.8115 - accuracy: 0.7401 - val_loss: 0.7849 - val_accuracy: 0.7594\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.7793 - accuracy: 0.7521 - val_loss: 0.7571 - val_accuracy: 0.7670\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.7535 - accuracy: 0.7626 - val_loss: 0.7336 - val_accuracy: 0.7756\n",
      "Epoch 9/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.7321 - accuracy: 0.7698 - val_loss: 0.7146 - val_accuracy: 0.7804\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.7141 - accuracy: 0.7758 - val_loss: 0.6985 - val_accuracy: 0.7846\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.6983 - accuracy: 0.7809 - val_loss: 0.6844 - val_accuracy: 0.7900\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6849 - accuracy: 0.7851 - val_loss: 0.6719 - val_accuracy: 0.7922\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6729 - accuracy: 0.7880 - val_loss: 0.6611 - val_accuracy: 0.7948\n",
      "Epoch 14/100\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.6621 - accuracy: 0.7913 - val_loss: 0.6509 - val_accuracy: 0.7994\n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.6525 - accuracy: 0.7943 - val_loss: 0.6424 - val_accuracy: 0.7984\n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.6437 - accuracy: 0.7975 - val_loss: 0.6337 - val_accuracy: 0.8022\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6358 - accuracy: 0.7995 - val_loss: 0.6265 - val_accuracy: 0.8026\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.6284 - accuracy: 0.8014 - val_loss: 0.6196 - val_accuracy: 0.8034\n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6217 - accuracy: 0.8035 - val_loss: 0.6140 - val_accuracy: 0.8088\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6154 - accuracy: 0.8050 - val_loss: 0.6073 - val_accuracy: 0.8066\n",
      "Epoch 21/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.6097 - accuracy: 0.8069 - val_loss: 0.6020 - val_accuracy: 0.8110\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6043 - accuracy: 0.8073 - val_loss: 0.5973 - val_accuracy: 0.8118\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.5992 - accuracy: 0.8091 - val_loss: 0.5920 - val_accuracy: 0.8136\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.5944 - accuracy: 0.8107 - val_loss: 0.5879 - val_accuracy: 0.8136\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.5899 - accuracy: 0.8117 - val_loss: 0.5838 - val_accuracy: 0.8146\n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5857 - accuracy: 0.8118 - val_loss: 0.5791 - val_accuracy: 0.8152\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5816 - accuracy: 0.8131 - val_loss: 0.5762 - val_accuracy: 0.8170\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5779 - accuracy: 0.8149 - val_loss: 0.5723 - val_accuracy: 0.8190\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5743 - accuracy: 0.8150 - val_loss: 0.5683 - val_accuracy: 0.8198\n",
      "Epoch 30/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5709 - accuracy: 0.8164 - val_loss: 0.5662 - val_accuracy: 0.8208\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5675 - accuracy: 0.8170 - val_loss: 0.5622 - val_accuracy: 0.8218\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5645 - accuracy: 0.8178 - val_loss: 0.5599 - val_accuracy: 0.8236\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5615 - accuracy: 0.8187 - val_loss: 0.5565 - val_accuracy: 0.8244\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5585 - accuracy: 0.8198 - val_loss: 0.5547 - val_accuracy: 0.8236\n",
      "Epoch 35/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5559 - accuracy: 0.8205 - val_loss: 0.5515 - val_accuracy: 0.8248\n",
      "Epoch 36/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5531 - accuracy: 0.8212 - val_loss: 0.5490 - val_accuracy: 0.8260\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5508 - accuracy: 0.8210 - val_loss: 0.5472 - val_accuracy: 0.8262\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5482 - accuracy: 0.8219 - val_loss: 0.5440 - val_accuracy: 0.8280\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5459 - accuracy: 0.8225 - val_loss: 0.5419 - val_accuracy: 0.8294\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5437 - accuracy: 0.8233 - val_loss: 0.5400 - val_accuracy: 0.8284\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5415 - accuracy: 0.8241 - val_loss: 0.5382 - val_accuracy: 0.8298\n",
      "Epoch 42/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5393 - accuracy: 0.8247 - val_loss: 0.5362 - val_accuracy: 0.8290\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5374 - accuracy: 0.8253 - val_loss: 0.5339 - val_accuracy: 0.8312\n",
      "Epoch 44/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5354 - accuracy: 0.8261 - val_loss: 0.5322 - val_accuracy: 0.8324\n",
      "Epoch 45/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5334 - accuracy: 0.8262 - val_loss: 0.5308 - val_accuracy: 0.8326\n",
      "Epoch 46/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5317 - accuracy: 0.8270 - val_loss: 0.5286 - val_accuracy: 0.8324\n",
      "Epoch 47/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5299 - accuracy: 0.8276 - val_loss: 0.5272 - val_accuracy: 0.8332\n",
      "Epoch 48/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5281 - accuracy: 0.8279 - val_loss: 0.5254 - val_accuracy: 0.8326\n",
      "Epoch 49/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.5264 - accuracy: 0.8284 - val_loss: 0.5248 - val_accuracy: 0.8344\n",
      "Epoch 50/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5248 - accuracy: 0.8292 - val_loss: 0.5225 - val_accuracy: 0.8336\n",
      "Epoch 51/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5231 - accuracy: 0.8290 - val_loss: 0.5212 - val_accuracy: 0.8330\n",
      "Epoch 52/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5217 - accuracy: 0.8298 - val_loss: 0.5196 - val_accuracy: 0.8346\n",
      "Epoch 53/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5201 - accuracy: 0.8298 - val_loss: 0.5185 - val_accuracy: 0.8356ss: 0.5209 - accuracy: 0. - ETA: 0s - loss: 0.5224 - accu\n",
      "Epoch 54/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5186 - accuracy: 0.8301 - val_loss: 0.5169 - val_accuracy: 0.8348\n",
      "Epoch 55/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5172 - accuracy: 0.8307 - val_loss: 0.5162 - val_accuracy: 0.8362\n",
      "Epoch 56/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5159 - accuracy: 0.8307 - val_loss: 0.5143 - val_accuracy: 0.8360\n",
      "Epoch 57/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5144 - accuracy: 0.8313 - val_loss: 0.5134 - val_accuracy: 0.8358\n",
      "Epoch 58/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5131 - accuracy: 0.8321 - val_loss: 0.5122 - val_accuracy: 0.8372\n",
      "Epoch 59/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5119 - accuracy: 0.8317 - val_loss: 0.5110 - val_accuracy: 0.8382\n",
      "Epoch 60/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5106 - accuracy: 0.8323 - val_loss: 0.5101 - val_accuracy: 0.8384\n",
      "Epoch 61/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5094 - accuracy: 0.8332 - val_loss: 0.5086 - val_accuracy: 0.8364\n",
      "Epoch 62/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5080 - accuracy: 0.8330 - val_loss: 0.5078 - val_accuracy: 0.8398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5070 - accuracy: 0.8327 - val_loss: 0.5061 - val_accuracy: 0.8386\n",
      "Epoch 64/100\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.5059 - accuracy: 0.8333 - val_loss: 0.5050 - val_accuracy: 0.8394\n",
      "Epoch 65/100\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.5047 - accuracy: 0.8335 - val_loss: 0.5047 - val_accuracy: 0.8408\n",
      "Epoch 66/100\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.5036 - accuracy: 0.8341 - val_loss: 0.5029 - val_accuracy: 0.8382\n",
      "Epoch 67/100\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.5026 - accuracy: 0.8339 - val_loss: 0.5025 - val_accuracy: 0.8402\n",
      "Epoch 68/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5015 - accuracy: 0.8344 - val_loss: 0.5015 - val_accuracy: 0.8414\n",
      "Epoch 69/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5004 - accuracy: 0.8350 - val_loss: 0.5003 - val_accuracy: 0.8404\n",
      "Epoch 70/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4994 - accuracy: 0.8349 - val_loss: 0.4996 - val_accuracy: 0.8404\n",
      "Epoch 71/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4984 - accuracy: 0.8355 - val_loss: 0.4983 - val_accuracy: 0.8416\n",
      "Epoch 72/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4974 - accuracy: 0.8357 - val_loss: 0.4978 - val_accuracy: 0.8418\n",
      "Epoch 73/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4965 - accuracy: 0.8358 - val_loss: 0.4967 - val_accuracy: 0.8426\n",
      "Epoch 74/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4956 - accuracy: 0.8361 - val_loss: 0.4957 - val_accuracy: 0.8432\n",
      "Epoch 75/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4947 - accuracy: 0.8363 - val_loss: 0.4952 - val_accuracy: 0.8418\n",
      "Epoch 76/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4938 - accuracy: 0.8365 - val_loss: 0.4940 - val_accuracy: 0.8420\n",
      "Epoch 77/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4928 - accuracy: 0.8369 - val_loss: 0.4934 - val_accuracy: 0.8430\n",
      "Epoch 78/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4919 - accuracy: 0.8375 - val_loss: 0.4929 - val_accuracy: 0.8428\n",
      "Epoch 79/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4911 - accuracy: 0.8375 - val_loss: 0.4922 - val_accuracy: 0.8416\n",
      "Epoch 80/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4903 - accuracy: 0.8382 - val_loss: 0.4908 - val_accuracy: 0.8434\n",
      "Epoch 81/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4894 - accuracy: 0.8382 - val_loss: 0.4902 - val_accuracy: 0.8438\n",
      "Epoch 82/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4887 - accuracy: 0.8381 - val_loss: 0.4893 - val_accuracy: 0.8434\n",
      "Epoch 83/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4879 - accuracy: 0.8383 - val_loss: 0.4886 - val_accuracy: 0.8446\n",
      "Epoch 84/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4871 - accuracy: 0.8389 - val_loss: 0.4886 - val_accuracy: 0.8436\n",
      "Epoch 85/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4863 - accuracy: 0.8390 - val_loss: 0.4870 - val_accuracy: 0.8432\n",
      "Epoch 86/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4855 - accuracy: 0.8388 - val_loss: 0.4868 - val_accuracy: 0.8448\n",
      "Epoch 87/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4847 - accuracy: 0.8395 - val_loss: 0.4864 - val_accuracy: 0.8442\n",
      "Epoch 88/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4841 - accuracy: 0.8401 - val_loss: 0.4859 - val_accuracy: 0.8446\n",
      "Epoch 89/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4833 - accuracy: 0.8396 - val_loss: 0.4845 - val_accuracy: 0.8440\n",
      "Epoch 90/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4826 - accuracy: 0.8402 - val_loss: 0.4854 - val_accuracy: 0.8444\n",
      "Epoch 91/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4819 - accuracy: 0.8406 - val_loss: 0.4840 - val_accuracy: 0.8456\n",
      "Epoch 92/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4812 - accuracy: 0.8402 - val_loss: 0.4829 - val_accuracy: 0.8460\n",
      "Epoch 93/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4805 - accuracy: 0.8408 - val_loss: 0.4826 - val_accuracy: 0.8442\n",
      "Epoch 94/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4799 - accuracy: 0.8414 - val_loss: 0.4820 - val_accuracy: 0.8458\n",
      "Epoch 95/100\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.4791 - accuracy: 0.8411 - val_loss: 0.4815 - val_accuracy: 0.8446\n",
      "Epoch 96/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4785 - accuracy: 0.8414 - val_loss: 0.4806 - val_accuracy: 0.8458\n",
      "Epoch 97/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4779 - accuracy: 0.8415 - val_loss: 0.4801 - val_accuracy: 0.8466\n",
      "Epoch 98/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4772 - accuracy: 0.8415 - val_loss: 0.4794 - val_accuracy: 0.8464\n",
      "Epoch 99/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4766 - accuracy: 0.8420 - val_loss: 0.4799 - val_accuracy: 0.8446\n",
      "Epoch 100/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4760 - accuracy: 0.8418 - val_loss: 0.4787 - val_accuracy: 0.8458\n",
      "18334/18334 [==============================] - 0s 25us/sample - loss: 0.4914 - accuracy: 0.8330\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 1.7261 - accuracy: 0.4791 - val_loss: 1.3094 - val_accuracy: 0.6498\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.1751 - accuracy: 0.6595 - val_loss: 1.0513 - val_accuracy: 0.6802\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0037 - accuracy: 0.6858 - val_loss: 0.9351 - val_accuracy: 0.7002\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.9150 - accuracy: 0.7058 - val_loss: 0.8674 - val_accuracy: 0.7184\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.8581 - accuracy: 0.7208 - val_loss: 0.8200 - val_accuracy: 0.7360\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.8172 - accuracy: 0.7333 - val_loss: 0.7852 - val_accuracy: 0.7474\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.7859 - accuracy: 0.7442 - val_loss: 0.7572 - val_accuracy: 0.7588\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.7606 - accuracy: 0.7506 - val_loss: 0.7351 - val_accuracy: 0.7644\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.7396 - accuracy: 0.7581 - val_loss: 0.7167 - val_accuracy: 0.7698\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.7218 - accuracy: 0.7641 - val_loss: 0.7005 - val_accuracy: 0.7774\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.7065 - accuracy: 0.7692 - val_loss: 0.6863 - val_accuracy: 0.7802\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6930 - accuracy: 0.7742 - val_loss: 0.6734 - val_accuracy: 0.7866\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6809 - accuracy: 0.7783 - val_loss: 0.6635 - val_accuracy: 0.7874\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.6702 - accuracy: 0.7823 - val_loss: 0.6532 - val_accuracy: 0.7920\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6605 - accuracy: 0.7853 - val_loss: 0.6438 - val_accuracy: 0.7954\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6517 - accuracy: 0.7873 - val_loss: 0.6361 - val_accuracy: 0.7980\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6436 - accuracy: 0.7907 - val_loss: 0.6281 - val_accuracy: 0.8008\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.6361 - accuracy: 0.7930 - val_loss: 0.6210 - val_accuracy: 0.8018\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.6292 - accuracy: 0.7953 - val_loss: 0.6156 - val_accuracy: 0.8038\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6229 - accuracy: 0.7973 - val_loss: 0.6098 - val_accuracy: 0.8050\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6169 - accuracy: 0.7989 - val_loss: 0.6039 - val_accuracy: 0.8068\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.6113 - accuracy: 0.8007 - val_loss: 0.5990 - val_accuracy: 0.8080\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6062 - accuracy: 0.8015 - val_loss: 0.5937 - val_accuracy: 0.8090\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6012 - accuracy: 0.8028 - val_loss: 0.5888 - val_accuracy: 0.8108\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5967 - accuracy: 0.8044 - val_loss: 0.5852 - val_accuracy: 0.8144\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5922 - accuracy: 0.8057 - val_loss: 0.5814 - val_accuracy: 0.8160\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5882 - accuracy: 0.8071 - val_loss: 0.5768 - val_accuracy: 0.8164\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5843 - accuracy: 0.8085 - val_loss: 0.5739 - val_accuracy: 0.8184\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5806 - accuracy: 0.8096 - val_loss: 0.5697 - val_accuracy: 0.8186\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5770 - accuracy: 0.8101 - val_loss: 0.5665 - val_accuracy: 0.8196\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5736 - accuracy: 0.8114 - val_loss: 0.5637 - val_accuracy: 0.8220\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5704 - accuracy: 0.8123 - val_loss: 0.5600 - val_accuracy: 0.8206\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5673 - accuracy: 0.8135 - val_loss: 0.5578 - val_accuracy: 0.8216\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5644 - accuracy: 0.8145 - val_loss: 0.5549 - val_accuracy: 0.8226\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5616 - accuracy: 0.8159 - val_loss: 0.5521 - val_accuracy: 0.8232\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5588 - accuracy: 0.8159 - val_loss: 0.5494 - val_accuracy: 0.8254\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5563 - accuracy: 0.8171 - val_loss: 0.5473 - val_accuracy: 0.8258\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5538 - accuracy: 0.8175 - val_loss: 0.5447 - val_accuracy: 0.8260\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5512 - accuracy: 0.8182 - val_loss: 0.5425 - val_accuracy: 0.8272\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5490 - accuracy: 0.8187 - val_loss: 0.5403 - val_accuracy: 0.8284\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5467 - accuracy: 0.8202 - val_loss: 0.5386 - val_accuracy: 0.8270\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5445 - accuracy: 0.8212 - val_loss: 0.5361 - val_accuracy: 0.8300\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5425 - accuracy: 0.8209 - val_loss: 0.5344 - val_accuracy: 0.8304\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5404 - accuracy: 0.8213 - val_loss: 0.5325 - val_accuracy: 0.8316\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5385 - accuracy: 0.8221 - val_loss: 0.5306 - val_accuracy: 0.8318\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5366 - accuracy: 0.8226 - val_loss: 0.5292 - val_accuracy: 0.8332\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5348 - accuracy: 0.8236 - val_loss: 0.5273 - val_accuracy: 0.8328\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5329 - accuracy: 0.8236 - val_loss: 0.5251 - val_accuracy: 0.8322\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5311 - accuracy: 0.8245 - val_loss: 0.5242 - val_accuracy: 0.8324\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5295 - accuracy: 0.8247 - val_loss: 0.5226 - val_accuracy: 0.8324\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5278 - accuracy: 0.8251 - val_loss: 0.5211 - val_accuracy: 0.8336\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5263 - accuracy: 0.8256 - val_loss: 0.5195 - val_accuracy: 0.8356\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5246 - accuracy: 0.8249 - val_loss: 0.5188 - val_accuracy: 0.8330\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5232 - accuracy: 0.8258 - val_loss: 0.5175 - val_accuracy: 0.8338\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5218 - accuracy: 0.8268 - val_loss: 0.5153 - val_accuracy: 0.8350\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5204 - accuracy: 0.8262 - val_loss: 0.5139 - val_accuracy: 0.8342\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5189 - accuracy: 0.8277 - val_loss: 0.5131 - val_accuracy: 0.8350\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5176 - accuracy: 0.8279 - val_loss: 0.5117 - val_accuracy: 0.8358\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5162 - accuracy: 0.8283 - val_loss: 0.5102 - val_accuracy: 0.8350\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5149 - accuracy: 0.8291 - val_loss: 0.5097 - val_accuracy: 0.8362\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5137 - accuracy: 0.8289 - val_loss: 0.5081 - val_accuracy: 0.8360\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5124 - accuracy: 0.8294 - val_loss: 0.5067 - val_accuracy: 0.8362\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5112 - accuracy: 0.8286 - val_loss: 0.5062 - val_accuracy: 0.8358\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5101 - accuracy: 0.8296 - val_loss: 0.5047 - val_accuracy: 0.8376\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5089 - accuracy: 0.8306 - val_loss: 0.5040 - val_accuracy: 0.8368\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5076 - accuracy: 0.8308 - val_loss: 0.5031 - val_accuracy: 0.8360\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5067 - accuracy: 0.8308 - val_loss: 0.5014 - val_accuracy: 0.8372\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5055 - accuracy: 0.8315 - val_loss: 0.5005 - val_accuracy: 0.8392\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5045 - accuracy: 0.8309 - val_loss: 0.4998 - val_accuracy: 0.8370\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5035 - accuracy: 0.8316 - val_loss: 0.4987 - val_accuracy: 0.8376\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5025 - accuracy: 0.8323 - val_loss: 0.4980 - val_accuracy: 0.8380\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5015 - accuracy: 0.8320 - val_loss: 0.4970 - val_accuracy: 0.8392\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5004 - accuracy: 0.8323 - val_loss: 0.4957 - val_accuracy: 0.8392\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4996 - accuracy: 0.8329 - val_loss: 0.4955 - val_accuracy: 0.8388\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4986 - accuracy: 0.8335 - val_loss: 0.4943 - val_accuracy: 0.8402\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4977 - accuracy: 0.8337 - val_loss: 0.4935 - val_accuracy: 0.8396\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4968 - accuracy: 0.8339 - val_loss: 0.4924 - val_accuracy: 0.8400\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4959 - accuracy: 0.8342 - val_loss: 0.4922 - val_accuracy: 0.8400\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4951 - accuracy: 0.8339 - val_loss: 0.4912 - val_accuracy: 0.8408\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4942 - accuracy: 0.8341 - val_loss: 0.4905 - val_accuracy: 0.8414\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4934 - accuracy: 0.8350 - val_loss: 0.4895 - val_accuracy: 0.8422\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4925 - accuracy: 0.8350 - val_loss: 0.4889 - val_accuracy: 0.8424\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4916 - accuracy: 0.8347 - val_loss: 0.4879 - val_accuracy: 0.8428\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4909 - accuracy: 0.8352 - val_loss: 0.4874 - val_accuracy: 0.8420\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4901 - accuracy: 0.8353 - val_loss: 0.4866 - val_accuracy: 0.8432\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4893 - accuracy: 0.8355 - val_loss: 0.4862 - val_accuracy: 0.8430\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4886 - accuracy: 0.8360 - val_loss: 0.4854 - val_accuracy: 0.8424\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4879 - accuracy: 0.8356 - val_loss: 0.4844 - val_accuracy: 0.8434\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4871 - accuracy: 0.8363 - val_loss: 0.4841 - val_accuracy: 0.8434\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4864 - accuracy: 0.8365 - val_loss: 0.4834 - val_accuracy: 0.8440\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4856 - accuracy: 0.8364 - val_loss: 0.4833 - val_accuracy: 0.8430\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4850 - accuracy: 0.8364 - val_loss: 0.4820 - val_accuracy: 0.8440\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4843 - accuracy: 0.8370 - val_loss: 0.4815 - val_accuracy: 0.8432\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4836 - accuracy: 0.8373 - val_loss: 0.4810 - val_accuracy: 0.8438\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4829 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.8440\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4823 - accuracy: 0.8378 - val_loss: 0.4794 - val_accuracy: 0.8450\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4815 - accuracy: 0.8376 - val_loss: 0.4796 - val_accuracy: 0.8448\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4810 - accuracy: 0.8379 - val_loss: 0.4790 - val_accuracy: 0.8440\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4803 - accuracy: 0.8382 - val_loss: 0.4779 - val_accuracy: 0.8446\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4797 - accuracy: 0.8381 - val_loss: 0.4775 - val_accuracy: 0.8442\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.4851 - accuracy: 0.8394\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 1.6724 - accuracy: 0.5032 - val_loss: 1.2991 - val_accuracy: 0.6518\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.1727 - accuracy: 0.6544 - val_loss: 1.0501 - val_accuracy: 0.6808\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0041 - accuracy: 0.6780 - val_loss: 0.9346 - val_accuracy: 0.7018\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.9147 - accuracy: 0.6995 - val_loss: 0.8657 - val_accuracy: 0.7232\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.8568 - accuracy: 0.7182 - val_loss: 0.8178 - val_accuracy: 0.7368\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.8152 - accuracy: 0.7333 - val_loss: 0.7829 - val_accuracy: 0.7514\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.7831 - accuracy: 0.7464 - val_loss: 0.7543 - val_accuracy: 0.7582\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.7573 - accuracy: 0.7551 - val_loss: 0.7318 - val_accuracy: 0.7678\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.7359 - accuracy: 0.7628 - val_loss: 0.7129 - val_accuracy: 0.7730\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7179 - accuracy: 0.7678 - val_loss: 0.6957 - val_accuracy: 0.7808\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.7024 - accuracy: 0.7738 - val_loss: 0.6821 - val_accuracy: 0.7860\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6887 - accuracy: 0.7779 - val_loss: 0.6695 - val_accuracy: 0.7890\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.6766 - accuracy: 0.7823 - val_loss: 0.6583 - val_accuracy: 0.7920\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6658 - accuracy: 0.7860 - val_loss: 0.6480 - val_accuracy: 0.7938\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6560 - accuracy: 0.7883 - val_loss: 0.6395 - val_accuracy: 0.7974\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6472 - accuracy: 0.7916 - val_loss: 0.6318 - val_accuracy: 0.7984\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6391 - accuracy: 0.7949 - val_loss: 0.6239 - val_accuracy: 0.8006\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6317 - accuracy: 0.7968 - val_loss: 0.6169 - val_accuracy: 0.8022\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6248 - accuracy: 0.7993 - val_loss: 0.6110 - val_accuracy: 0.8044\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6184 - accuracy: 0.8007 - val_loss: 0.6050 - val_accuracy: 0.8072\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6125 - accuracy: 0.8022 - val_loss: 0.5993 - val_accuracy: 0.8096\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6071 - accuracy: 0.8042 - val_loss: 0.5945 - val_accuracy: 0.8092\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6019 - accuracy: 0.8054 - val_loss: 0.5898 - val_accuracy: 0.8110\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5971 - accuracy: 0.8072 - val_loss: 0.5853 - val_accuracy: 0.8130\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5925 - accuracy: 0.8092 - val_loss: 0.5811 - val_accuracy: 0.8136\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.5882 - accuracy: 0.8103 - val_loss: 0.5777 - val_accuracy: 0.8142\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5840 - accuracy: 0.8111 - val_loss: 0.5735 - val_accuracy: 0.8152\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5803 - accuracy: 0.8115 - val_loss: 0.5698 - val_accuracy: 0.8174\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5766 - accuracy: 0.8125 - val_loss: 0.5662 - val_accuracy: 0.8186\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5731 - accuracy: 0.8137 - val_loss: 0.5631 - val_accuracy: 0.8202\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5697 - accuracy: 0.8148 - val_loss: 0.5600 - val_accuracy: 0.8206\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5666 - accuracy: 0.8150 - val_loss: 0.5569 - val_accuracy: 0.8218\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5636 - accuracy: 0.8165 - val_loss: 0.5544 - val_accuracy: 0.8212\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.5607 - accuracy: 0.8167 - val_loss: 0.5521 - val_accuracy: 0.8234\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5579 - accuracy: 0.8186 - val_loss: 0.5499 - val_accuracy: 0.8224\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5553 - accuracy: 0.8186 - val_loss: 0.5473 - val_accuracy: 0.8242\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5527 - accuracy: 0.8195 - val_loss: 0.5441 - val_accuracy: 0.8254\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5503 - accuracy: 0.8198 - val_loss: 0.5421 - val_accuracy: 0.8266\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5479 - accuracy: 0.8209 - val_loss: 0.5397 - val_accuracy: 0.8268\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5456 - accuracy: 0.8221 - val_loss: 0.5379 - val_accuracy: 0.8288\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5435 - accuracy: 0.8221 - val_loss: 0.5360 - val_accuracy: 0.8288\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5412 - accuracy: 0.8223 - val_loss: 0.5341 - val_accuracy: 0.8290\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5393 - accuracy: 0.8232 - val_loss: 0.5328 - val_accuracy: 0.8298\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5372 - accuracy: 0.8231 - val_loss: 0.5302 - val_accuracy: 0.8306\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5354 - accuracy: 0.8238 - val_loss: 0.5285 - val_accuracy: 0.8320\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5336 - accuracy: 0.8245 - val_loss: 0.5266 - val_accuracy: 0.8328\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5318 - accuracy: 0.8247 - val_loss: 0.5255 - val_accuracy: 0.8318\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5299 - accuracy: 0.8252 - val_loss: 0.5232 - val_accuracy: 0.8324\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5283 - accuracy: 0.8250 - val_loss: 0.5221 - val_accuracy: 0.8332\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5266 - accuracy: 0.8268 - val_loss: 0.5209 - val_accuracy: 0.8332\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5251 - accuracy: 0.8262 - val_loss: 0.5193 - val_accuracy: 0.8324\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5235 - accuracy: 0.8263 - val_loss: 0.5175 - val_accuracy: 0.8324\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5220 - accuracy: 0.8274 - val_loss: 0.5165 - val_accuracy: 0.8354\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5206 - accuracy: 0.8276 - val_loss: 0.5148 - val_accuracy: 0.8340\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5192 - accuracy: 0.8280 - val_loss: 0.5138 - val_accuracy: 0.8338\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5177 - accuracy: 0.8282 - val_loss: 0.5121 - val_accuracy: 0.8334\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5164 - accuracy: 0.8295 - val_loss: 0.5106 - val_accuracy: 0.8352\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5151 - accuracy: 0.8286 - val_loss: 0.5098 - val_accuracy: 0.8358\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5137 - accuracy: 0.8289 - val_loss: 0.5090 - val_accuracy: 0.8344\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5125 - accuracy: 0.8297 - val_loss: 0.5075 - val_accuracy: 0.8354\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5112 - accuracy: 0.8300 - val_loss: 0.5065 - val_accuracy: 0.8372\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5101 - accuracy: 0.8300 - val_loss: 0.5056 - val_accuracy: 0.8378\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5088 - accuracy: 0.8302 - val_loss: 0.5040 - val_accuracy: 0.8360\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5077 - accuracy: 0.8305 - val_loss: 0.5032 - val_accuracy: 0.8376\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5065 - accuracy: 0.8311 - val_loss: 0.5020 - val_accuracy: 0.8368\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5055 - accuracy: 0.8315 - val_loss: 0.5010 - val_accuracy: 0.8378\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5044 - accuracy: 0.8318 - val_loss: 0.5005 - val_accuracy: 0.8378\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5034 - accuracy: 0.8323 - val_loss: 0.4992 - val_accuracy: 0.8382\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5023 - accuracy: 0.8328 - val_loss: 0.4989 - val_accuracy: 0.8392\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5013 - accuracy: 0.8326 - val_loss: 0.4976 - val_accuracy: 0.8394\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5003 - accuracy: 0.8331 - val_loss: 0.4968 - val_accuracy: 0.8398\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4993 - accuracy: 0.8333 - val_loss: 0.4960 - val_accuracy: 0.8406\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4984 - accuracy: 0.8335 - val_loss: 0.4949 - val_accuracy: 0.8404\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4974 - accuracy: 0.8331 - val_loss: 0.4940 - val_accuracy: 0.8400\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4965 - accuracy: 0.8337 - val_loss: 0.4939 - val_accuracy: 0.8410\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4957 - accuracy: 0.8336 - val_loss: 0.4926 - val_accuracy: 0.8410\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4948 - accuracy: 0.8342 - val_loss: 0.4918 - val_accuracy: 0.8416\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4939 - accuracy: 0.8345 - val_loss: 0.4912 - val_accuracy: 0.8420\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4929 - accuracy: 0.8358 - val_loss: 0.4909 - val_accuracy: 0.8428\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4922 - accuracy: 0.8356 - val_loss: 0.4892 - val_accuracy: 0.8426\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4913 - accuracy: 0.8360 - val_loss: 0.4887 - val_accuracy: 0.8420\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4905 - accuracy: 0.8359 - val_loss: 0.4886 - val_accuracy: 0.8428\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4898 - accuracy: 0.8357 - val_loss: 0.4876 - val_accuracy: 0.8430\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4889 - accuracy: 0.8366 - val_loss: 0.4867 - val_accuracy: 0.8426\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4882 - accuracy: 0.8364 - val_loss: 0.4859 - val_accuracy: 0.8420\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4875 - accuracy: 0.8372 - val_loss: 0.4853 - val_accuracy: 0.8428\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4867 - accuracy: 0.8376 - val_loss: 0.4847 - val_accuracy: 0.8432\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4860 - accuracy: 0.8379 - val_loss: 0.4839 - val_accuracy: 0.8424\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4853 - accuracy: 0.8374 - val_loss: 0.4834 - val_accuracy: 0.8432\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4845 - accuracy: 0.8381 - val_loss: 0.4826 - val_accuracy: 0.8432\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4839 - accuracy: 0.8385 - val_loss: 0.4820 - val_accuracy: 0.8440\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4832 - accuracy: 0.8386 - val_loss: 0.4819 - val_accuracy: 0.8426\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4824 - accuracy: 0.8388 - val_loss: 0.4818 - val_accuracy: 0.8450\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4818 - accuracy: 0.8391 - val_loss: 0.4807 - val_accuracy: 0.8434\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4811 - accuracy: 0.8388 - val_loss: 0.4803 - val_accuracy: 0.8440\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4804 - accuracy: 0.8395 - val_loss: 0.4795 - val_accuracy: 0.8442\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4799 - accuracy: 0.8397 - val_loss: 0.4786 - val_accuracy: 0.8426\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4792 - accuracy: 0.8399 - val_loss: 0.4790 - val_accuracy: 0.8442\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4787 - accuracy: 0.8394 - val_loss: 0.4783 - val_accuracy: 0.84220.4756 - ac\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4781 - accuracy: 0.8397 - val_loss: 0.4774 - val_accuracy: 0.8440\n",
      "18333/18333 [==============================] - 0s 21us/sample - loss: 0.4869 - accuracy: 0.8354\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.9817 - accuracy: 0.6658 - val_loss: 0.6241 - val_accuracy: 0.7926\n",
      "Epoch 2/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.5905 - accuracy: 0.7943 - val_loss: 0.5422 - val_accuracy: 0.8116\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5291 - accuracy: 0.8172 - val_loss: 0.4833 - val_accuracy: 0.8376\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4933 - accuracy: 0.8288 - val_loss: 0.4589 - val_accuracy: 0.8450\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4687 - accuracy: 0.8389 - val_loss: 0.4312 - val_accuracy: 0.8534\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4484 - accuracy: 0.8453 - val_loss: 0.4251 - val_accuracy: 0.8512\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4336 - accuracy: 0.8487 - val_loss: 0.4245 - val_accuracy: 0.8520\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4209 - accuracy: 0.8523 - val_loss: 0.4204 - val_accuracy: 0.8550\n",
      "Epoch 9/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4080 - accuracy: 0.8571 - val_loss: 0.4311 - val_accuracy: 0.8484\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3977 - accuracy: 0.8582 - val_loss: 0.3953 - val_accuracy: 0.8574\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3877 - accuracy: 0.8630 - val_loss: 0.3977 - val_accuracy: 0.8590\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3786 - accuracy: 0.8644 - val_loss: 0.3918 - val_accuracy: 0.8638\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3701 - accuracy: 0.8685 - val_loss: 0.3933 - val_accuracy: 0.8576\n",
      "Epoch 14/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3642 - accuracy: 0.8697 - val_loss: 0.3814 - val_accuracy: 0.8656\n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3574 - accuracy: 0.8712 - val_loss: 0.3931 - val_accuracy: 0.8594\n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3533 - accuracy: 0.8738 - val_loss: 0.3772 - val_accuracy: 0.8684\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3464 - accuracy: 0.8759 - val_loss: 0.3921 - val_accuracy: 0.8596\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3424 - accuracy: 0.8772 - val_loss: 0.3760 - val_accuracy: 0.8646\n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3363 - accuracy: 0.8798 - val_loss: 0.3651 - val_accuracy: 0.8674\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3331 - accuracy: 0.8807 - val_loss: 0.3663 - val_accuracy: 0.8702\n",
      "Epoch 21/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3283 - accuracy: 0.8818 - val_loss: 0.3588 - val_accuracy: 0.8702\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3241 - accuracy: 0.8830 - val_loss: 0.3780 - val_accuracy: 0.8652\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3210 - accuracy: 0.8848 - val_loss: 0.3573 - val_accuracy: 0.8730\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3175 - accuracy: 0.8862 - val_loss: 0.3670 - val_accuracy: 0.8660\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3143 - accuracy: 0.8857 - val_loss: 0.3563 - val_accuracy: 0.8714\n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3101 - accuracy: 0.8889 - val_loss: 0.3907 - val_accuracy: 0.8668\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3079 - accuracy: 0.8878 - val_loss: 0.3569 - val_accuracy: 0.8728\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3033 - accuracy: 0.8906 - val_loss: 0.3558 - val_accuracy: 0.8746\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3016 - accuracy: 0.8909 - val_loss: 0.3590 - val_accuracy: 0.8710\n",
      "Epoch 30/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2981 - accuracy: 0.8918 - val_loss: 0.3709 - val_accuracy: 0.8696\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.2941 - accuracy: 0.8933 - val_loss: 0.3746 - val_accuracy: 0.8678\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2919 - accuracy: 0.8943 - val_loss: 0.3591 - val_accuracy: 0.8736\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2901 - accuracy: 0.8943 - val_loss: 0.3581 - val_accuracy: 0.8722\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2869 - accuracy: 0.8959 - val_loss: 0.3578 - val_accuracy: 0.8716\n",
      "Epoch 35/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2844 - accuracy: 0.8971 - val_loss: 0.3612 - val_accuracy: 0.8718\n",
      "Epoch 36/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2828 - accuracy: 0.8990 - val_loss: 0.3575 - val_accuracy: 0.8708\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2798 - accuracy: 0.8983 - val_loss: 0.3565 - val_accuracy: 0.8716\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2766 - accuracy: 0.8993 - val_loss: 0.3523 - val_accuracy: 0.8742\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2749 - accuracy: 0.9013 - val_loss: 0.3762 - val_accuracy: 0.8692\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.2729 - accuracy: 0.9000 - val_loss: 0.3513 - val_accuracy: 0.8758\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2708 - accuracy: 0.9014 - val_loss: 0.3558 - val_accuracy: 0.8754\n",
      "Epoch 42/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2675 - accuracy: 0.9030 - val_loss: 0.3533 - val_accuracy: 0.8756\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.2656 - accuracy: 0.9025 - val_loss: 0.3627 - val_accuracy: 0.8726\n",
      "Epoch 44/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2636 - accuracy: 0.9044 - val_loss: 0.3620 - val_accuracy: 0.8720\n",
      "Epoch 45/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2618 - accuracy: 0.9038 - val_loss: 0.3826 - val_accuracy: 0.8678\n",
      "Epoch 46/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.2601 - accuracy: 0.9044 - val_loss: 0.3635 - val_accuracy: 0.8718\n",
      "Epoch 47/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2579 - accuracy: 0.9059 - val_loss: 0.3500 - val_accuracy: 0.8766\n",
      "Epoch 48/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.2575 - accuracy: 0.9050 - val_loss: 0.3509 - val_accuracy: 0.8802\n",
      "Epoch 49/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.2549 - accuracy: 0.9070 - val_loss: 0.3807 - val_accuracy: 0.8714\n",
      "Epoch 50/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.2528 - accuracy: 0.9077 - val_loss: 0.3608 - val_accuracy: 0.8786\n",
      "Epoch 51/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2505 - accuracy: 0.9088 - val_loss: 0.3641 - val_accuracy: 0.8770\n",
      "Epoch 52/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.2494 - accuracy: 0.9082 - val_loss: 0.3740 - val_accuracy: 0.8700\n",
      "Epoch 53/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.2481 - accuracy: 0.9100 - val_loss: 0.3747 - val_accuracy: 0.8682\n",
      "Epoch 54/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.2460 - accuracy: 0.9098 - val_loss: 0.3815 - val_accuracy: 0.8688\n",
      "Epoch 55/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.2443 - accuracy: 0.9094 - val_loss: 0.3678 - val_accuracy: 0.8772\n",
      "Epoch 56/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2434 - accuracy: 0.9101 - val_loss: 0.3887 - val_accuracy: 0.8706\n",
      "Epoch 57/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.2409 - accuracy: 0.9116 - val_loss: 0.3718 - val_accuracy: 0.8680\n",
      "18334/18334 [==============================] - 0s 25us/sample - loss: 0.3765 - accuracy: 0.8710\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.0463 - accuracy: 0.6225 - val_loss: 0.7164 - val_accuracy: 0.7510\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6315 - accuracy: 0.7784 - val_loss: 0.5735 - val_accuracy: 0.8046\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5562 - accuracy: 0.8053 - val_loss: 0.5118 - val_accuracy: 0.8296\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5176 - accuracy: 0.8183 - val_loss: 0.4985 - val_accuracy: 0.8314\n",
      "Epoch 5/100\n",
      "12096/36667 [========>.....................] - ETA: 0s - loss: 0.4960 - accuracy: 0.8292"
     ]
    }
   ],
   "source": [
    " param_distribs = {\n",
    "        \"n_hidden\": [0, 1, 2, 3],\n",
    "        \"n_neurons\": np.arange(1, 100),\n",
    "        \"learning_rate\": reciprocal(3e-4, 3e-2)}\n",
    "    \n",
    "rnd_search_cv = RandomizedSearchCV(keras_classifier, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 1.2052 - accuracy: 0.6048 - val_loss: 0.7269 - val_accuracy: 0.7526\n",
      "Epoch 2/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6529 - accuracy: 0.7723 - val_loss: 0.5751 - val_accuracy: 0.8024\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5594 - accuracy: 0.8063 - val_loss: 0.5189 - val_accuracy: 0.8266\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.5145 - accuracy: 0.8188 - val_loss: 0.4855 - val_accuracy: 0.8296\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4870 - accuracy: 0.8286 - val_loss: 0.4634 - val_accuracy: 0.8410\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4685 - accuracy: 0.8358 - val_loss: 0.4478 - val_accuracy: 0.8486\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.4535 - accuracy: 0.8406 - val_loss: 0.4326 - val_accuracy: 0.8536\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4396 - accuracy: 0.8459 - val_loss: 0.4425 - val_accuracy: 0.8488\n",
      "Epoch 9/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4283 - accuracy: 0.8504 - val_loss: 0.4785 - val_accuracy: 0.8266\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4182 - accuracy: 0.8536 - val_loss: 0.4134 - val_accuracy: 0.8578\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4101 - accuracy: 0.8574 - val_loss: 0.4000 - val_accuracy: 0.8616\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4010 - accuracy: 0.8604 - val_loss: 0.3976 - val_accuracy: 0.8620\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3943 - accuracy: 0.8633 - val_loss: 0.4000 - val_accuracy: 0.8628\n",
      "Epoch 14/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3861 - accuracy: 0.8661 - val_loss: 0.3943 - val_accuracy: 0.8640\n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3803 - accuracy: 0.8664 - val_loss: 0.3930 - val_accuracy: 0.8648\n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3731 - accuracy: 0.8686 - val_loss: 0.4013 - val_accuracy: 0.8566\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3691 - accuracy: 0.8718 - val_loss: 0.3769 - val_accuracy: 0.8652\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3640 - accuracy: 0.8727 - val_loss: 0.3694 - val_accuracy: 0.8706\n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3586 - accuracy: 0.8741 - val_loss: 0.3901 - val_accuracy: 0.8676\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3542 - accuracy: 0.8767 - val_loss: 0.3933 - val_accuracy: 0.8638\n",
      "Epoch 21/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3488 - accuracy: 0.8775 - val_loss: 0.3900 - val_accuracy: 0.8652\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3458 - accuracy: 0.8771 - val_loss: 0.3718 - val_accuracy: 0.8690\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3403 - accuracy: 0.8795 - val_loss: 0.3730 - val_accuracy: 0.8664\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3385 - accuracy: 0.8802 - val_loss: 0.3596 - val_accuracy: 0.8744\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3326 - accuracy: 0.8817 - val_loss: 0.3695 - val_accuracy: 0.8656\n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3299 - accuracy: 0.8835 - val_loss: 0.3580 - val_accuracy: 0.8694\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3264 - accuracy: 0.8836 - val_loss: 0.3617 - val_accuracy: 0.8728\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3228 - accuracy: 0.8853 - val_loss: 0.3551 - val_accuracy: 0.8754\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3197 - accuracy: 0.8870 - val_loss: 0.3534 - val_accuracy: 0.8776\n",
      "Epoch 30/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3167 - accuracy: 0.8876 - val_loss: 0.3616 - val_accuracy: 0.8706\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3130 - accuracy: 0.8882 - val_loss: 0.3498 - val_accuracy: 0.8776\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3099 - accuracy: 0.8888 - val_loss: 0.3595 - val_accuracy: 0.8748\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.3065 - accuracy: 0.8925 - val_loss: 0.3406 - val_accuracy: 0.8792\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3031 - accuracy: 0.8911 - val_loss: 0.3667 - val_accuracy: 0.8716\n",
      "Epoch 35/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3017 - accuracy: 0.8926 - val_loss: 0.3595 - val_accuracy: 0.8738\n",
      "Epoch 36/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2972 - accuracy: 0.8950 - val_loss: 0.3459 - val_accuracy: 0.8798\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2959 - accuracy: 0.8939 - val_loss: 0.3527 - val_accuracy: 0.8760\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.2926 - accuracy: 0.8962 - val_loss: 0.3450 - val_accuracy: 0.8742\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.2909 - accuracy: 0.8959 - val_loss: 0.3487 - val_accuracy: 0.8768\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2873 - accuracy: 0.8979 - val_loss: 0.3546 - val_accuracy: 0.8760\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.2849 - accuracy: 0.8982 - val_loss: 0.3532 - val_accuracy: 0.8748\n",
      "Epoch 42/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2843 - accuracy: 0.8986 - val_loss: 0.3482 - val_accuracy: 0.8784\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2805 - accuracy: 0.8999 - val_loss: 0.3465 - val_accuracy: 0.8786\n",
      "18334/18334 [==============================] - 0s 22us/sample - loss: 0.3519 - accuracy: 0.8718\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 1.2177 - accuracy: 0.5951 - val_loss: 0.7370 - val_accuracy: 0.7464\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6806 - accuracy: 0.7574 - val_loss: 0.6137 - val_accuracy: 0.7930\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5815 - accuracy: 0.7992 - val_loss: 0.5403 - val_accuracy: 0.8174\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5294 - accuracy: 0.8149 - val_loss: 0.4896 - val_accuracy: 0.8358\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4981 - accuracy: 0.8258 - val_loss: 0.4702 - val_accuracy: 0.8386\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4771 - accuracy: 0.8296 - val_loss: 0.4495 - val_accuracy: 0.8472\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4601 - accuracy: 0.8369 - val_loss: 0.4803 - val_accuracy: 0.8320\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4464 - accuracy: 0.8417 - val_loss: 0.4297 - val_accuracy: 0.8518\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4340 - accuracy: 0.8472 - val_loss: 0.4198 - val_accuracy: 0.8560\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4250 - accuracy: 0.8491 - val_loss: 0.4238 - val_accuracy: 0.8558\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4156 - accuracy: 0.8535 - val_loss: 0.4256 - val_accuracy: 0.8494\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4072 - accuracy: 0.8546 - val_loss: 0.4129 - val_accuracy: 0.8552\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4006 - accuracy: 0.8585 - val_loss: 0.3986 - val_accuracy: 0.8612\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3942 - accuracy: 0.8592 - val_loss: 0.3917 - val_accuracy: 0.8646\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3865 - accuracy: 0.8635 - val_loss: 0.3970 - val_accuracy: 0.8640\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3808 - accuracy: 0.8652 - val_loss: 0.3931 - val_accuracy: 0.8618\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3765 - accuracy: 0.8680 - val_loss: 0.4008 - val_accuracy: 0.8626\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3714 - accuracy: 0.8681 - val_loss: 0.3806 - val_accuracy: 0.8700\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3670 - accuracy: 0.8697 - val_loss: 0.3842 - val_accuracy: 0.8670\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3617 - accuracy: 0.8719 - val_loss: 0.3761 - val_accuracy: 0.8752\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3587 - accuracy: 0.8731 - val_loss: 0.3784 - val_accuracy: 0.8678\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3537 - accuracy: 0.8742 - val_loss: 0.3790 - val_accuracy: 0.8682\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3498 - accuracy: 0.8750 - val_loss: 0.3792 - val_accuracy: 0.8650\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3458 - accuracy: 0.8767 - val_loss: 0.3669 - val_accuracy: 0.8766\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3429 - accuracy: 0.8776 - val_loss: 0.3690 - val_accuracy: 0.8708\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3399 - accuracy: 0.8795 - val_loss: 0.3816 - val_accuracy: 0.8654\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3353 - accuracy: 0.8794 - val_loss: 0.3602 - val_accuracy: 0.8744\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3323 - accuracy: 0.8816 - val_loss: 0.3689 - val_accuracy: 0.8718\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3300 - accuracy: 0.8816 - val_loss: 0.3608 - val_accuracy: 0.8764\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3255 - accuracy: 0.8840 - val_loss: 0.3553 - val_accuracy: 0.8778\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3230 - accuracy: 0.8825 - val_loss: 0.3508 - val_accuracy: 0.8764\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3208 - accuracy: 0.8845 - val_loss: 0.3527 - val_accuracy: 0.8758\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3166 - accuracy: 0.8874 - val_loss: 0.3506 - val_accuracy: 0.8786\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3133 - accuracy: 0.8880 - val_loss: 0.3518 - val_accuracy: 0.8800\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3112 - accuracy: 0.8868 - val_loss: 0.3444 - val_accuracy: 0.8792\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3078 - accuracy: 0.8894 - val_loss: 0.3512 - val_accuracy: 0.8750\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3055 - accuracy: 0.8908 - val_loss: 0.3472 - val_accuracy: 0.8820\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3023 - accuracy: 0.8909 - val_loss: 0.3488 - val_accuracy: 0.8784\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3000 - accuracy: 0.8915 - val_loss: 0.3411 - val_accuracy: 0.8802\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2981 - accuracy: 0.8917 - val_loss: 0.3479 - val_accuracy: 0.8770\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2939 - accuracy: 0.8934 - val_loss: 0.3349 - val_accuracy: 0.8828\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2923 - accuracy: 0.8942 - val_loss: 0.3535 - val_accuracy: 0.8748\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2901 - accuracy: 0.8948 - val_loss: 0.3361 - val_accuracy: 0.8818\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2868 - accuracy: 0.8958 - val_loss: 0.3403 - val_accuracy: 0.8802\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2847 - accuracy: 0.8973 - val_loss: 0.3454 - val_accuracy: 0.8772\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2828 - accuracy: 0.8972 - val_loss: 0.3384 - val_accuracy: 0.8802\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2803 - accuracy: 0.8967 - val_loss: 0.3418 - val_accuracy: 0.8798\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2769 - accuracy: 0.8997 - val_loss: 0.3348 - val_accuracy: 0.8836\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2757 - accuracy: 0.8993 - val_loss: 0.3338 - val_accuracy: 0.8834\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2735 - accuracy: 0.9006 - val_loss: 0.3356 - val_accuracy: 0.8812\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2711 - accuracy: 0.9019 - val_loss: 0.3404 - val_accuracy: 0.8822\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2699 - accuracy: 0.9024 - val_loss: 0.3371 - val_accuracy: 0.8816\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2671 - accuracy: 0.9024 - val_loss: 0.3320 - val_accuracy: 0.8826\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2636 - accuracy: 0.9044 - val_loss: 0.3266 - val_accuracy: 0.8858\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2636 - accuracy: 0.9034 - val_loss: 0.3391 - val_accuracy: 0.8782\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2613 - accuracy: 0.9039 - val_loss: 0.3440 - val_accuracy: 0.8774\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2584 - accuracy: 0.9052 - val_loss: 0.3326 - val_accuracy: 0.8832\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2571 - accuracy: 0.9056 - val_loss: 0.3412 - val_accuracy: 0.8842\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2534 - accuracy: 0.9086 - val_loss: 0.3412 - val_accuracy: 0.8818\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2527 - accuracy: 0.9077 - val_loss: 0.3243 - val_accuracy: 0.8838\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2518 - accuracy: 0.9080 - val_loss: 0.3247 - val_accuracy: 0.8844\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2497 - accuracy: 0.9092 - val_loss: 0.3598 - val_accuracy: 0.8758\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2469 - accuracy: 0.9093 - val_loss: 0.3261 - val_accuracy: 0.8830\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2458 - accuracy: 0.9110 - val_loss: 0.3260 - val_accuracy: 0.8848\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2444 - accuracy: 0.9102 - val_loss: 0.3298 - val_accuracy: 0.8840\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2428 - accuracy: 0.9109 - val_loss: 0.3370 - val_accuracy: 0.8802\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2404 - accuracy: 0.9113 - val_loss: 0.3333 - val_accuracy: 0.8790\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2390 - accuracy: 0.9126 - val_loss: 0.3324 - val_accuracy: 0.8826\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2372 - accuracy: 0.9117 - val_loss: 0.3276 - val_accuracy: 0.8820\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2347 - accuracy: 0.9152 - val_loss: 0.3292 - val_accuracy: 0.8844\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 0.3428 - accuracy: 0.8831\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 1.2814 - accuracy: 0.5613 - val_loss: 0.7615 - val_accuracy: 0.7362\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6922 - accuracy: 0.7561 - val_loss: 0.6147 - val_accuracy: 0.7860\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5957 - accuracy: 0.7942 - val_loss: 0.5546 - val_accuracy: 0.8028\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5398 - accuracy: 0.8102 - val_loss: 0.5056 - val_accuracy: 0.8270\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5028 - accuracy: 0.8253 - val_loss: 0.4830 - val_accuracy: 0.8346\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4768 - accuracy: 0.8325 - val_loss: 0.4612 - val_accuracy: 0.8468\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4600 - accuracy: 0.8375 - val_loss: 0.4404 - val_accuracy: 0.8522\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4435 - accuracy: 0.8433 - val_loss: 0.4370 - val_accuracy: 0.8510\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4308 - accuracy: 0.8470 - val_loss: 0.4403 - val_accuracy: 0.8490\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4196 - accuracy: 0.8516 - val_loss: 0.4330 - val_accuracy: 0.8452\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4091 - accuracy: 0.8540 - val_loss: 0.4121 - val_accuracy: 0.8554\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4006 - accuracy: 0.8584 - val_loss: 0.4313 - val_accuracy: 0.8464\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3950 - accuracy: 0.8612 - val_loss: 0.4327 - val_accuracy: 0.8442\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3868 - accuracy: 0.8626 - val_loss: 0.3968 - val_accuracy: 0.8648\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3799 - accuracy: 0.8657 - val_loss: 0.3949 - val_accuracy: 0.8602\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3738 - accuracy: 0.8673 - val_loss: 0.3902 - val_accuracy: 0.8638\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3693 - accuracy: 0.8691 - val_loss: 0.3762 - val_accuracy: 0.8692\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3635 - accuracy: 0.8711 - val_loss: 0.4085 - val_accuracy: 0.8540\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3583 - accuracy: 0.8734 - val_loss: 0.3718 - val_accuracy: 0.8714\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3529 - accuracy: 0.8743 - val_loss: 0.3742 - val_accuracy: 0.8708\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3488 - accuracy: 0.8750 - val_loss: 0.3824 - val_accuracy: 0.8690\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3435 - accuracy: 0.8773 - val_loss: 0.3662 - val_accuracy: 0.8734\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3396 - accuracy: 0.8784 - val_loss: 0.3615 - val_accuracy: 0.8716\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3361 - accuracy: 0.8792 - val_loss: 0.3619 - val_accuracy: 0.8734\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3314 - accuracy: 0.8818 - val_loss: 0.3770 - val_accuracy: 0.8630\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3276 - accuracy: 0.8825 - val_loss: 0.3596 - val_accuracy: 0.8734\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3243 - accuracy: 0.8837 - val_loss: 0.3594 - val_accuracy: 0.8750\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3208 - accuracy: 0.8846 - val_loss: 0.3566 - val_accuracy: 0.8728\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3195 - accuracy: 0.8851 - val_loss: 0.3551 - val_accuracy: 0.8742\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3145 - accuracy: 0.8869 - val_loss: 0.3587 - val_accuracy: 0.8736\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3107 - accuracy: 0.8890 - val_loss: 0.3514 - val_accuracy: 0.8790\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3079 - accuracy: 0.8899 - val_loss: 0.3689 - val_accuracy: 0.8736\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3036 - accuracy: 0.8909 - val_loss: 0.3548 - val_accuracy: 0.8748\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3019 - accuracy: 0.8918 - val_loss: 0.3633 - val_accuracy: 0.8688\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2989 - accuracy: 0.8925 - val_loss: 0.3490 - val_accuracy: 0.8746\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2964 - accuracy: 0.8930 - val_loss: 0.3645 - val_accuracy: 0.8740\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2918 - accuracy: 0.8948 - val_loss: 0.3595 - val_accuracy: 0.8744\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2899 - accuracy: 0.8971 - val_loss: 0.3458 - val_accuracy: 0.8764\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2882 - accuracy: 0.8964 - val_loss: 0.3438 - val_accuracy: 0.8790\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2842 - accuracy: 0.8977 - val_loss: 0.3408 - val_accuracy: 0.8794\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2812 - accuracy: 0.8978 - val_loss: 0.3446 - val_accuracy: 0.8786\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2792 - accuracy: 0.9003 - val_loss: 0.3511 - val_accuracy: 0.8776\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2762 - accuracy: 0.9008 - val_loss: 0.3526 - val_accuracy: 0.8746\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2752 - accuracy: 0.9002 - val_loss: 0.3375 - val_accuracy: 0.8804\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2722 - accuracy: 0.9024 - val_loss: 0.3384 - val_accuracy: 0.8806\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2697 - accuracy: 0.9025 - val_loss: 0.3418 - val_accuracy: 0.8832\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2663 - accuracy: 0.9045 - val_loss: 0.3362 - val_accuracy: 0.8804\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.2656 - accuracy: 0.9032 - val_loss: 0.3385 - val_accuracy: 0.8810\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2618 - accuracy: 0.9052 - val_loss: 0.3352 - val_accuracy: 0.8822\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2609 - accuracy: 0.9066 - val_loss: 0.3429 - val_accuracy: 0.8788\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2579 - accuracy: 0.9060 - val_loss: 0.3383 - val_accuracy: 0.8798\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2554 - accuracy: 0.9080 - val_loss: 0.3316 - val_accuracy: 0.8824\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2538 - accuracy: 0.9070 - val_loss: 0.3385 - val_accuracy: 0.8796\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2525 - accuracy: 0.9078 - val_loss: 0.3360 - val_accuracy: 0.8832\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.2495 - accuracy: 0.9105 - val_loss: 0.3300 - val_accuracy: 0.8862\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2486 - accuracy: 0.9103 - val_loss: 0.3305 - val_accuracy: 0.8826\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2458 - accuracy: 0.9104 - val_loss: 0.3397 - val_accuracy: 0.8786\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2431 - accuracy: 0.9123 - val_loss: 0.3389 - val_accuracy: 0.8794\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2416 - accuracy: 0.9129 - val_loss: 0.3363 - val_accuracy: 0.8800\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2386 - accuracy: 0.9133 - val_loss: 0.3422 - val_accuracy: 0.8800\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2388 - accuracy: 0.9139 - val_loss: 0.3524 - val_accuracy: 0.8776\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2371 - accuracy: 0.9135 - val_loss: 0.3354 - val_accuracy: 0.8856\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2343 - accuracy: 0.9158 - val_loss: 0.3337 - val_accuracy: 0.8828\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2314 - accuracy: 0.9171 - val_loss: 0.3342 - val_accuracy: 0.8826\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2291 - accuracy: 0.9178 - val_loss: 0.3630 - val_accuracy: 0.8760\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.3726 - accuracy: 0.8712\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 1.0706 - accuracy: 0.6617 - val_loss: 0.7826 - val_accuracy: 0.7534\n",
      "Epoch 2/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.7272 - accuracy: 0.7664 - val_loss: 0.6705 - val_accuracy: 0.7946\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.6506 - accuracy: 0.7924 - val_loss: 0.6188 - val_accuracy: 0.8072\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.6091 - accuracy: 0.8054 - val_loss: 0.5936 - val_accuracy: 0.8124\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.5819 - accuracy: 0.8115 - val_loss: 0.5668 - val_accuracy: 0.8198\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5619 - accuracy: 0.8186 - val_loss: 0.5492 - val_accuracy: 0.8270\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5466 - accuracy: 0.8227 - val_loss: 0.5388 - val_accuracy: 0.8272\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.5340 - accuracy: 0.8255 - val_loss: 0.5250 - val_accuracy: 0.8336\n",
      "Epoch 9/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.5239 - accuracy: 0.8290 - val_loss: 0.5186 - val_accuracy: 0.8364\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5151 - accuracy: 0.8304 - val_loss: 0.5096 - val_accuracy: 0.8384\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.5080 - accuracy: 0.8327 - val_loss: 0.5025 - val_accuracy: 0.8366\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.5013 - accuracy: 0.8351 - val_loss: 0.4967 - val_accuracy: 0.8404\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4955 - accuracy: 0.8365 - val_loss: 0.4938 - val_accuracy: 0.8428\n",
      "Epoch 14/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4902 - accuracy: 0.8379 - val_loss: 0.4874 - val_accuracy: 0.8414\n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4856 - accuracy: 0.8388 - val_loss: 0.4845 - val_accuracy: 0.8446\n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4813 - accuracy: 0.8402 - val_loss: 0.4804 - val_accuracy: 0.8440: 0.4791 - accuracy: 0.84 - ETA: 0s - loss: 0.4802 - accuracy: 0.\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4775 - accuracy: 0.8412 - val_loss: 0.4758 - val_accuracy: 0.8476\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4739 - accuracy: 0.8426 - val_loss: 0.4762 - val_accuracy: 0.8476\n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4708 - accuracy: 0.8434 - val_loss: 0.4714 - val_accuracy: 0.8462\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4675 - accuracy: 0.8441 - val_loss: 0.4685 - val_accuracy: 0.8494\n",
      "Epoch 21/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4650 - accuracy: 0.8446 - val_loss: 0.4653 - val_accuracy: 0.8492\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4619 - accuracy: 0.8455 - val_loss: 0.4646 - val_accuracy: 0.8484\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4595 - accuracy: 0.8465 - val_loss: 0.4615 - val_accuracy: 0.8504\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4570 - accuracy: 0.8470 - val_loss: 0.4639 - val_accuracy: 0.8512\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4549 - accuracy: 0.8485 - val_loss: 0.4582 - val_accuracy: 0.8518\n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4527 - accuracy: 0.8487 - val_loss: 0.4573 - val_accuracy: 0.8508\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4512 - accuracy: 0.8490 - val_loss: 0.4540 - val_accuracy: 0.8530\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4489 - accuracy: 0.8503 - val_loss: 0.4537 - val_accuracy: 0.8522s - loss: 0.4\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4471 - accuracy: 0.8500 - val_loss: 0.4514 - val_accuracy: 0.8540\n",
      "Epoch 30/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4456 - accuracy: 0.8507 - val_loss: 0.4506 - val_accuracy: 0.8536\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4439 - accuracy: 0.8512 - val_loss: 0.4497 - val_accuracy: 0.8532\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4423 - accuracy: 0.8522 - val_loss: 0.4471 - val_accuracy: 0.8550\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4410 - accuracy: 0.8522 - val_loss: 0.4463 - val_accuracy: 0.8546\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4396 - accuracy: 0.8523 - val_loss: 0.4461 - val_accuracy: 0.8556\n",
      "Epoch 35/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4380 - accuracy: 0.8522 - val_loss: 0.4452 - val_accuracy: 0.8538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4367 - accuracy: 0.8533 - val_loss: 0.4432 - val_accuracy: 0.8552\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4354 - accuracy: 0.8535 - val_loss: 0.4434 - val_accuracy: 0.8550\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4340 - accuracy: 0.8537 - val_loss: 0.4424 - val_accuracy: 0.8554\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4329 - accuracy: 0.8543 - val_loss: 0.4408 - val_accuracy: 0.8548\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4318 - accuracy: 0.8549 - val_loss: 0.4409 - val_accuracy: 0.8538\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4308 - accuracy: 0.8552 - val_loss: 0.4393 - val_accuracy: 0.8550\n",
      "Epoch 42/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4299 - accuracy: 0.8554 - val_loss: 0.4392 - val_accuracy: 0.8560\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4287 - accuracy: 0.8561 - val_loss: 0.4373 - val_accuracy: 0.8562\n",
      "Epoch 44/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4273 - accuracy: 0.8557 - val_loss: 0.4397 - val_accuracy: 0.8542\n",
      "Epoch 45/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4268 - accuracy: 0.8556 - val_loss: 0.4354 - val_accuracy: 0.8548\n",
      "Epoch 46/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4258 - accuracy: 0.8568 - val_loss: 0.4357 - val_accuracy: 0.8560\n",
      "Epoch 47/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4248 - accuracy: 0.8564 - val_loss: 0.4371 - val_accuracy: 0.8566\n",
      "Epoch 48/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4240 - accuracy: 0.8570 - val_loss: 0.4352 - val_accuracy: 0.8562\n",
      "Epoch 49/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4234 - accuracy: 0.8574 - val_loss: 0.4343 - val_accuracy: 0.8566\n",
      "Epoch 50/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4224 - accuracy: 0.8583 - val_loss: 0.4377 - val_accuracy: 0.8560\n",
      "Epoch 51/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4215 - accuracy: 0.8573 - val_loss: 0.4336 - val_accuracy: 0.8576\n",
      "Epoch 52/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4206 - accuracy: 0.8585 - val_loss: 0.4326 - val_accuracy: 0.8566\n",
      "Epoch 53/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4201 - accuracy: 0.8580 - val_loss: 0.4318 - val_accuracy: 0.8574\n",
      "Epoch 54/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4191 - accuracy: 0.8591 - val_loss: 0.4308 - val_accuracy: 0.8576\n",
      "Epoch 55/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4184 - accuracy: 0.8597 - val_loss: 0.4311 - val_accuracy: 0.8582\n",
      "Epoch 56/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4178 - accuracy: 0.8592 - val_loss: 0.4294 - val_accuracy: 0.8564\n",
      "Epoch 57/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4171 - accuracy: 0.8596 - val_loss: 0.4303 - val_accuracy: 0.8586\n",
      "Epoch 58/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4164 - accuracy: 0.8588 - val_loss: 0.4310 - val_accuracy: 0.8574\n",
      "Epoch 59/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4157 - accuracy: 0.8599 - val_loss: 0.4295 - val_accuracy: 0.8582\n",
      "Epoch 60/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4148 - accuracy: 0.8599 - val_loss: 0.4291 - val_accuracy: 0.8590\n",
      "Epoch 61/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4142 - accuracy: 0.8600 - val_loss: 0.4273 - val_accuracy: 0.8584\n",
      "Epoch 62/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4136 - accuracy: 0.8598 - val_loss: 0.4279 - val_accuracy: 0.8592\n",
      "Epoch 63/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4132 - accuracy: 0.8606 - val_loss: 0.4273 - val_accuracy: 0.8604\n",
      "Epoch 64/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4125 - accuracy: 0.8608 - val_loss: 0.4291 - val_accuracy: 0.8582\n",
      "Epoch 65/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4119 - accuracy: 0.8612 - val_loss: 0.4287 - val_accuracy: 0.8580\n",
      "Epoch 66/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4114 - accuracy: 0.8609 - val_loss: 0.4250 - val_accuracy: 0.8586\n",
      "Epoch 67/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4106 - accuracy: 0.8615 - val_loss: 0.4261 - val_accuracy: 0.8582\n",
      "Epoch 68/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4101 - accuracy: 0.8603 - val_loss: 0.4266 - val_accuracy: 0.8598\n",
      "Epoch 69/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4099 - accuracy: 0.8628 - val_loss: 0.4271 - val_accuracy: 0.8600\n",
      "Epoch 70/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4090 - accuracy: 0.8625 - val_loss: 0.4254 - val_accuracy: 0.8578\n",
      "Epoch 71/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4087 - accuracy: 0.8622 - val_loss: 0.4243 - val_accuracy: 0.8592\n",
      "Epoch 72/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4081 - accuracy: 0.8625 - val_loss: 0.4226 - val_accuracy: 0.8600\n",
      "Epoch 73/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4076 - accuracy: 0.8626 - val_loss: 0.4247 - val_accuracy: 0.8594\n",
      "Epoch 74/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4072 - accuracy: 0.8619 - val_loss: 0.4262 - val_accuracy: 0.8596\n",
      "Epoch 75/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4066 - accuracy: 0.8631 - val_loss: 0.4239 - val_accuracy: 0.8576\n",
      "Epoch 76/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4063 - accuracy: 0.8628 - val_loss: 0.4237 - val_accuracy: 0.8608\n",
      "Epoch 77/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4059 - accuracy: 0.8631 - val_loss: 0.4235 - val_accuracy: 0.8594\n",
      "Epoch 78/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4053 - accuracy: 0.8640 - val_loss: 0.4241 - val_accuracy: 0.8614\n",
      "Epoch 79/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4046 - accuracy: 0.8629 - val_loss: 0.4229 - val_accuracy: 0.8580\n",
      "Epoch 80/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4045 - accuracy: 0.8632 - val_loss: 0.4217 - val_accuracy: 0.8600\n",
      "Epoch 81/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4035 - accuracy: 0.8632 - val_loss: 0.4265 - val_accuracy: 0.8580\n",
      "Epoch 82/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4034 - accuracy: 0.8639 - val_loss: 0.4220 - val_accuracy: 0.8588\n",
      "Epoch 83/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4029 - accuracy: 0.8643 - val_loss: 0.4220 - val_accuracy: 0.8598\n",
      "Epoch 84/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4026 - accuracy: 0.8637 - val_loss: 0.4215 - val_accuracy: 0.8600\n",
      "Epoch 85/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4020 - accuracy: 0.8639 - val_loss: 0.4229 - val_accuracy: 0.8610\n",
      "Epoch 86/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4016 - accuracy: 0.8651 - val_loss: 0.4220 - val_accuracy: 0.8598\n",
      "Epoch 87/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4013 - accuracy: 0.8639 - val_loss: 0.4208 - val_accuracy: 0.8606\n",
      "Epoch 88/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4009 - accuracy: 0.8645 - val_loss: 0.4200 - val_accuracy: 0.8608\n",
      "Epoch 89/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4006 - accuracy: 0.8649 - val_loss: 0.4222 - val_accuracy: 0.8612\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4002 - accuracy: 0.8657 - val_loss: 0.4232 - val_accuracy: 0.8610\n",
      "Epoch 91/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.3999 - accuracy: 0.8651 - val_loss: 0.4213 - val_accuracy: 0.8590\n",
      "Epoch 92/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.3993 - accuracy: 0.8654 - val_loss: 0.4196 - val_accuracy: 0.8598\n",
      "Epoch 93/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.3991 - accuracy: 0.8660 - val_loss: 0.4185 - val_accuracy: 0.8604\n",
      "Epoch 94/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.3987 - accuracy: 0.8651 - val_loss: 0.4190 - val_accuracy: 0.8596\n",
      "Epoch 95/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.3984 - accuracy: 0.8665 - val_loss: 0.4204 - val_accuracy: 0.8626\n",
      "Epoch 96/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.3981 - accuracy: 0.8661 - val_loss: 0.4193 - val_accuracy: 0.8592\n",
      "Epoch 97/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.3976 - accuracy: 0.8665 - val_loss: 0.4209 - val_accuracy: 0.8624\n",
      "Epoch 98/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.3972 - accuracy: 0.8661 - val_loss: 0.4226 - val_accuracy: 0.8618\n",
      "Epoch 99/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.3969 - accuracy: 0.8648 - val_loss: 0.4188 - val_accuracy: 0.8616\n",
      "Epoch 100/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.3966 - accuracy: 0.8657 - val_loss: 0.4187 - val_accuracy: 0.8614\n",
      "18334/18334 [==============================] - 0s 18us/sample - loss: 0.4319 - accuracy: 0.8484\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.0910 - accuracy: 0.6539 - val_loss: 0.7858 - val_accuracy: 0.7538\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.7354 - accuracy: 0.7622 - val_loss: 0.6703 - val_accuracy: 0.7888\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.6566 - accuracy: 0.7872 - val_loss: 0.6167 - val_accuracy: 0.8066\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.6134 - accuracy: 0.8004 - val_loss: 0.5894 - val_accuracy: 0.8132\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5857 - accuracy: 0.8089 - val_loss: 0.5665 - val_accuracy: 0.8210\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5651 - accuracy: 0.8156 - val_loss: 0.5472 - val_accuracy: 0.8276\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5496 - accuracy: 0.8173 - val_loss: 0.5358 - val_accuracy: 0.8282\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5371 - accuracy: 0.8220 - val_loss: 0.5231 - val_accuracy: 0.8332\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5269 - accuracy: 0.8247 - val_loss: 0.5143 - val_accuracy: 0.8338\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5178 - accuracy: 0.8271 - val_loss: 0.5084 - val_accuracy: 0.8348\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5104 - accuracy: 0.8289 - val_loss: 0.5009 - val_accuracy: 0.8382\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5040 - accuracy: 0.8307 - val_loss: 0.4958 - val_accuracy: 0.8408\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4980 - accuracy: 0.8323 - val_loss: 0.4938 - val_accuracy: 0.8384\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4928 - accuracy: 0.8336 - val_loss: 0.4879 - val_accuracy: 0.8382\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4880 - accuracy: 0.8343 - val_loss: 0.4831 - val_accuracy: 0.8404\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4840 - accuracy: 0.8354 - val_loss: 0.4791 - val_accuracy: 0.8432\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4801 - accuracy: 0.8375 - val_loss: 0.4760 - val_accuracy: 0.8448\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4765 - accuracy: 0.8380 - val_loss: 0.4750 - val_accuracy: 0.8434\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4732 - accuracy: 0.8393 - val_loss: 0.4705 - val_accuracy: 0.8450\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4702 - accuracy: 0.8402 - val_loss: 0.4697 - val_accuracy: 0.8472\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4675 - accuracy: 0.8414 - val_loss: 0.4651 - val_accuracy: 0.8460\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4646 - accuracy: 0.8417 - val_loss: 0.4635 - val_accuracy: 0.8484\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4622 - accuracy: 0.8434 - val_loss: 0.4618 - val_accuracy: 0.8486\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4599 - accuracy: 0.8435 - val_loss: 0.4624 - val_accuracy: 0.8482\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4576 - accuracy: 0.8444 - val_loss: 0.4596 - val_accuracy: 0.8488\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4556 - accuracy: 0.8453 - val_loss: 0.4575 - val_accuracy: 0.8490\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4535 - accuracy: 0.8454 - val_loss: 0.4544 - val_accuracy: 0.8504\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4514 - accuracy: 0.8468 - val_loss: 0.4548 - val_accuracy: 0.8486\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4498 - accuracy: 0.8459 - val_loss: 0.4575 - val_accuracy: 0.8508\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4484 - accuracy: 0.8473 - val_loss: 0.4515 - val_accuracy: 0.8490s - loss: 0.4455 - accuracy: 0.\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4469 - accuracy: 0.8469 - val_loss: 0.4498 - val_accuracy: 0.8502\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4449 - accuracy: 0.8485 - val_loss: 0.4498 - val_accuracy: 0.8512\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4436 - accuracy: 0.8486 - val_loss: 0.4478 - val_accuracy: 0.8510\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4424 - accuracy: 0.8485 - val_loss: 0.4460 - val_accuracy: 0.8530\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4407 - accuracy: 0.8502 - val_loss: 0.4462 - val_accuracy: 0.8492\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4396 - accuracy: 0.8496 - val_loss: 0.4438 - val_accuracy: 0.8518\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4382 - accuracy: 0.8502 - val_loss: 0.4443 - val_accuracy: 0.8524\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4372 - accuracy: 0.8506 - val_loss: 0.4423 - val_accuracy: 0.8528\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4358 - accuracy: 0.8510 - val_loss: 0.4415 - val_accuracy: 0.8520\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4347 - accuracy: 0.8515 - val_loss: 0.4411 - val_accuracy: 0.8524\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4338 - accuracy: 0.8520 - val_loss: 0.4403 - val_accuracy: 0.8534\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4325 - accuracy: 0.8525 - val_loss: 0.4412 - val_accuracy: 0.8540\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4318 - accuracy: 0.8525 - val_loss: 0.4381 - val_accuracy: 0.8532\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4306 - accuracy: 0.8527 - val_loss: 0.4377 - val_accuracy: 0.8528\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4296 - accuracy: 0.8524 - val_loss: 0.4372 - val_accuracy: 0.8534\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4287 - accuracy: 0.8528 - val_loss: 0.4362 - val_accuracy: 0.8530\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4276 - accuracy: 0.8539 - val_loss: 0.4354 - val_accuracy: 0.8542\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4269 - accuracy: 0.8538 - val_loss: 0.4355 - val_accuracy: 0.8540\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4260 - accuracy: 0.8541 - val_loss: 0.4364 - val_accuracy: 0.8558\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4253 - accuracy: 0.8543 - val_loss: 0.4346 - val_accuracy: 0.8538\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4246 - accuracy: 0.8545 - val_loss: 0.4341 - val_accuracy: 0.8522\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4236 - accuracy: 0.8553 - val_loss: 0.4327 - val_accuracy: 0.8540\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4231 - accuracy: 0.8551 - val_loss: 0.4327 - val_accuracy: 0.8544\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4224 - accuracy: 0.8552 - val_loss: 0.4316 - val_accuracy: 0.8540\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4214 - accuracy: 0.8558 - val_loss: 0.4322 - val_accuracy: 0.8550\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4207 - accuracy: 0.8558 - val_loss: 0.4335 - val_accuracy: 0.8560\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4200 - accuracy: 0.8552 - val_loss: 0.4307 - val_accuracy: 0.8528\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4194 - accuracy: 0.8562 - val_loss: 0.4306 - val_accuracy: 0.8536\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4187 - accuracy: 0.8562 - val_loss: 0.4333 - val_accuracy: 0.8524\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4179 - accuracy: 0.8570 - val_loss: 0.4294 - val_accuracy: 0.8554\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4173 - accuracy: 0.8567 - val_loss: 0.4299 - val_accuracy: 0.8554\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4168 - accuracy: 0.8565 - val_loss: 0.4280 - val_accuracy: 0.8528\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4160 - accuracy: 0.8578 - val_loss: 0.4280 - val_accuracy: 0.8540\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4155 - accuracy: 0.8569 - val_loss: 0.4274 - val_accuracy: 0.8554\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4148 - accuracy: 0.8578 - val_loss: 0.4344 - val_accuracy: 0.8532\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4147 - accuracy: 0.8580 - val_loss: 0.4303 - val_accuracy: 0.8568\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4139 - accuracy: 0.8575 - val_loss: 0.4300 - val_accuracy: 0.8536\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4134 - accuracy: 0.8573 - val_loss: 0.4280 - val_accuracy: 0.8556\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4127 - accuracy: 0.8577 - val_loss: 0.4264 - val_accuracy: 0.8556\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4121 - accuracy: 0.8589 - val_loss: 0.4267 - val_accuracy: 0.8546\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4117 - accuracy: 0.8587 - val_loss: 0.4283 - val_accuracy: 0.8562\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4109 - accuracy: 0.8596 - val_loss: 0.4265 - val_accuracy: 0.8542\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4108 - accuracy: 0.8588 - val_loss: 0.4250 - val_accuracy: 0.8544\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4101 - accuracy: 0.8581 - val_loss: 0.4259 - val_accuracy: 0.8582\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4097 - accuracy: 0.8588 - val_loss: 0.4244 - val_accuracy: 0.8562\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4091 - accuracy: 0.8592 - val_loss: 0.4243 - val_accuracy: 0.8566\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4087 - accuracy: 0.8597 - val_loss: 0.4267 - val_accuracy: 0.8550\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4085 - accuracy: 0.8587 - val_loss: 0.4240 - val_accuracy: 0.8564\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4076 - accuracy: 0.8600 - val_loss: 0.4254 - val_accuracy: 0.8546\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4076 - accuracy: 0.8589 - val_loss: 0.4235 - val_accuracy: 0.8552\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4069 - accuracy: 0.8599 - val_loss: 0.4233 - val_accuracy: 0.8568\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4066 - accuracy: 0.8597 - val_loss: 0.4240 - val_accuracy: 0.8570\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4062 - accuracy: 0.8598 - val_loss: 0.4231 - val_accuracy: 0.8564\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4058 - accuracy: 0.8598 - val_loss: 0.4218 - val_accuracy: 0.8558\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4054 - accuracy: 0.8599 - val_loss: 0.4223 - val_accuracy: 0.8556\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4049 - accuracy: 0.8596 - val_loss: 0.4221 - val_accuracy: 0.8568\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4045 - accuracy: 0.8607 - val_loss: 0.4227 - val_accuracy: 0.8558\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4041 - accuracy: 0.8609 - val_loss: 0.4227 - val_accuracy: 0.8576\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4039 - accuracy: 0.8610 - val_loss: 0.4204 - val_accuracy: 0.8560\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4033 - accuracy: 0.8609 - val_loss: 0.4236 - val_accuracy: 0.8568\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4033 - accuracy: 0.8607 - val_loss: 0.4210 - val_accuracy: 0.8550\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4027 - accuracy: 0.8614 - val_loss: 0.4213 - val_accuracy: 0.8568: 0.4026 \n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4019 - accuracy: 0.8608 - val_loss: 0.4216 - val_accuracy: 0.8566\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4018 - accuracy: 0.8616 - val_loss: 0.4221 - val_accuracy: 0.8562\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4017 - accuracy: 0.8613 - val_loss: 0.4201 - val_accuracy: 0.8570\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4011 - accuracy: 0.8618 - val_loss: 0.4215 - val_accuracy: 0.8570\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4010 - accuracy: 0.8624 - val_loss: 0.4205 - val_accuracy: 0.8568\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4004 - accuracy: 0.8616 - val_loss: 0.4195 - val_accuracy: 0.8576\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4001 - accuracy: 0.8625 - val_loss: 0.4200 - val_accuracy: 0.8556\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.3999 - accuracy: 0.8621 - val_loss: 0.4203 - val_accuracy: 0.8558\n",
      "18333/18333 [==============================] - 0s 18us/sample - loss: 0.4237 - accuracy: 0.8571\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0584 - accuracy: 0.6839 - val_loss: 0.7722 - val_accuracy: 0.7680\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.7256 - accuracy: 0.7722 - val_loss: 0.6664 - val_accuracy: 0.7956\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.6508 - accuracy: 0.7932 - val_loss: 0.6145 - val_accuracy: 0.8056\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.6092 - accuracy: 0.8054 - val_loss: 0.5854 - val_accuracy: 0.8096\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5823 - accuracy: 0.8113 - val_loss: 0.5618 - val_accuracy: 0.8210\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5626 - accuracy: 0.8163 - val_loss: 0.5468 - val_accuracy: 0.8258\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5473 - accuracy: 0.8205 - val_loss: 0.5373 - val_accuracy: 0.8310\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5349 - accuracy: 0.8242 - val_loss: 0.5227 - val_accuracy: 0.8326\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5247 - accuracy: 0.8267 - val_loss: 0.5159 - val_accuracy: 0.8318\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5164 - accuracy: 0.8302 - val_loss: 0.5081 - val_accuracy: 0.8378\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5087 - accuracy: 0.8313 - val_loss: 0.5018 - val_accuracy: 0.8380\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5022 - accuracy: 0.8329 - val_loss: 0.4957 - val_accuracy: 0.8404\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4965 - accuracy: 0.8344 - val_loss: 0.4909 - val_accuracy: 0.8432\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4914 - accuracy: 0.8368 - val_loss: 0.4891 - val_accuracy: 0.8416\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4870 - accuracy: 0.8377 - val_loss: 0.4849 - val_accuracy: 0.8434\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4825 - accuracy: 0.8393 - val_loss: 0.4788 - val_accuracy: 0.8438\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4787 - accuracy: 0.8402 - val_loss: 0.4797 - val_accuracy: 0.8418\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4751 - accuracy: 0.8414 - val_loss: 0.4760 - val_accuracy: 0.8430\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4719 - accuracy: 0.8420 - val_loss: 0.4723 - val_accuracy: 0.8418\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4688 - accuracy: 0.8423 - val_loss: 0.4705 - val_accuracy: 0.8444\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4662 - accuracy: 0.8435 - val_loss: 0.4697 - val_accuracy: 0.8464\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4634 - accuracy: 0.8445 - val_loss: 0.4650 - val_accuracy: 0.8472\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4611 - accuracy: 0.8455 - val_loss: 0.4633 - val_accuracy: 0.8458\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4585 - accuracy: 0.8460 - val_loss: 0.4639 - val_accuracy: 0.8476\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4565 - accuracy: 0.8460 - val_loss: 0.4585 - val_accuracy: 0.8486\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4546 - accuracy: 0.8473 - val_loss: 0.4564 - val_accuracy: 0.8500\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4525 - accuracy: 0.8471 - val_loss: 0.4552 - val_accuracy: 0.8494\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4506 - accuracy: 0.8483 - val_loss: 0.4532 - val_accuracy: 0.8520\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4486 - accuracy: 0.8490 - val_loss: 0.4532 - val_accuracy: 0.8522\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4472 - accuracy: 0.8481 - val_loss: 0.4509 - val_accuracy: 0.8524\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4457 - accuracy: 0.8495 - val_loss: 0.4498 - val_accuracy: 0.8514\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4440 - accuracy: 0.8505 - val_loss: 0.4503 - val_accuracy: 0.8502\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4427 - accuracy: 0.8501 - val_loss: 0.4495 - val_accuracy: 0.8534\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4410 - accuracy: 0.8498 - val_loss: 0.4492 - val_accuracy: 0.8524\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4399 - accuracy: 0.8509 - val_loss: 0.4454 - val_accuracy: 0.8522\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4385 - accuracy: 0.8509 - val_loss: 0.4453 - val_accuracy: 0.8528\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4371 - accuracy: 0.8520 - val_loss: 0.4461 - val_accuracy: 0.8530\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4362 - accuracy: 0.8507 - val_loss: 0.4439 - val_accuracy: 0.8548\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4349 - accuracy: 0.8518 - val_loss: 0.4428 - val_accuracy: 0.8538\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4338 - accuracy: 0.8533 - val_loss: 0.4423 - val_accuracy: 0.8554\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4329 - accuracy: 0.8525 - val_loss: 0.4411 - val_accuracy: 0.8532\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4315 - accuracy: 0.8529 - val_loss: 0.4416 - val_accuracy: 0.8534\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4305 - accuracy: 0.8546 - val_loss: 0.4406 - val_accuracy: 0.8544\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4298 - accuracy: 0.8535 - val_loss: 0.4395 - val_accuracy: 0.8546\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4288 - accuracy: 0.8538 - val_loss: 0.4379 - val_accuracy: 0.8554\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4279 - accuracy: 0.8547 - val_loss: 0.4372 - val_accuracy: 0.8536\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4270 - accuracy: 0.8534 - val_loss: 0.4397 - val_accuracy: 0.8548\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4258 - accuracy: 0.8541 - val_loss: 0.4382 - val_accuracy: 0.8538\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4251 - accuracy: 0.8552 - val_loss: 0.4388 - val_accuracy: 0.8542\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4244 - accuracy: 0.8551 - val_loss: 0.4367 - val_accuracy: 0.8534\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4237 - accuracy: 0.8552 - val_loss: 0.4339 - val_accuracy: 0.8552\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4229 - accuracy: 0.8553 - val_loss: 0.4332 - val_accuracy: 0.8576\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4220 - accuracy: 0.8561 - val_loss: 0.4334 - val_accuracy: 0.8568\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4211 - accuracy: 0.8559 - val_loss: 0.4331 - val_accuracy: 0.8570\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4206 - accuracy: 0.8563 - val_loss: 0.4324 - val_accuracy: 0.8566\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4199 - accuracy: 0.8566 - val_loss: 0.4316 - val_accuracy: 0.8568\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4190 - accuracy: 0.8562 - val_loss: 0.4308 - val_accuracy: 0.8576\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4182 - accuracy: 0.8574 - val_loss: 0.4314 - val_accuracy: 0.8564\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4179 - accuracy: 0.8578 - val_loss: 0.4325 - val_accuracy: 0.8558\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4172 - accuracy: 0.8575 - val_loss: 0.4338 - val_accuracy: 0.8556\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4166 - accuracy: 0.8577 - val_loss: 0.4302 - val_accuracy: 0.8570\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4162 - accuracy: 0.8579 - val_loss: 0.4308 - val_accuracy: 0.8560\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4154 - accuracy: 0.8582 - val_loss: 0.4294 - val_accuracy: 0.8586\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4146 - accuracy: 0.8581 - val_loss: 0.4308 - val_accuracy: 0.8546\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4142 - accuracy: 0.8588 - val_loss: 0.4294 - val_accuracy: 0.8564\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4137 - accuracy: 0.8588 - val_loss: 0.4293 - val_accuracy: 0.8576\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4132 - accuracy: 0.8592 - val_loss: 0.4281 - val_accuracy: 0.8570s - loss: 0.4133 - accuracy: 0.85\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4126 - accuracy: 0.8590 - val_loss: 0.4271 - val_accuracy: 0.8580\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4121 - accuracy: 0.8583 - val_loss: 0.4279 - val_accuracy: 0.8564\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4115 - accuracy: 0.8589 - val_loss: 0.4276 - val_accuracy: 0.8550\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4109 - accuracy: 0.8598 - val_loss: 0.4268 - val_accuracy: 0.8570s - loss: 0.4107 - accu\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4105 - accuracy: 0.8596 - val_loss: 0.4305 - val_accuracy: 0.8556\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4100 - accuracy: 0.8606 - val_loss: 0.4272 - val_accuracy: 0.8562\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4097 - accuracy: 0.8599 - val_loss: 0.4261 - val_accuracy: 0.8564 - accuracy - ETA: 0s - loss: 0.4106 - accuracy: 0.\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4089 - accuracy: 0.8601 - val_loss: 0.4298 - val_accuracy: 0.8560\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4087 - accuracy: 0.8601 - val_loss: 0.4252 - val_accuracy: 0.8564\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4079 - accuracy: 0.8610 - val_loss: 0.4279 - val_accuracy: 0.8558\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4077 - accuracy: 0.8602 - val_loss: 0.4247 - val_accuracy: 0.8582\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4073 - accuracy: 0.8613 - val_loss: 0.4261 - val_accuracy: 0.8552ss: 0.4065 - accuracy: 0. - ETA: 0s - loss: 0.4095 - ac\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4069 - accuracy: 0.8607 - val_loss: 0.4261 - val_accuracy: 0.8542\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4063 - accuracy: 0.8607 - val_loss: 0.4245 - val_accuracy: 0.8572\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4058 - accuracy: 0.8616 - val_loss: 0.4239 - val_accuracy: 0.8586\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4056 - accuracy: 0.8611 - val_loss: 0.4256 - val_accuracy: 0.8572\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4050 - accuracy: 0.8617 - val_loss: 0.4238 - val_accuracy: 0.8580\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4047 - accuracy: 0.8611 - val_loss: 0.4231 - val_accuracy: 0.8586\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4045 - accuracy: 0.8618 - val_loss: 0.4222 - val_accuracy: 0.8582\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4036 - accuracy: 0.8619 - val_loss: 0.4258 - val_accuracy: 0.8574\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4036 - accuracy: 0.8618 - val_loss: 0.4224 - val_accuracy: 0.8568\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4031 - accuracy: 0.8621 - val_loss: 0.4234 - val_accuracy: 0.8576\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4030 - accuracy: 0.8619 - val_loss: 0.4239 - val_accuracy: 0.8592\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4021 - accuracy: 0.8622 - val_loss: 0.4232 - val_accuracy: 0.8562\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4020 - accuracy: 0.8619 - val_loss: 0.4255 - val_accuracy: 0.8576\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4018 - accuracy: 0.8627 - val_loss: 0.4240 - val_accuracy: 0.8576\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4014 - accuracy: 0.8627 - val_loss: 0.4228 - val_accuracy: 0.8560\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4011 - accuracy: 0.8625 - val_loss: 0.4216 - val_accuracy: 0.8602\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4007 - accuracy: 0.8625 - val_loss: 0.4232 - val_accuracy: 0.8580\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4005 - accuracy: 0.8629 - val_loss: 0.4232 - val_accuracy: 0.8568\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4000 - accuracy: 0.8632 - val_loss: 0.4219 - val_accuracy: 0.8590\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.3995 - accuracy: 0.8632 - val_loss: 0.4220 - val_accuracy: 0.8576\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.3992 - accuracy: 0.8630 - val_loss: 0.4230 - val_accuracy: 0.8588 accura\n",
      "18333/18333 [==============================] - 0s 18us/sample - loss: 0.4275 - accuracy: 0.8534\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.4829 - accuracy: 0.5328 - val_loss: 1.0261 - val_accuracy: 0.6790\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.8958 - accuracy: 0.7158 - val_loss: 0.7925 - val_accuracy: 0.7472\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.7485 - accuracy: 0.7621 - val_loss: 0.6970 - val_accuracy: 0.7724\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.6751 - accuracy: 0.7833 - val_loss: 0.6419 - val_accuracy: 0.7892\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.6283 - accuracy: 0.7981 - val_loss: 0.6027 - val_accuracy: 0.8068\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5952 - accuracy: 0.8073 - val_loss: 0.5758 - val_accuracy: 0.8152\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5709 - accuracy: 0.8141 - val_loss: 0.5558 - val_accuracy: 0.8222\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5518 - accuracy: 0.8188 - val_loss: 0.5378 - val_accuracy: 0.8232\n",
      "Epoch 9/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5365 - accuracy: 0.8225 - val_loss: 0.5284 - val_accuracy: 0.8248\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5238 - accuracy: 0.8257 - val_loss: 0.5130 - val_accuracy: 0.8302\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5128 - accuracy: 0.8280 - val_loss: 0.5037 - val_accuracy: 0.8348\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5035 - accuracy: 0.8309 - val_loss: 0.4996 - val_accuracy: 0.8310\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4957 - accuracy: 0.8331 - val_loss: 0.4879 - val_accuracy: 0.8380\n",
      "Epoch 14/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4881 - accuracy: 0.8364 - val_loss: 0.4820 - val_accuracy: 0.8382: 0.4862 \n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4817 - accuracy: 0.8366 - val_loss: 0.4781 - val_accuracy: 0.84184872 \n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4758 - accuracy: 0.8395 - val_loss: 0.4718 - val_accuracy: 0.8436\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4707 - accuracy: 0.8400 - val_loss: 0.4690 - val_accuracy: 0.8448\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4658 - accuracy: 0.8421 - val_loss: 0.4648 - val_accuracy: 0.8466- loss: 0.4613 - accura\n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4612 - accuracy: 0.8438 - val_loss: 0.4591 - val_accuracy: 0.8492\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4571 - accuracy: 0.8445 - val_loss: 0.4556 - val_accuracy: 0.8500\n",
      "Epoch 21/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4530 - accuracy: 0.8456 - val_loss: 0.4534 - val_accuracy: 0.8512\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4492 - accuracy: 0.8468 - val_loss: 0.4481 - val_accuracy: 0.8534\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4460 - accuracy: 0.8474 - val_loss: 0.4457 - val_accuracy: 0.8528\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4425 - accuracy: 0.8498 - val_loss: 0.4473 - val_accuracy: 0.8516\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4396 - accuracy: 0.8496 - val_loss: 0.4436 - val_accuracy: 0.8534- loss: 0.4406 - accura - ETA: 0s - loss: 0.4385 - \n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4365 - accuracy: 0.8503 - val_loss: 0.4396 - val_accuracy: 0.8558\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4338 - accuracy: 0.8531 - val_loss: 0.4366 - val_accuracy: 0.8574\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4309 - accuracy: 0.8533 - val_loss: 0.4411 - val_accuracy: 0.8548\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4282 - accuracy: 0.8546 - val_loss: 0.4327 - val_accuracy: 0.8590\n",
      "Epoch 30/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4256 - accuracy: 0.8559 - val_loss: 0.4311 - val_accuracy: 0.8592\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4229 - accuracy: 0.8555 - val_loss: 0.4269 - val_accuracy: 0.8596\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4208 - accuracy: 0.8563 - val_loss: 0.4293 - val_accuracy: 0.8592\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4189 - accuracy: 0.8561 - val_loss: 0.4240 - val_accuracy: 0.85820.4183 - accuracy: 0. - ETA: 0s - loss: 0.4170 - ac - ETA: 0s - loss: 0.4184 - accuracy: 0.\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4166 - accuracy: 0.8571 - val_loss: 0.4217 - val_accuracy: 0.8616\n",
      "Epoch 35/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4144 - accuracy: 0.8571 - val_loss: 0.4238 - val_accuracy: 0.8596\n",
      "Epoch 36/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4124 - accuracy: 0.8582 - val_loss: 0.4254 - val_accuracy: 0.8596\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4104 - accuracy: 0.8602 - val_loss: 0.4180 - val_accuracy: 0.8634\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4086 - accuracy: 0.8598 - val_loss: 0.4167 - val_accuracy: 0.8626\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4069 - accuracy: 0.8603 - val_loss: 0.4149 - val_accuracy: 0.8626\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4048 - accuracy: 0.8613 - val_loss: 0.4139 - val_accuracy: 0.8626\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4032 - accuracy: 0.8621 - val_loss: 0.4123 - val_accuracy: 0.8648\n",
      "Epoch 42/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4014 - accuracy: 0.8624 - val_loss: 0.4120 - val_accuracy: 0.8630- loss: 0.4018 - accuracy\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3999 - accuracy: 0.8627 - val_loss: 0.4097 - val_accuracy: 0.8638\n",
      "Epoch 44/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3985 - accuracy: 0.8632 - val_loss: 0.4090 - val_accuracy: 0.8654\n",
      "Epoch 45/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3968 - accuracy: 0.8640 - val_loss: 0.4085 - val_accuracy: 0.8638\n",
      "Epoch 46/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3950 - accuracy: 0.8650 - val_loss: 0.4066 - val_accuracy: 0.8662\n",
      "Epoch 47/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3937 - accuracy: 0.8647 - val_loss: 0.4145 - val_accuracy: 0.8616\n",
      "Epoch 48/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3919 - accuracy: 0.8651 - val_loss: 0.4044 - val_accuracy: 0.8650\n",
      "Epoch 49/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3905 - accuracy: 0.8659 - val_loss: 0.4025 - val_accuracy: 0.8656\n",
      "Epoch 50/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3887 - accuracy: 0.8660 - val_loss: 0.4038 - val_accuracy: 0.8636\n",
      "Epoch 51/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3876 - accuracy: 0.8668 - val_loss: 0.4058 - val_accuracy: 0.8640\n",
      "Epoch 52/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3863 - accuracy: 0.8670 - val_loss: 0.4017 - val_accuracy: 0.8656\n",
      "Epoch 53/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3851 - accuracy: 0.8679 - val_loss: 0.3989 - val_accuracy: 0.8682 0.86\n",
      "Epoch 54/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3840 - accuracy: 0.8669 - val_loss: 0.3995 - val_accuracy: 0.8652\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3824 - accuracy: 0.8683 - val_loss: 0.3981 - val_accuracy: 0.8650\n",
      "Epoch 56/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3808 - accuracy: 0.8688 - val_loss: 0.3997 - val_accuracy: 0.8656\n",
      "Epoch 57/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3799 - accuracy: 0.8676 - val_loss: 0.4022 - val_accuracy: 0.8660\n",
      "Epoch 58/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3787 - accuracy: 0.8699 - val_loss: 0.3980 - val_accuracy: 0.8666\n",
      "Epoch 59/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3773 - accuracy: 0.8713 - val_loss: 0.3952 - val_accuracy: 0.8662\n",
      "Epoch 60/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3759 - accuracy: 0.8702 - val_loss: 0.3943 - val_accuracy: 0.8660\n",
      "Epoch 61/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3750 - accuracy: 0.8705 - val_loss: 0.3940 - val_accuracy: 0.8676\n",
      "Epoch 62/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3737 - accuracy: 0.8717 - val_loss: 0.3940 - val_accuracy: 0.8698\n",
      "Epoch 63/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3728 - accuracy: 0.8717 - val_loss: 0.3936 - val_accuracy: 0.8662\n",
      "Epoch 64/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3716 - accuracy: 0.8732 - val_loss: 0.3916 - val_accuracy: 0.8682\n",
      "Epoch 65/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3704 - accuracy: 0.8726 - val_loss: 0.3898 - val_accuracy: 0.8684\n",
      "Epoch 66/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3694 - accuracy: 0.8735 - val_loss: 0.3899 - val_accuracy: 0.8684\n",
      "Epoch 67/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3683 - accuracy: 0.8743 - val_loss: 0.3885 - val_accuracy: 0.8680\n",
      "Epoch 68/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3674 - accuracy: 0.8737 - val_loss: 0.3881 - val_accuracy: 0.8670ss: 0.3651 - accuracy - ETA: 0s - loss: 0.3677 - accuracy: 0.87\n",
      "Epoch 69/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3664 - accuracy: 0.8742 - val_loss: 0.3869 - val_accuracy: 0.868462 - accuracy\n",
      "Epoch 70/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3656 - accuracy: 0.8749 - val_loss: 0.3860 - val_accuracy: 0.8688\n",
      "Epoch 71/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3639 - accuracy: 0.8752 - val_loss: 0.3900 - val_accuracy: 0.8646\n",
      "Epoch 72/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3632 - accuracy: 0.8754 - val_loss: 0.3835 - val_accuracy: 0.8698\n",
      "Epoch 73/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3621 - accuracy: 0.8753 - val_loss: 0.3851 - val_accuracy: 0.8710\n",
      "Epoch 74/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3610 - accuracy: 0.8756 - val_loss: 0.3873 - val_accuracy: 0.8694\n",
      "Epoch 75/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3602 - accuracy: 0.8765 - val_loss: 0.3829 - val_accuracy: 0.8720 ac\n",
      "Epoch 76/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3593 - accuracy: 0.8771 - val_loss: 0.3849 - val_accuracy: 0.8668\n",
      "Epoch 77/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3584 - accuracy: 0.8774 - val_loss: 0.3865 - val_accuracy: 0.8680\n",
      "Epoch 78/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3575 - accuracy: 0.8777 - val_loss: 0.3834 - val_accuracy: 0.8718\n",
      "Epoch 79/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3565 - accuracy: 0.8784 - val_loss: 0.3828 - val_accuracy: 0.8714\n",
      "Epoch 80/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3554 - accuracy: 0.8789 - val_loss: 0.3848 - val_accuracy: 0.8690\n",
      "Epoch 81/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3546 - accuracy: 0.8788 - val_loss: 0.3827 - val_accuracy: 0.870023 - accu\n",
      "Epoch 82/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3540 - accuracy: 0.8797 - val_loss: 0.3795 - val_accuracy: 0.8710\n",
      "Epoch 83/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3530 - accuracy: 0.8789 - val_loss: 0.3780 - val_accuracy: 0.8722\n",
      "Epoch 84/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3522 - accuracy: 0.8797 - val_loss: 0.3805 - val_accuracy: 0.8714s - loss: 0.3488 - accuracy:  - ETA: 0s - loss: 0.3547 - accuracy - ETA: 0s - loss: 0.3503 \n",
      "Epoch 85/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3512 - accuracy: 0.8798 - val_loss: 0.3798 - val_accuracy: 0.8688\n",
      "Epoch 86/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3501 - accuracy: 0.8804 - val_loss: 0.3786 - val_accuracy: 0.87260.3505 \n",
      "Epoch 87/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3494 - accuracy: 0.8810 - val_loss: 0.3767 - val_accuracy: 0.8730\n",
      "Epoch 88/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3487 - accuracy: 0.8813 - val_loss: 0.3799 - val_accuracy: 0.8716\n",
      "Epoch 89/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3479 - accuracy: 0.8812 - val_loss: 0.3775 - val_accuracy: 0.8706\n",
      "Epoch 90/100\n",
      "36666/36666 [==============================] - ETA: 0s - loss: 0.3465 - accuracy: 0.88 - 1s 36us/sample - loss: 0.3470 - accuracy: 0.8815 - val_loss: 0.3755 - val_accuracy: 0.8726\n",
      "Epoch 91/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3460 - accuracy: 0.8812 - val_loss: 0.3750 - val_accuracy: 0.8718\n",
      "Epoch 92/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3455 - accuracy: 0.8819 - val_loss: 0.3768 - val_accuracy: 0.8714 - accuracy: \n",
      "Epoch 93/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3441 - accuracy: 0.8819 - val_loss: 0.3793 - val_accuracy: 0.8714\n",
      "Epoch 94/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3437 - accuracy: 0.8826 - val_loss: 0.3754 - val_accuracy: 0.8726\n",
      "Epoch 95/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3425 - accuracy: 0.8831 - val_loss: 0.3732 - val_accuracy: 0.8726\n",
      "Epoch 96/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3419 - accuracy: 0.8827 - val_loss: 0.3782 - val_accuracy: 0.8728\n",
      "Epoch 97/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3412 - accuracy: 0.8834 - val_loss: 0.3748 - val_accuracy: 0.8700\n",
      "Epoch 98/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3407 - accuracy: 0.8838 - val_loss: 0.3735 - val_accuracy: 0.8728\n",
      "Epoch 99/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3400 - accuracy: 0.8837 - val_loss: 0.3742 - val_accuracy: 0.8738\n",
      "Epoch 100/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3388 - accuracy: 0.8841 - val_loss: 0.3729 - val_accuracy: 0.8738\n",
      "18334/18334 [==============================] - 0s 24us/sample - loss: 0.3880 - accuracy: 0.8618\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.4283 - accuracy: 0.5420 - val_loss: 0.9739 - val_accuracy: 0.6994\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.8620 - accuracy: 0.7222 - val_loss: 0.7628 - val_accuracy: 0.7538\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.7294 - accuracy: 0.7622 - val_loss: 0.6776 - val_accuracy: 0.7758- l\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6636 - accuracy: 0.7824 - val_loss: 0.6296 - val_accuracy: 0.7932uracy\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6211 - accuracy: 0.7938 - val_loss: 0.5960 - val_accuracy: 0.80246217 - accuracy: 0.79\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5913 - accuracy: 0.8026 - val_loss: 0.5678 - val_accuracy: 0.8102\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - ETA: 0s - loss: 0.5688 - accuracy: 0.80 - 1s 33us/sample - loss: 0.5686 - accuracy: 0.8088 - val_loss: 0.5514 - val_accuracy: 0.8170\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5509 - accuracy: 0.8138 - val_loss: 0.5352 - val_accuracy: 0.8232\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5365 - accuracy: 0.8179 - val_loss: 0.5224 - val_accuracy: 0.8270\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5246 - accuracy: 0.8210 - val_loss: 0.5122 - val_accuracy: 0.8322\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5145 - accuracy: 0.8242 - val_loss: 0.5030 - val_accuracy: 0.8332\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5059 - accuracy: 0.8260 - val_loss: 0.4943 - val_accuracy: 0.8366\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4982 - accuracy: 0.8287 - val_loss: 0.4902 - val_accuracy: 0.8356\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4914 - accuracy: 0.8289 - val_loss: 0.4834 - val_accuracy: 0.8404\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4855 - accuracy: 0.8315 - val_loss: 0.4777 - val_accuracy: 0.8408\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4799 - accuracy: 0.8333 - val_loss: 0.4760 - val_accuracy: 0.8388\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4747 - accuracy: 0.8354 - val_loss: 0.4681 - val_accuracy: 0.8438\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4701 - accuracy: 0.8367 - val_loss: 0.4652 - val_accuracy: 0.8432\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4660 - accuracy: 0.8382 - val_loss: 0.4621 - val_accuracy: 0.8456\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4622 - accuracy: 0.8400 - val_loss: 0.4569 - val_accuracy: 0.8484\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4583 - accuracy: 0.8406 - val_loss: 0.4549 - val_accuracy: 0.8480\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - ETA: 0s - loss: 0.4549 - accuracy: 0.84 - 1s 33us/sample - loss: 0.4546 - accuracy: 0.8421 - val_loss: 0.4508 - val_accuracy: 0.8500\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4518 - accuracy: 0.8427 - val_loss: 0.4489 - val_accuracy: 0.8490\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4487 - accuracy: 0.8431 - val_loss: 0.4469 - val_accuracy: 0.8498\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4456 - accuracy: 0.8443 - val_loss: 0.4435 - val_accuracy: 0.8532\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4433 - accuracy: 0.8448 - val_loss: 0.4484 - val_accuracy: 0.8472\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4408 - accuracy: 0.8460 - val_loss: 0.4389 - val_accuracy: 0.8528\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4381 - accuracy: 0.8462 - val_loss: 0.4380 - val_accuracy: 0.8528ss: 0.4369  - ETA: 0s - loss: 0.4396 - accuracy: 0.\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4358 - accuracy: 0.8469 - val_loss: 0.4359 - val_accuracy: 0.8544\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4332 - accuracy: 0.8481 - val_loss: 0.4344 - val_accuracy: 0.8514y: 0.84\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4308 - accuracy: 0.8493 - val_loss: 0.4317 - val_accuracy: 0.8542\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4290 - accuracy: 0.8493 - val_loss: 0.4315 - val_accuracy: 0.8528 - accu\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4267 - accuracy: 0.8499 - val_loss: 0.4298 - val_accuracy: 0.8526\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4246 - accuracy: 0.8509 - val_loss: 0.4279 - val_accuracy: 0.8550\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4230 - accuracy: 0.8521 - val_loss: 0.4259 - val_accuracy: 0.8554\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4210 - accuracy: 0.8526 - val_loss: 0.4236 - val_accuracy: 0.8576\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4194 - accuracy: 0.8539 - val_loss: 0.4249 - val_accuracy: 0.8546\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4172 - accuracy: 0.8546 - val_loss: 0.4211 - val_accuracy: 0.8556\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4157 - accuracy: 0.8550 - val_loss: 0.4200 - val_accuracy: 0.8550\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4136 - accuracy: 0.8549 - val_loss: 0.4195 - val_accuracy: 0.8552\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4120 - accuracy: 0.8557 - val_loss: 0.4178 - val_accuracy: 0.8578\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4105 - accuracy: 0.8566 - val_loss: 0.4166 - val_accuracy: 0.8580\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4091 - accuracy: 0.8578 - val_loss: 0.4153 - val_accuracy: 0.8594\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4073 - accuracy: 0.8576 - val_loss: 0.4132 - val_accuracy: 0.8582\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4057 - accuracy: 0.8573 - val_loss: 0.4141 - val_accuracy: 0.8590 - accu\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4047 - accuracy: 0.8578 - val_loss: 0.4126 - val_accuracy: 0.8570\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4031 - accuracy: 0.8586 - val_loss: 0.4120 - val_accuracy: 0.8596\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4016 - accuracy: 0.8594 - val_loss: 0.4106 - val_accuracy: 0.8620\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4000 - accuracy: 0.8597 - val_loss: 0.4135 - val_accuracy: 0.8576\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3987 - accuracy: 0.8601 - val_loss: 0.4073 - val_accuracy: 0.8594\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3974 - accuracy: 0.8609 - val_loss: 0.4094 - val_accuracy: 0.8626\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3959 - accuracy: 0.8612 - val_loss: 0.4088 - val_accuracy: 0.8604\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3950 - accuracy: 0.8622 - val_loss: 0.4060 - val_accuracy: 0.8586\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3936 - accuracy: 0.8619 - val_loss: 0.4113 - val_accuracy: 0.8588\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3930 - accuracy: 0.8618 - val_loss: 0.4042 - val_accuracy: 0.8626\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3914 - accuracy: 0.8620 - val_loss: 0.4043 - val_accuracy: 0.8584\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3903 - accuracy: 0.8627 - val_loss: 0.4041 - val_accuracy: 0.8630\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3892 - accuracy: 0.8629 - val_loss: 0.4041 - val_accuracy: 0.8574: 0.3901 - accu - ETA: 0s - loss: 0.3918 - accuracy: \n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3879 - accuracy: 0.8646 - val_loss: 0.4038 - val_accuracy: 0.8634\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3869 - accuracy: 0.8642 - val_loss: 0.3986 - val_accuracy: 0.8618ura\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3855 - accuracy: 0.8650 - val_loss: 0.4015 - val_accuracy: 0.8624\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3847 - accuracy: 0.8649 - val_loss: 0.3984 - val_accuracy: 0.8630\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3837 - accuracy: 0.8648 - val_loss: 0.3973 - val_accuracy: 0.8624\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3827 - accuracy: 0.8651 - val_loss: 0.3967 - val_accuracy: 0.8624\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3817 - accuracy: 0.8654 - val_loss: 0.3957 - val_accuracy: 0.8620\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3806 - accuracy: 0.8664 - val_loss: 0.3951 - val_accuracy: 0.8622\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3797 - accuracy: 0.8662 - val_loss: 0.3962 - val_accuracy: 0.8620- loss: 0.377 - ETA: 0s - loss: 0.3781 - accura\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3788 - accuracy: 0.8686 - val_loss: 0.3928 - val_accuracy: 0.8630- los\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3774 - accuracy: 0.8670 - val_loss: 0.3970 - val_accuracy: 0.8602\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3765 - accuracy: 0.8679 - val_loss: 0.3922 - val_accuracy: 0.8612\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3756 - accuracy: 0.8695 - val_loss: 0.3969 - val_accuracy: 0.8622\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3745 - accuracy: 0.8683 - val_loss: 0.3933 - val_accuracy: 0.8616\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3738 - accuracy: 0.8683 - val_loss: 0.3908 - val_accuracy: 0.8622\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3731 - accuracy: 0.8697 - val_loss: 0.3893 - val_accuracy: 0.8622\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3721 - accuracy: 0.8697 - val_loss: 0.3913 - val_accuracy: 0.8628\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3711 - accuracy: 0.8697 - val_loss: 0.3917 - val_accuracy: 0.8652ss: 0.3716 - accura\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3705 - accuracy: 0.8697 - val_loss: 0.3916 - val_accuracy: 0.8648\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3693 - accuracy: 0.8708 - val_loss: 0.3905 - val_accuracy: 0.8644\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3687 - accuracy: 0.8704 - val_loss: 0.3920 - val_accuracy: 0.8612\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3682 - accuracy: 0.8707 - val_loss: 0.3889 - val_accuracy: 0.8626\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3669 - accuracy: 0.8708 - val_loss: 0.3891 - val_accuracy: 0.8640\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3662 - accuracy: 0.8698 - val_loss: 0.3884 - val_accuracy: 0.8618\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3654 - accuracy: 0.8714 - val_loss: 0.3872 - val_accuracy: 0.8642\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3646 - accuracy: 0.8721 - val_loss: 0.3907 - val_accuracy: 0.8630\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3639 - accuracy: 0.8720 - val_loss: 0.3887 - val_accuracy: 0.8644 - \n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3629 - accuracy: 0.8724 - val_loss: 0.3843 - val_accuracy: 0.8630\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3624 - accuracy: 0.8734 - val_loss: 0.3868 - val_accuracy: 0.8648\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3616 - accuracy: 0.8733 - val_loss: 0.3856 - val_accuracy: 0.8656\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3606 - accuracy: 0.8746 - val_loss: 0.3878 - val_accuracy: 0.8624\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3602 - accuracy: 0.8731 - val_loss: 0.3859 - val_accuracy: 0.8646\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3590 - accuracy: 0.8734 - val_loss: 0.3838 - val_accuracy: 0.8654\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3585 - accuracy: 0.8750 - val_loss: 0.3856 - val_accuracy: 0.8642 \n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3584 - accuracy: 0.8747 - val_loss: 0.3839 - val_accuracy: 0.8646\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3571 - accuracy: 0.8739 - val_loss: 0.3884 - val_accuracy: 0.8656ss: 0.3576 - accura - ETA: 0s - loss: 0.3542 - accuracy\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3563 - accuracy: 0.8746 - val_loss: 0.3823 - val_accuracy: 0.8654\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3555 - accuracy: 0.8757 - val_loss: 0.3841 - val_accuracy: 0.8648\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3547 - accuracy: 0.8756 - val_loss: 0.3857 - val_accuracy: 0.8634: 0.3540 - accuracy: 0.87 - ETA: 0s - loss: 0.3540 - accuracy\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3543 - accuracy: 0.8759 - val_loss: 0.3817 - val_accuracy: 0.8666\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3535 - accuracy: 0.8765 - val_loss: 0.3834 - val_accuracy: 0.8650: 0.3538 - accuracy: 0.87\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3530 - accuracy: 0.8762 - val_loss: 0.3800 - val_accuracy: 0.8668\n",
      "18333/18333 [==============================] - 0s 20us/sample - loss: 0.3905 - accuracy: 0.8651\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.4015 - accuracy: 0.5900 - val_loss: 0.9679 - val_accuracy: 0.6964\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.8711 - accuracy: 0.7155 - val_loss: 0.7728 - val_accuracy: 0.7558\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.7395 - accuracy: 0.7571 - val_loss: 0.6869 - val_accuracy: 0.7786\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6720 - accuracy: 0.7780 - val_loss: 0.6377 - val_accuracy: 0.7942\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6289 - accuracy: 0.7921 - val_loss: 0.6046 - val_accuracy: 0.8068\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5984 - accuracy: 0.8028 - val_loss: 0.5789 - val_accuracy: 0.8126\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5753 - accuracy: 0.8088 - val_loss: 0.5590 - val_accuracy: 0.8230\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5572 - accuracy: 0.8135 - val_loss: 0.5428 - val_accuracy: 0.8244\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - ETA: 0s - loss: 0.5414 - accuracy: 0.8202 ETA: 0s - loss: 0 - 1s 33us/sample - loss: 0.5419 - accuracy: 0.8199 - val_loss: 0.5299 - val_accuracy: 0.8286\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5292 - accuracy: 0.8220 - val_loss: 0.5220 - val_accuracy: 0.82765298 - accuracy: 0.82\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5184 - accuracy: 0.8264 - val_loss: 0.5124 - val_accuracy: 0.8314\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5090 - accuracy: 0.8279 - val_loss: 0.5005 - val_accuracy: 0.8366\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5007 - accuracy: 0.8315 - val_loss: 0.4947 - val_accuracy: 0.8368\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4933 - accuracy: 0.8341 - val_loss: 0.4881 - val_accuracy: 0.8380\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4866 - accuracy: 0.8352 - val_loss: 0.4818 - val_accuracy: 0.8400\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4806 - accuracy: 0.8369 - val_loss: 0.4775 - val_accuracy: 0.8402\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4751 - accuracy: 0.8383 - val_loss: 0.4707 - val_accuracy: 0.8418\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4701 - accuracy: 0.8396 - val_loss: 0.4677 - val_accuracy: 0.8452\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4655 - accuracy: 0.8407 - val_loss: 0.4656 - val_accuracy: 0.8446\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4613 - accuracy: 0.8430 - val_loss: 0.4595 - val_accuracy: 0.845619 - accuracy: 0.\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4571 - accuracy: 0.8447 - val_loss: 0.4587 - val_accuracy: 0.8458\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4537 - accuracy: 0.8457 - val_loss: 0.4528 - val_accuracy: 0.8490\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4500 - accuracy: 0.8461 - val_loss: 0.4512 - val_accuracy: 0.8496\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4464 - accuracy: 0.8482 - val_loss: 0.4504 - val_accuracy: 0.85000.4461 - ac\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4434 - accuracy: 0.8481 - val_loss: 0.4467 - val_accuracy: 0.8500\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4403 - accuracy: 0.8490 - val_loss: 0.4428 - val_accuracy: 0.85144394 - accuracy: \n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4373 - accuracy: 0.8505 - val_loss: 0.4422 - val_accuracy: 0.8520\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4350 - accuracy: 0.8513 - val_loss: 0.4374 - val_accuracy: 0.8496\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4322 - accuracy: 0.8520 - val_loss: 0.4342 - val_accuracy: 0.8560\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4294 - accuracy: 0.8523 - val_loss: 0.4344 - val_accuracy: 0.8538\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4267 - accuracy: 0.8537 - val_loss: 0.4324 - val_accuracy: 0.85720.4318 -  - ETA: 0s - loss: 0.4271 - accuracy: \n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4247 - accuracy: 0.8541 - val_loss: 0.4306 - val_accuracy: 0.8564\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4224 - accuracy: 0.8546 - val_loss: 0.4270 - val_accuracy: 0.8590\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4204 - accuracy: 0.8552 - val_loss: 0.4255 - val_accuracy: 0.8586\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4183 - accuracy: 0.8572 - val_loss: 0.4241 - val_accuracy: 0.8590\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4157 - accuracy: 0.8569 - val_loss: 0.4228 - val_accuracy: 0.8570\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4136 - accuracy: 0.8578 - val_loss: 0.4326 - val_accuracy: 0.8542\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4123 - accuracy: 0.8585 - val_loss: 0.4228 - val_accuracy: 0.8590- loss: 0.4119 - accura\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4102 - accuracy: 0.8593 - val_loss: 0.4262 - val_accuracy: 0.8568\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4084 - accuracy: 0.8594 - val_loss: 0.4172 - val_accuracy: 0.8572\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4068 - accuracy: 0.8598 - val_loss: 0.4143 - val_accuracy: 0.8608\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4050 - accuracy: 0.8602 - val_loss: 0.4146 - val_accuracy: 0.8592\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4031 - accuracy: 0.8609 - val_loss: 0.4129 - val_accuracy: 0.8598.86\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4014 - accuracy: 0.8613 - val_loss: 0.4109 - val_accuracy: 0.8602\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4001 - accuracy: 0.8625 - val_loss: 0.4102 - val_accuracy: 0.8632\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.3981 - accuracy: 0.8627 - val_loss: 0.4105 - val_accuracy: 0.8638\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.3966 - accuracy: 0.8638 - val_loss: 0.4077 - val_accuracy: 0.8634\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3951 - accuracy: 0.8649 - val_loss: 0.4072 - val_accuracy: 0.8656\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3937 - accuracy: 0.8639 - val_loss: 0.4065 - val_accuracy: 0.8620\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.3920 - accuracy: 0.8649 - val_loss: 0.4046 - val_accuracy: 0.8626\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3911 - accuracy: 0.8642 - val_loss: 0.4034 - val_accuracy: 0.8646 - accuracy - ETA: 0s - loss: 0.3909 - accuracy\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3893 - accuracy: 0.8664 - val_loss: 0.4038 - val_accuracy: 0.8664l\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3882 - accuracy: 0.8665 - val_loss: 0.4029 - val_accuracy: 0.8634\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3866 - accuracy: 0.8678 - val_loss: 0.4005 - val_accuracy: 0.8648\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.3853 - accuracy: 0.8663 - val_loss: 0.4020 - val_accuracy: 0.8648\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.3837 - accuracy: 0.8678 - val_loss: 0.4001 - val_accuracy: 0.8660\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3824 - accuracy: 0.8681 - val_loss: 0.4006 - val_accuracy: 0.8636\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3813 - accuracy: 0.8680 - val_loss: 0.3980 - val_accuracy: 0.8662\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3802 - accuracy: 0.8680 - val_loss: 0.3999 - val_accuracy: 0.8660\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3787 - accuracy: 0.8697 - val_loss: 0.3977 - val_accuracy: 0.8668\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.3781 - accuracy: 0.8694 - val_loss: 0.3962 - val_accuracy: 0.8684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3764 - accuracy: 0.8693 - val_loss: 0.4042 - val_accuracy: 0.8648\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3755 - accuracy: 0.8704 - val_loss: 0.3939 - val_accuracy: 0.8682\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3741 - accuracy: 0.8710 - val_loss: 0.3959 - val_accuracy: 0.8668\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 3966s 108ms/sample - loss: 0.3729 - accuracy: 0.8715 - val_loss: 0.3967 - val_accuracy: 0.8686\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3722 - accuracy: 0.8714 - val_loss: 0.3951 - val_accuracy: 0.8678\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3711 - accuracy: 0.8713 - val_loss: 0.3922 - val_accuracy: 0.8678\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3701 - accuracy: 0.8728 - val_loss: 0.3919 - val_accuracy: 0.8664\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.3687 - accuracy: 0.8727 - val_loss: 0.3892 - val_accuracy: 0.8688\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.3678 - accuracy: 0.8721 - val_loss: 0.3913 - val_accuracy: 0.86783660 - accuracy: \n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.3669 - accuracy: 0.8723 - val_loss: 0.3926 - val_accuracy: 0.8704\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 3s 72us/sample - loss: 0.3660 - accuracy: 0.8732 - val_loss: 0.3894 - val_accuracy: 0.8692\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 5s 140us/sample - loss: 0.3649 - accuracy: 0.8734 - val_loss: 0.3890 - val_accuracy: 0.8700\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.3638 - accuracy: 0.8747 - val_loss: 0.3931 - val_accuracy: 0.8676\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 5s 140us/sample - loss: 0.3629 - accuracy: 0.8747 - val_loss: 0.3909 - val_accuracy: 0.8666\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.3617 - accuracy: 0.8750 - val_loss: 0.3861 - val_accuracy: 0.8688\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.3610 - accuracy: 0.8747 - val_loss: 0.3871 - val_accuracy: 0.8690\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.3597 - accuracy: 0.8758 - val_loss: 0.3852 - val_accuracy: 0.8696\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 5s 141us/sample - loss: 0.3592 - accuracy: 0.8760 - val_loss: 0.3862 - val_accuracy: 0.8708\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 5s 141us/sample - loss: 0.3582 - accuracy: 0.8758 - val_loss: 0.3852 - val_accuracy: 0.8668\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1027s 28ms/sample - loss: 0.3573 - accuracy: 0.8766 - val_loss: 0.3845 - val_accuracy: 0.8690\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 0.3565 - accuracy: 0.8764 - val_loss: 0.3864 - val_accuracy: 0.8694\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 2s 64us/sample - loss: 0.3554 - accuracy: 0.8776 - val_loss: 0.3842 - val_accuracy: 0.8720\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3548 - accuracy: 0.8778 - val_loss: 0.3808 - val_accuracy: 0.8702\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.3539 - accuracy: 0.8783 - val_loss: 0.3853 - val_accuracy: 0.8712\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.3528 - accuracy: 0.8770 - val_loss: 0.3809 - val_accuracy: 0.8718\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 2s 66us/sample - loss: 0.3522 - accuracy: 0.8786 - val_loss: 0.3843 - val_accuracy: 0.8692\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.3514 - accuracy: 0.8792 - val_loss: 0.3806 - val_accuracy: 0.8716\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.3506 - accuracy: 0.8794 - val_loss: 0.3820 - val_accuracy: 0.8716\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3497 - accuracy: 0.8782 - val_loss: 0.3864 - val_accuracy: 0.8726\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3489 - accuracy: 0.8792 - val_loss: 0.3811 - val_accuracy: 0.8730\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.3477 - accuracy: 0.8794 - val_loss: 0.3850 - val_accuracy: 0.8692\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.3472 - accuracy: 0.8797 - val_loss: 0.3799 - val_accuracy: 0.8712\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3466 - accuracy: 0.8804 - val_loss: 0.3846 - val_accuracy: 0.8712\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3457 - accuracy: 0.8804 - val_loss: 0.3821 - val_accuracy: 0.8748\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3445 - accuracy: 0.8799 - val_loss: 0.3819 - val_accuracy: 0.8698\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3442 - accuracy: 0.8806 - val_loss: 0.3789 - val_accuracy: 0.8700\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.3430 - accuracy: 0.8805 - val_loss: 0.3794 - val_accuracy: 0.8694\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3425 - accuracy: 0.8816 - val_loss: 0.3771 - val_accuracy: 0.8726\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3421 - accuracy: 0.8809 - val_loss: 0.3774 - val_accuracy: 0.8720\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.3819 - accuracy: 0.8681\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 2.0859 - accuracy: 0.2774 - val_loss: 1.8001 - val_accuracy: 0.4112\n",
      "Epoch 2/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 1.5472 - accuracy: 0.5084 - val_loss: 1.2919 - val_accuracy: 0.5870\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 1.1522 - accuracy: 0.6338 - val_loss: 1.0140 - val_accuracy: 0.6738\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.9528 - accuracy: 0.6807 - val_loss: 0.8776 - val_accuracy: 0.6984\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.8471 - accuracy: 0.7043 - val_loss: 0.8018 - val_accuracy: 0.7186\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - ETA: 0s - loss: 0.7832 - accuracy: 0.72 - 1s 32us/sample - loss: 0.7832 - accuracy: 0.7223 - val_loss: 0.7522 - val_accuracy: 0.7362\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.7394 - accuracy: 0.7366 - val_loss: 0.7153 - val_accuracy: 0.7502\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.7059 - accuracy: 0.7508 - val_loss: 0.6862 - val_accuracy: 0.7610\n",
      "Epoch 9/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.6790 - accuracy: 0.7631 - val_loss: 0.6614 - val_accuracy: 0.7704\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.6562 - accuracy: 0.7742 - val_loss: 0.6459 - val_accuracy: 0.7818\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.6364 - accuracy: 0.7818 - val_loss: 0.6235 - val_accuracy: 0.7836\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.6191 - accuracy: 0.7870 - val_loss: 0.6058 - val_accuracy: 0.7918\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.6040 - accuracy: 0.7932 - val_loss: 0.5944 - val_accuracy: 0.7940\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5910 - accuracy: 0.7970 - val_loss: 0.5836 - val_accuracy: 0.8018\n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5790 - accuracy: 0.8003 - val_loss: 0.5701 - val_accuracy: 0.8042\n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5684 - accuracy: 0.8039 - val_loss: 0.5621 - val_accuracy: 0.8048\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5588 - accuracy: 0.8064 - val_loss: 0.5518 - val_accuracy: 0.8098\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5505 - accuracy: 0.8093 - val_loss: 0.5425 - val_accuracy: 0.8148loss: 0.5518 - accuracy: \n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5429 - accuracy: 0.8119 - val_loss: 0.5381 - val_accuracy: 0.8148\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5361 - accuracy: 0.8144 - val_loss: 0.5284 - val_accuracy: 0.8210\n",
      "Epoch 21/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.5296 - accuracy: 0.8152 - val_loss: 0.5250 - val_accuracy: 0.8220\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5232 - accuracy: 0.8183 - val_loss: 0.5186 - val_accuracy: 0.8236\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5186 - accuracy: 0.8192 - val_loss: 0.5113 - val_accuracy: 0.8262\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5132 - accuracy: 0.8214 - val_loss: 0.5072 - val_accuracy: 0.8276\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5082 - accuracy: 0.8240 - val_loss: 0.5071 - val_accuracy: 0.8258\n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5039 - accuracy: 0.8240 - val_loss: 0.5002 - val_accuracy: 0.8300\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4997 - accuracy: 0.8254 - val_loss: 0.4975 - val_accuracy: 0.8334\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4958 - accuracy: 0.8267 - val_loss: 0.4937 - val_accuracy: 0.8342\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4922 - accuracy: 0.8283 - val_loss: 0.4921 - val_accuracy: 0.8322\n",
      "Epoch 30/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4889 - accuracy: 0.8301 - val_loss: 0.4861 - val_accuracy: 0.8384\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4855 - accuracy: 0.8303 - val_loss: 0.4860 - val_accuracy: 0.8346\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4826 - accuracy: 0.8320 - val_loss: 0.4794 - val_accuracy: 0.8398\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4794 - accuracy: 0.8328 - val_loss: 0.4787 - val_accuracy: 0.8392\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4767 - accuracy: 0.8330 - val_loss: 0.4766 - val_accuracy: 0.8394\n",
      "Epoch 35/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4735 - accuracy: 0.8346 - val_loss: 0.4754 - val_accuracy: 0.8398\n",
      "Epoch 36/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4712 - accuracy: 0.8357 - val_loss: 0.4763 - val_accuracy: 0.8374\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4689 - accuracy: 0.8368 - val_loss: 0.4692 - val_accuracy: 0.8418\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4663 - accuracy: 0.8377 - val_loss: 0.4685 - val_accuracy: 0.8416\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4639 - accuracy: 0.8373 - val_loss: 0.4643 - val_accuracy: 0.8452\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4615 - accuracy: 0.8387 - val_loss: 0.4639 - val_accuracy: 0.8440\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4593 - accuracy: 0.8402 - val_loss: 0.4625 - val_accuracy: 0.8440\n",
      "Epoch 42/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4570 - accuracy: 0.8408 - val_loss: 0.4588 - val_accuracy: 0.8462\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4551 - accuracy: 0.8417 - val_loss: 0.4603 - val_accuracy: 0.8432\n",
      "Epoch 44/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4533 - accuracy: 0.8425 - val_loss: 0.4562 - val_accuracy: 0.8462\n",
      "Epoch 45/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4514 - accuracy: 0.8429 - val_loss: 0.4550 - val_accuracy: 0.8464\n",
      "Epoch 46/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4497 - accuracy: 0.8441 - val_loss: 0.4574 - val_accuracy: 0.8468\n",
      "Epoch 47/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4474 - accuracy: 0.8444 - val_loss: 0.4518 - val_accuracy: 0.8490\n",
      "Epoch 48/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4459 - accuracy: 0.8450 - val_loss: 0.4506 - val_accuracy: 0.8496\n",
      "Epoch 49/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4444 - accuracy: 0.8463 - val_loss: 0.4508 - val_accuracy: 0.8488\n",
      "Epoch 50/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4416 - accuracy: 0.8471 - val_loss: 0.4491 - val_accuracy: 0.8484\n",
      "Epoch 51/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4409 - accuracy: 0.8474 - val_loss: 0.4468 - val_accuracy: 0.8496\n",
      "Epoch 52/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4393 - accuracy: 0.8493 - val_loss: 0.4463 - val_accuracy: 0.8528\n",
      "Epoch 53/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4377 - accuracy: 0.8484 - val_loss: 0.4473 - val_accuracy: 0.8478\n",
      "Epoch 54/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4363 - accuracy: 0.8489 - val_loss: 0.4408 - val_accuracy: 0.8518\n",
      "Epoch 55/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4344 - accuracy: 0.8505 - val_loss: 0.4424 - val_accuracy: 0.8502\n",
      "Epoch 56/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4331 - accuracy: 0.8514 - val_loss: 0.4397 - val_accuracy: 0.8530\n",
      "Epoch 57/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4316 - accuracy: 0.8516 - val_loss: 0.4379 - val_accuracy: 0.8544\n",
      "Epoch 58/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4302 - accuracy: 0.8521 - val_loss: 0.4375 - val_accuracy: 0.8534\n",
      "Epoch 59/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4287 - accuracy: 0.8540 - val_loss: 0.4373 - val_accuracy: 0.8526\n",
      "Epoch 60/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4275 - accuracy: 0.8527 - val_loss: 0.4391 - val_accuracy: 0.8550\n",
      "Epoch 61/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4261 - accuracy: 0.8532 - val_loss: 0.4379 - val_accuracy: 0.8514\n",
      "Epoch 62/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4251 - accuracy: 0.8536 - val_loss: 0.4350 - val_accuracy: 0.8524\n",
      "Epoch 63/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4235 - accuracy: 0.8549 - val_loss: 0.4322 - val_accuracy: 0.8556\n",
      "Epoch 64/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4225 - accuracy: 0.8551 - val_loss: 0.4317 - val_accuracy: 0.8536\n",
      "Epoch 65/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4212 - accuracy: 0.8540 - val_loss: 0.4366 - val_accuracy: 0.8558\n",
      "Epoch 66/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4204 - accuracy: 0.8555 - val_loss: 0.4289 - val_accuracy: 0.8574\n",
      "Epoch 67/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4186 - accuracy: 0.8559 - val_loss: 0.4302 - val_accuracy: 0.8566\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4174 - accuracy: 0.8559 - val_loss: 0.4324 - val_accuracy: 0.8544\n",
      "Epoch 69/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4164 - accuracy: 0.8569 - val_loss: 0.4284 - val_accuracy: 0.8570\n",
      "Epoch 70/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4152 - accuracy: 0.8577 - val_loss: 0.4288 - val_accuracy: 0.8534\n",
      "Epoch 71/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4144 - accuracy: 0.8578 - val_loss: 0.4271 - val_accuracy: 0.8544\n",
      "Epoch 72/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4128 - accuracy: 0.8577 - val_loss: 0.4266 - val_accuracy: 0.8548\n",
      "Epoch 73/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4122 - accuracy: 0.8586 - val_loss: 0.4261 - val_accuracy: 0.8554\n",
      "Epoch 74/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4109 - accuracy: 0.8581 - val_loss: 0.4233 - val_accuracy: 0.8574\n",
      "Epoch 75/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4099 - accuracy: 0.8589 - val_loss: 0.4236 - val_accuracy: 0.8580\n",
      "Epoch 76/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4091 - accuracy: 0.8596 - val_loss: 0.4270 - val_accuracy: 0.8546\n",
      "Epoch 77/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4082 - accuracy: 0.8592 - val_loss: 0.4234 - val_accuracy: 0.8534\n",
      "Epoch 78/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4068 - accuracy: 0.8605 - val_loss: 0.4236 - val_accuracy: 0.8572\n",
      "Epoch 79/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4060 - accuracy: 0.8607 - val_loss: 0.4189 - val_accuracy: 0.8598\n",
      "Epoch 80/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4048 - accuracy: 0.8597 - val_loss: 0.4221 - val_accuracy: 0.8562\n",
      "Epoch 81/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4042 - accuracy: 0.8619 - val_loss: 0.4199 - val_accuracy: 0.8578\n",
      "Epoch 82/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4034 - accuracy: 0.8614 - val_loss: 0.4173 - val_accuracy: 0.8578\n",
      "Epoch 83/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4020 - accuracy: 0.8615 - val_loss: 0.4205 - val_accuracy: 0.8574\n",
      "Epoch 84/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4011 - accuracy: 0.8617 - val_loss: 0.4219 - val_accuracy: 0.8602\n",
      "Epoch 85/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4004 - accuracy: 0.8622 - val_loss: 0.4154 - val_accuracy: 0.8598\n",
      "Epoch 86/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3992 - accuracy: 0.8622 - val_loss: 0.4142 - val_accuracy: 0.8612\n",
      "Epoch 87/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3985 - accuracy: 0.8631 - val_loss: 0.4190 - val_accuracy: 0.8560\n",
      "Epoch 88/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3975 - accuracy: 0.8638 - val_loss: 0.4146 - val_accuracy: 0.8616\n",
      "Epoch 89/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3966 - accuracy: 0.8635 - val_loss: 0.4154 - val_accuracy: 0.8602\n",
      "Epoch 90/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3961 - accuracy: 0.8633 - val_loss: 0.4137 - val_accuracy: 0.8588\n",
      "Epoch 91/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3950 - accuracy: 0.8642 - val_loss: 0.4135 - val_accuracy: 0.8580\n",
      "Epoch 92/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3943 - accuracy: 0.8645 - val_loss: 0.4121 - val_accuracy: 0.8622\n",
      "Epoch 93/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3937 - accuracy: 0.8644 - val_loss: 0.4142 - val_accuracy: 0.8608\n",
      "Epoch 94/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3926 - accuracy: 0.8652 - val_loss: 0.4097 - val_accuracy: 0.8600\n",
      "Epoch 95/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3920 - accuracy: 0.8654 - val_loss: 0.4182 - val_accuracy: 0.8548\n",
      "Epoch 96/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.3912 - accuracy: 0.8655 - val_loss: 0.4120 - val_accuracy: 0.8580\n",
      "Epoch 97/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.3903 - accuracy: 0.8662 - val_loss: 0.4069 - val_accuracy: 0.8614\n",
      "Epoch 98/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.3891 - accuracy: 0.8669 - val_loss: 0.4086 - val_accuracy: 0.8584\n",
      "Epoch 99/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.3884 - accuracy: 0.8663 - val_loss: 0.4076 - val_accuracy: 0.8596\n",
      "Epoch 100/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.3880 - accuracy: 0.8663 - val_loss: 0.4104 - val_accuracy: 0.8584\n",
      "18334/18334 [==============================] - 0s 20us/sample - loss: 0.4230 - accuracy: 0.8501\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 2.0957 - accuracy: 0.2345 - val_loss: 1.8599 - val_accuracy: 0.3458\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 1.6051 - accuracy: 0.4652 - val_loss: 1.3176 - val_accuracy: 0.6036\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.1549 - accuracy: 0.6486 - val_loss: 1.0094 - val_accuracy: 0.6822\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.9474 - accuracy: 0.6964 - val_loss: 0.8744 - val_accuracy: 0.7158\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.8436 - accuracy: 0.7231 - val_loss: 0.7935 - val_accuracy: 0.7344\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.7765 - accuracy: 0.7411 - val_loss: 0.7384 - val_accuracy: 0.7490\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.7280 - accuracy: 0.7535 - val_loss: 0.6947 - val_accuracy: 0.7602\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.6907 - accuracy: 0.7629 - val_loss: 0.6624 - val_accuracy: 0.7694\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6624 - accuracy: 0.7705 - val_loss: 0.6391 - val_accuracy: 0.7760\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6392 - accuracy: 0.7790 - val_loss: 0.6190 - val_accuracy: 0.7854\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6205 - accuracy: 0.7864 - val_loss: 0.6017 - val_accuracy: 0.7906\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6049 - accuracy: 0.7907 - val_loss: 0.5875 - val_accuracy: 0.7964\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5910 - accuracy: 0.7955 - val_loss: 0.5759 - val_accuracy: 0.7978\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5792 - accuracy: 0.7997 - val_loss: 0.5629 - val_accuracy: 0.8052\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5684 - accuracy: 0.8037 - val_loss: 0.5559 - val_accuracy: 0.8096\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5596 - accuracy: 0.8059 - val_loss: 0.5465 - val_accuracy: 0.8158\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5511 - accuracy: 0.8093 - val_loss: 0.5389 - val_accuracy: 0.8168\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5431 - accuracy: 0.8117 - val_loss: 0.5301 - val_accuracy: 0.8178\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5362 - accuracy: 0.8132 - val_loss: 0.5235 - val_accuracy: 0.8216\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5297 - accuracy: 0.8152 - val_loss: 0.5177 - val_accuracy: 0.8246\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5237 - accuracy: 0.8170 - val_loss: 0.5122 - val_accuracy: 0.8246\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5182 - accuracy: 0.8184 - val_loss: 0.5095 - val_accuracy: 0.8254\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5134 - accuracy: 0.8205 - val_loss: 0.5029 - val_accuracy: 0.8264\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5086 - accuracy: 0.8210 - val_loss: 0.4971 - val_accuracy: 0.8286\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5037 - accuracy: 0.8240 - val_loss: 0.4952 - val_accuracy: 0.8304\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4997 - accuracy: 0.8246 - val_loss: 0.4921 - val_accuracy: 0.8308s - loss: 0.4982 - accuracy: 0.82 - ETA: 0s - loss: 0.4973 - accuracy\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4955 - accuracy: 0.8252 - val_loss: 0.4897 - val_accuracy: 0.8296\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4921 - accuracy: 0.8255 - val_loss: 0.4890 - val_accuracy: 0.8310\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4884 - accuracy: 0.8263 - val_loss: 0.4803 - val_accuracy: 0.8320\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4848 - accuracy: 0.8293 - val_loss: 0.4778 - val_accuracy: 0.8330\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4817 - accuracy: 0.8295 - val_loss: 0.4745 - val_accuracy: 0.8376\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4785 - accuracy: 0.8311 - val_loss: 0.4725 - val_accuracy: 0.8378\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4758 - accuracy: 0.8318 - val_loss: 0.4692 - val_accuracy: 0.8384\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4732 - accuracy: 0.8334 - val_loss: 0.4656 - val_accuracy: 0.8382\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4700 - accuracy: 0.8339 - val_loss: 0.4642 - val_accuracy: 0.8384\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4676 - accuracy: 0.8343 - val_loss: 0.4644 - val_accuracy: 0.8410\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4650 - accuracy: 0.8353 - val_loss: 0.4616 - val_accuracy: 0.8438\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4628 - accuracy: 0.8356 - val_loss: 0.4582 - val_accuracy: 0.8440\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4601 - accuracy: 0.8364 - val_loss: 0.4556 - val_accuracy: 0.8446\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4582 - accuracy: 0.8381 - val_loss: 0.4542 - val_accuracy: 0.8458\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4562 - accuracy: 0.8389 - val_loss: 0.4503 - val_accuracy: 0.8452\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4538 - accuracy: 0.8391 - val_loss: 0.4541 - val_accuracy: 0.8422\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4523 - accuracy: 0.8396 - val_loss: 0.4476 - val_accuracy: 0.8486\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4500 - accuracy: 0.8408 - val_loss: 0.4494 - val_accuracy: 0.8472\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4482 - accuracy: 0.8416 - val_loss: 0.4438 - val_accuracy: 0.8516\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4463 - accuracy: 0.8429 - val_loss: 0.4468 - val_accuracy: 0.8484\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4449 - accuracy: 0.8433 - val_loss: 0.4438 - val_accuracy: 0.8486\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4429 - accuracy: 0.8431 - val_loss: 0.4419 - val_accuracy: 0.8516\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4413 - accuracy: 0.8438 - val_loss: 0.4384 - val_accuracy: 0.8522\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4399 - accuracy: 0.8447 - val_loss: 0.4370 - val_accuracy: 0.8534\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4381 - accuracy: 0.8450 - val_loss: 0.4371 - val_accuracy: 0.8544\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4364 - accuracy: 0.8459 - val_loss: 0.4340 - val_accuracy: 0.8534\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4347 - accuracy: 0.8469 - val_loss: 0.4370 - val_accuracy: 0.8504\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4335 - accuracy: 0.8471 - val_loss: 0.4315 - val_accuracy: 0.8560\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4323 - accuracy: 0.8469 - val_loss: 0.4332 - val_accuracy: 0.8558\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4309 - accuracy: 0.8476 - val_loss: 0.4329 - val_accuracy: 0.8548\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4288 - accuracy: 0.8478 - val_loss: 0.4308 - val_accuracy: 0.8566\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4282 - accuracy: 0.8479 - val_loss: 0.4289 - val_accuracy: 0.8584\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4269 - accuracy: 0.8491 - val_loss: 0.4290 - val_accuracy: 0.8568\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4257 - accuracy: 0.8484 - val_loss: 0.4282 - val_accuracy: 0.8560\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4245 - accuracy: 0.8510 - val_loss: 0.4252 - val_accuracy: 0.8604\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4236 - accuracy: 0.8505 - val_loss: 0.4273 - val_accuracy: 0.8570\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4218 - accuracy: 0.8513 - val_loss: 0.4231 - val_accuracy: 0.8600\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4208 - accuracy: 0.8517 - val_loss: 0.4270 - val_accuracy: 0.8562\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4200 - accuracy: 0.8516 - val_loss: 0.4241 - val_accuracy: 0.8584\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4192 - accuracy: 0.8511 - val_loss: 0.4238 - val_accuracy: 0.8594\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4175 - accuracy: 0.8526 - val_loss: 0.4257 - val_accuracy: 0.8592\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4166 - accuracy: 0.8532 - val_loss: 0.4230 - val_accuracy: 0.8578\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4153 - accuracy: 0.8530 - val_loss: 0.4250 - val_accuracy: 0.8562\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4148 - accuracy: 0.8539 - val_loss: 0.4210 - val_accuracy: 0.8596\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4138 - accuracy: 0.8539 - val_loss: 0.4202 - val_accuracy: 0.8616\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4131 - accuracy: 0.8542 - val_loss: 0.4178 - val_accuracy: 0.8616\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4119 - accuracy: 0.8553 - val_loss: 0.4179 - val_accuracy: 0.8620\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4107 - accuracy: 0.8543 - val_loss: 0.4205 - val_accuracy: 0.8610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4100 - accuracy: 0.8552 - val_loss: 0.4182 - val_accuracy: 0.8602\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4090 - accuracy: 0.8553 - val_loss: 0.4171 - val_accuracy: 0.8618\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4084 - accuracy: 0.8553 - val_loss: 0.4152 - val_accuracy: 0.8616\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4076 - accuracy: 0.8552 - val_loss: 0.4171 - val_accuracy: 0.8628\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4061 - accuracy: 0.8570 - val_loss: 0.4175 - val_accuracy: 0.8610\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4060 - accuracy: 0.8557 - val_loss: 0.4127 - val_accuracy: 0.8638\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4046 - accuracy: 0.8565 - val_loss: 0.4127 - val_accuracy: 0.8640\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4036 - accuracy: 0.8571 - val_loss: 0.4154 - val_accuracy: 0.8614\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4032 - accuracy: 0.8573 - val_loss: 0.4112 - val_accuracy: 0.8620\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4024 - accuracy: 0.8586 - val_loss: 0.4155 - val_accuracy: 0.8604\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4017 - accuracy: 0.8576 - val_loss: 0.4113 - val_accuracy: 0.8630\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4011 - accuracy: 0.8576 - val_loss: 0.4158 - val_accuracy: 0.8622\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3997 - accuracy: 0.8581 - val_loss: 0.4142 - val_accuracy: 0.8608\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.3996 - accuracy: 0.8590 - val_loss: 0.4105 - val_accuracy: 0.8632\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3984 - accuracy: 0.8590 - val_loss: 0.4118 - val_accuracy: 0.8640\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.3974 - accuracy: 0.8609 - val_loss: 0.4112 - val_accuracy: 0.8612\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3969 - accuracy: 0.8595 - val_loss: 0.4108 - val_accuracy: 0.8642loss: 0.3982 - accuracy: 0.85\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3965 - accuracy: 0.8595 - val_loss: 0.4118 - val_accuracy: 0.8628\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3956 - accuracy: 0.8601 - val_loss: 0.4077 - val_accuracy: 0.8644\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3948 - accuracy: 0.8611 - val_loss: 0.4082 - val_accuracy: 0.8634\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3943 - accuracy: 0.8607 - val_loss: 0.4107 - val_accuracy: 0.8632\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3936 - accuracy: 0.8614 - val_loss: 0.4048 - val_accuracy: 0.8640\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3929 - accuracy: 0.8614 - val_loss: 0.4053 - val_accuracy: 0.8646\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.3924 - accuracy: 0.8610 - val_loss: 0.4049 - val_accuracy: 0.8642\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3916 - accuracy: 0.8609 - val_loss: 0.4070 - val_accuracy: 0.8646\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.3905 - accuracy: 0.8622 - val_loss: 0.4048 - val_accuracy: 0.8664\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.4132 - accuracy: 0.8596\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 2.0925 - accuracy: 0.1584 - val_loss: 1.8585 - val_accuracy: 0.2666\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 1.5993 - accuracy: 0.4742 - val_loss: 1.3276 - val_accuracy: 0.6100\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 1.1775 - accuracy: 0.6373 - val_loss: 1.0399 - val_accuracy: 0.6752\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.9743 - accuracy: 0.6828 - val_loss: 0.8945 - val_accuracy: 0.7182\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.8619 - accuracy: 0.7074 - val_loss: 0.8096 - val_accuracy: 0.7336\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.7931 - accuracy: 0.7258 - val_loss: 0.7558 - val_accuracy: 0.7528\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.7455 - accuracy: 0.7406 - val_loss: 0.7132 - val_accuracy: 0.7666\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.7090 - accuracy: 0.7515 - val_loss: 0.6776 - val_accuracy: 0.7754\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6797 - accuracy: 0.7623 - val_loss: 0.6512 - val_accuracy: 0.7850\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6547 - accuracy: 0.7716 - val_loss: 0.6291 - val_accuracy: 0.7964\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6334 - accuracy: 0.7810 - val_loss: 0.6106 - val_accuracy: 0.7976\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6152 - accuracy: 0.7861 - val_loss: 0.5938 - val_accuracy: 0.8024\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5997 - accuracy: 0.7922 - val_loss: 0.5802 - val_accuracy: 0.80800.6042 - accuracy\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5857 - accuracy: 0.7963 - val_loss: 0.5640 - val_accuracy: 0.8140\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5741 - accuracy: 0.8010 - val_loss: 0.5583 - val_accuracy: 0.8174\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5640 - accuracy: 0.8040 - val_loss: 0.5438 - val_accuracy: 0.8206\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5546 - accuracy: 0.8084 - val_loss: 0.5360 - val_accuracy: 0.8232\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5470 - accuracy: 0.8108 - val_loss: 0.5313 - val_accuracy: 0.8222\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5396 - accuracy: 0.8144 - val_loss: 0.5218 - val_accuracy: 0.8252\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5327 - accuracy: 0.8165 - val_loss: 0.5164 - val_accuracy: 0.8288ss: 0.5393 \n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5266 - accuracy: 0.8176 - val_loss: 0.5145 - val_accuracy: 0.8286\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5218 - accuracy: 0.8199 - val_loss: 0.5098 - val_accuracy: 0.8266\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5162 - accuracy: 0.8215 - val_loss: 0.5054 - val_accuracy: 0.8282\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5113 - accuracy: 0.8237 - val_loss: 0.5054 - val_accuracy: 0.8294\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5070 - accuracy: 0.8248 - val_loss: 0.4929 - val_accuracy: 0.8340\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5024 - accuracy: 0.8256 - val_loss: 0.4900 - val_accuracy: 0.8360\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4984 - accuracy: 0.8260 - val_loss: 0.4860 - val_accuracy: 0.8352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4945 - accuracy: 0.8277 - val_loss: 0.4843 - val_accuracy: 0.8358\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4905 - accuracy: 0.8290 - val_loss: 0.4821 - val_accuracy: 0.8364\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4874 - accuracy: 0.8303 - val_loss: 0.4779 - val_accuracy: 0.8374\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4844 - accuracy: 0.8312 - val_loss: 0.4756 - val_accuracy: 0.8368\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4814 - accuracy: 0.8327 - val_loss: 0.4705 - val_accuracy: 0.8380\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4783 - accuracy: 0.8336 - val_loss: 0.4730 - val_accuracy: 0.8384\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4751 - accuracy: 0.8352 - val_loss: 0.4699 - val_accuracy: 0.8390\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4726 - accuracy: 0.8355 - val_loss: 0.4644 - val_accuracy: 0.8400\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4698 - accuracy: 0.8354 - val_loss: 0.4659 - val_accuracy: 0.8418\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4676 - accuracy: 0.8372 - val_loss: 0.4658 - val_accuracy: 0.8404\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4653 - accuracy: 0.8379 - val_loss: 0.4602 - val_accuracy: 0.8426\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4628 - accuracy: 0.8384 - val_loss: 0.4627 - val_accuracy: 0.8430\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4600 - accuracy: 0.8396 - val_loss: 0.4571 - val_accuracy: 0.8456\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4582 - accuracy: 0.8392 - val_loss: 0.4530 - val_accuracy: 0.8444\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4563 - accuracy: 0.8411 - val_loss: 0.4560 - val_accuracy: 0.8434\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4542 - accuracy: 0.8417 - val_loss: 0.4545 - val_accuracy: 0.8434\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4524 - accuracy: 0.8426 - val_loss: 0.4575 - val_accuracy: 0.8422\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4507 - accuracy: 0.8417 - val_loss: 0.4476 - val_accuracy: 0.8482\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4487 - accuracy: 0.8440 - val_loss: 0.4482 - val_accuracy: 0.8468\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4469 - accuracy: 0.8440 - val_loss: 0.4453 - val_accuracy: 0.8456\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4452 - accuracy: 0.8447 - val_loss: 0.4473 - val_accuracy: 0.8444\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4437 - accuracy: 0.8452 - val_loss: 0.4433 - val_accuracy: 0.8464\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4419 - accuracy: 0.8462 - val_loss: 0.4393 - val_accuracy: 0.8484\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4403 - accuracy: 0.8480 - val_loss: 0.4395 - val_accuracy: 0.8504\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4388 - accuracy: 0.8475 - val_loss: 0.4377 - val_accuracy: 0.8508\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4374 - accuracy: 0.8486 - val_loss: 0.4354 - val_accuracy: 0.8520\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4361 - accuracy: 0.8477 - val_loss: 0.4382 - val_accuracy: 0.8504\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4343 - accuracy: 0.8484 - val_loss: 0.4358 - val_accuracy: 0.8480\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4331 - accuracy: 0.8496 - val_loss: 0.4314 - val_accuracy: 0.8542\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4318 - accuracy: 0.8506 - val_loss: 0.4336 - val_accuracy: 0.8524\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4298 - accuracy: 0.8502 - val_loss: 0.4346 - val_accuracy: 0.8520\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4287 - accuracy: 0.8503 - val_loss: 0.4381 - val_accuracy: 0.8522\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4278 - accuracy: 0.8518 - val_loss: 0.4328 - val_accuracy: 0.8496\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4260 - accuracy: 0.8523 - val_loss: 0.4302 - val_accuracy: 0.8530\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4249 - accuracy: 0.8525 - val_loss: 0.4277 - val_accuracy: 0.8526\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4241 - accuracy: 0.8524 - val_loss: 0.4278 - val_accuracy: 0.8518\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4222 - accuracy: 0.8540 - val_loss: 0.4281 - val_accuracy: 0.8548\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4214 - accuracy: 0.8531 - val_loss: 0.4241 - val_accuracy: 0.8578\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4199 - accuracy: 0.8542 - val_loss: 0.4274 - val_accuracy: 0.8530\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4188 - accuracy: 0.8554 - val_loss: 0.4226 - val_accuracy: 0.8576\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4174 - accuracy: 0.8556 - val_loss: 0.4224 - val_accuracy: 0.8570\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4160 - accuracy: 0.8561 - val_loss: 0.4210 - val_accuracy: 0.8558\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4152 - accuracy: 0.8562 - val_loss: 0.4222 - val_accuracy: 0.8568\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4138 - accuracy: 0.8553 - val_loss: 0.4179 - val_accuracy: 0.8580\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4128 - accuracy: 0.8560 - val_loss: 0.4201 - val_accuracy: 0.8568\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4117 - accuracy: 0.8565 - val_loss: 0.4184 - val_accuracy: 0.8586\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4106 - accuracy: 0.8578 - val_loss: 0.4168 - val_accuracy: 0.8554\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4091 - accuracy: 0.8577 - val_loss: 0.4184 - val_accuracy: 0.8582\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4085 - accuracy: 0.8580 - val_loss: 0.4177 - val_accuracy: 0.8584\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4073 - accuracy: 0.8580 - val_loss: 0.4163 - val_accuracy: 0.8560\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4064 - accuracy: 0.8584 - val_loss: 0.4158 - val_accuracy: 0.8568\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4051 - accuracy: 0.8596 - val_loss: 0.4163 - val_accuracy: 0.8572\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4039 - accuracy: 0.8589 - val_loss: 0.4120 - val_accuracy: 0.8602\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4033 - accuracy: 0.8593 - val_loss: 0.4143 - val_accuracy: 0.8602\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4026 - accuracy: 0.8597 - val_loss: 0.4138 - val_accuracy: 0.8576\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4016 - accuracy: 0.8593 - val_loss: 0.4099 - val_accuracy: 0.8604\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4005 - accuracy: 0.8603 - val_loss: 0.4116 - val_accuracy: 0.8590\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3994 - accuracy: 0.8608 - val_loss: 0.4121 - val_accuracy: 0.8572\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3988 - accuracy: 0.8616 - val_loss: 0.4082 - val_accuracy: 0.8594\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3980 - accuracy: 0.8611 - val_loss: 0.4117 - val_accuracy: 0.8550\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3975 - accuracy: 0.8619 - val_loss: 0.4092 - val_accuracy: 0.8596\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3967 - accuracy: 0.8619 - val_loss: 0.4079 - val_accuracy: 0.8596\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3956 - accuracy: 0.8619 - val_loss: 0.4137 - val_accuracy: 0.8550\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3941 - accuracy: 0.8628 - val_loss: 0.4073 - val_accuracy: 0.8598\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3943 - accuracy: 0.8617 - val_loss: 0.4060 - val_accuracy: 0.8576\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3931 - accuracy: 0.8632 - val_loss: 0.4097 - val_accuracy: 0.8606\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3925 - accuracy: 0.8631 - val_loss: 0.4082 - val_accuracy: 0.8576\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.3916 - accuracy: 0.8629 - val_loss: 0.4044 - val_accuracy: 0.8596\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3907 - accuracy: 0.8637 - val_loss: 0.4062 - val_accuracy: 0.8602\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3904 - accuracy: 0.8634 - val_loss: 0.4058 - val_accuracy: 0.8586\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3897 - accuracy: 0.8635 - val_loss: 0.4043 - val_accuracy: 0.8602\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3887 - accuracy: 0.8643 - val_loss: 0.4036 - val_accuracy: 0.8602\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.3881 - accuracy: 0.8644 - val_loss: 0.4019 - val_accuracy: 0.8604\n",
      "18333/18333 [==============================] - 0s 19us/sample - loss: 0.4165 - accuracy: 0.8557\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 1.4382 - accuracy: 0.5716 - val_loss: 1.0438 - val_accuracy: 0.6920\n",
      "Epoch 2/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.9476 - accuracy: 0.7071 - val_loss: 0.8594 - val_accuracy: 0.7384\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.8255 - accuracy: 0.7406 - val_loss: 0.7778 - val_accuracy: 0.7584\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.7616 - accuracy: 0.7593 - val_loss: 0.7281 - val_accuracy: 0.7754\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.7197 - accuracy: 0.7714 - val_loss: 0.6947 - val_accuracy: 0.7840\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.6893 - accuracy: 0.7794 - val_loss: 0.6686 - val_accuracy: 0.7910\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.6658 - accuracy: 0.7862 - val_loss: 0.6470 - val_accuracy: 0.7956\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.6470 - accuracy: 0.7924 - val_loss: 0.6301 - val_accuracy: 0.8010\n",
      "Epoch 9/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.6313 - accuracy: 0.7972 - val_loss: 0.6165 - val_accuracy: 0.8040\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.6180 - accuracy: 0.8017 - val_loss: 0.6051 - val_accuracy: 0.8082\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.6067 - accuracy: 0.8053 - val_loss: 0.5947 - val_accuracy: 0.8120\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.5964 - accuracy: 0.8066 - val_loss: 0.5873 - val_accuracy: 0.8144\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5877 - accuracy: 0.8108 - val_loss: 0.5774 - val_accuracy: 0.8170\n",
      "Epoch 14/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5799 - accuracy: 0.8124 - val_loss: 0.5704 - val_accuracy: 0.8188\n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5726 - accuracy: 0.8153 - val_loss: 0.5656 - val_accuracy: 0.8202s - loss: 0.5717 - accuracy: 0.\n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5661 - accuracy: 0.8172 - val_loss: 0.5572 - val_accuracy: 0.8230\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5602 - accuracy: 0.8188 - val_loss: 0.5520 - val_accuracy: 0.8266\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5546 - accuracy: 0.8205 - val_loss: 0.5476 - val_accuracy: 0.8304\n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5496 - accuracy: 0.8215 - val_loss: 0.5429 - val_accuracy: 0.8302\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5449 - accuracy: 0.8223 - val_loss: 0.5387 - val_accuracy: 0.8298\n",
      "Epoch 21/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5406 - accuracy: 0.8236 - val_loss: 0.5340 - val_accuracy: 0.8308\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5365 - accuracy: 0.8250 - val_loss: 0.5299 - val_accuracy: 0.8346\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5327 - accuracy: 0.8260 - val_loss: 0.5268 - val_accuracy: 0.8334\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5291 - accuracy: 0.8269 - val_loss: 0.5236 - val_accuracy: 0.8358\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5259 - accuracy: 0.8277 - val_loss: 0.5208 - val_accuracy: 0.8372\n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5225 - accuracy: 0.8279 - val_loss: 0.5168 - val_accuracy: 0.8376\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5196 - accuracy: 0.8293 - val_loss: 0.5143 - val_accuracy: 0.8384\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5167 - accuracy: 0.8298 - val_loss: 0.5121 - val_accuracy: 0.8382\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5139 - accuracy: 0.8304 - val_loss: 0.5102 - val_accuracy: 0.8414\n",
      "Epoch 30/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5113 - accuracy: 0.8310 - val_loss: 0.5070 - val_accuracy: 0.8388\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.5089 - accuracy: 0.8313 - val_loss: 0.5045 - val_accuracy: 0.8408\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5064 - accuracy: 0.8323 - val_loss: 0.5021 - val_accuracy: 0.8394\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.5042 - accuracy: 0.8333 - val_loss: 0.5000 - val_accuracy: 0.8394\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.5020 - accuracy: 0.8337 - val_loss: 0.4983 - val_accuracy: 0.8432\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4998 - accuracy: 0.8345 - val_loss: 0.5005 - val_accuracy: 0.8414\n",
      "Epoch 36/100\n",
      "36666/36666 [==============================] - ETA: 0s - loss: 0.4976 - accuracy: 0.83 - 1s 27us/sample - loss: 0.4980 - accuracy: 0.8347 - val_loss: 0.4956 - val_accuracy: 0.8414\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4960 - accuracy: 0.8346 - val_loss: 0.4931 - val_accuracy: 0.8418\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4942 - accuracy: 0.8357 - val_loss: 0.4923 - val_accuracy: 0.8418 - accuracy\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4924 - accuracy: 0.8364 - val_loss: 0.4910 - val_accuracy: 0.8434\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4907 - accuracy: 0.8375 - val_loss: 0.4883 - val_accuracy: 0.8434\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4889 - accuracy: 0.8372 - val_loss: 0.4873 - val_accuracy: 0.8444\n",
      "Epoch 42/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4875 - accuracy: 0.8381 - val_loss: 0.4861 - val_accuracy: 0.8450\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4859 - accuracy: 0.8388 - val_loss: 0.4845 - val_accuracy: 0.8470\n",
      "Epoch 44/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4843 - accuracy: 0.8392 - val_loss: 0.4826 - val_accuracy: 0.8464\n",
      "Epoch 45/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4827 - accuracy: 0.8392 - val_loss: 0.4828 - val_accuracy: 0.8456\n",
      "Epoch 46/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4816 - accuracy: 0.8399 - val_loss: 0.4798 - val_accuracy: 0.8458\n",
      "Epoch 47/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4801 - accuracy: 0.8407 - val_loss: 0.4792 - val_accuracy: 0.8464\n",
      "Epoch 48/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4787 - accuracy: 0.8411 - val_loss: 0.4781 - val_accuracy: 0.8478- loss: 0\n",
      "Epoch 49/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4774 - accuracy: 0.8414 - val_loss: 0.4782 - val_accuracy: 0.8478\n",
      "Epoch 50/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4763 - accuracy: 0.8416 - val_loss: 0.4768 - val_accuracy: 0.8474\n",
      "Epoch 51/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4750 - accuracy: 0.8417 - val_loss: 0.4747 - val_accuracy: 0.8490\n",
      "Epoch 52/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4739 - accuracy: 0.8425 - val_loss: 0.4735 - val_accuracy: 0.8486\n",
      "Epoch 53/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4726 - accuracy: 0.8427 - val_loss: 0.4732 - val_accuracy: 0.8468\n",
      "Epoch 54/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4715 - accuracy: 0.8434 - val_loss: 0.4726 - val_accuracy: 0.8478\n",
      "Epoch 55/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4704 - accuracy: 0.8436 - val_loss: 0.4728 - val_accuracy: 0.8476\n",
      "Epoch 56/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4694 - accuracy: 0.8439 - val_loss: 0.4704 - val_accuracy: 0.8480\n",
      "Epoch 57/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4682 - accuracy: 0.8447 - val_loss: 0.4693 - val_accuracy: 0.8484\n",
      "Epoch 58/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4673 - accuracy: 0.8444 - val_loss: 0.4677 - val_accuracy: 0.8496\n",
      "Epoch 59/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4663 - accuracy: 0.8449 - val_loss: 0.4675 - val_accuracy: 0.8486\n",
      "Epoch 60/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4652 - accuracy: 0.8448 - val_loss: 0.4663 - val_accuracy: 0.8502\n",
      "Epoch 61/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4642 - accuracy: 0.8451 - val_loss: 0.4673 - val_accuracy: 0.8480\n",
      "Epoch 62/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4635 - accuracy: 0.8459 - val_loss: 0.4648 - val_accuracy: 0.8500\n",
      "Epoch 63/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4624 - accuracy: 0.8462 - val_loss: 0.4646 - val_accuracy: 0.8488\n",
      "Epoch 64/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4616 - accuracy: 0.8465 - val_loss: 0.4637 - val_accuracy: 0.8496\n",
      "Epoch 65/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4607 - accuracy: 0.8469 - val_loss: 0.4626 - val_accuracy: 0.8498\n",
      "Epoch 66/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4599 - accuracy: 0.8463 - val_loss: 0.4617 - val_accuracy: 0.8508- loss: 0.4633 - accuracy: 0. - ETA: 0s - loss: 0.4606 - accuracy: 0.84\n",
      "Epoch 67/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4591 - accuracy: 0.8472 - val_loss: 0.4615 - val_accuracy: 0.8502\n",
      "Epoch 68/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4582 - accuracy: 0.8464 - val_loss: 0.4607 - val_accuracy: 0.8504\n",
      "Epoch 69/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4574 - accuracy: 0.8475 - val_loss: 0.4601 - val_accuracy: 0.8502\n",
      "Epoch 70/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4566 - accuracy: 0.8477 - val_loss: 0.4590 - val_accuracy: 0.8506\n",
      "Epoch 71/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4560 - accuracy: 0.8476 - val_loss: 0.4586 - val_accuracy: 0.8502\n",
      "Epoch 72/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4552 - accuracy: 0.8486 - val_loss: 0.4576 - val_accuracy: 0.8508\n",
      "Epoch 73/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4544 - accuracy: 0.8484 - val_loss: 0.4575 - val_accuracy: 0.8510\n",
      "Epoch 74/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4536 - accuracy: 0.8492 - val_loss: 0.4565 - val_accuracy: 0.8516\n",
      "Epoch 75/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4529 - accuracy: 0.8491 - val_loss: 0.4574 - val_accuracy: 0.8514\n",
      "Epoch 76/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4522 - accuracy: 0.8499 - val_loss: 0.4555 - val_accuracy: 0.8522\n",
      "Epoch 77/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4516 - accuracy: 0.8495 - val_loss: 0.4549 - val_accuracy: 0.8532\n",
      "Epoch 78/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4508 - accuracy: 0.8494 - val_loss: 0.4546 - val_accuracy: 0.8516\n",
      "Epoch 79/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4502 - accuracy: 0.8502 - val_loss: 0.4533 - val_accuracy: 0.8516\n",
      "Epoch 80/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4495 - accuracy: 0.8505 - val_loss: 0.4532 - val_accuracy: 0.8524\n",
      "Epoch 81/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4490 - accuracy: 0.8503 - val_loss: 0.4524 - val_accuracy: 0.8516\n",
      "Epoch 82/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4483 - accuracy: 0.8505 - val_loss: 0.4522 - val_accuracy: 0.8516s - loss: 0\n",
      "Epoch 83/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4476 - accuracy: 0.8507 - val_loss: 0.4522 - val_accuracy: 0.8518\n",
      "Epoch 84/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4472 - accuracy: 0.8511 - val_loss: 0.4512 - val_accuracy: 0.8534\n",
      "Epoch 85/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4464 - accuracy: 0.8508 - val_loss: 0.4514 - val_accuracy: 0.8508ss: 0.4473 - accura\n",
      "Epoch 86/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4459 - accuracy: 0.8519 - val_loss: 0.4523 - val_accuracy: 0.8520\n",
      "Epoch 87/100\n",
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4451 - accuracy: 0.8516 - val_loss: 0.4505 - val_accuracy: 0.8522\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 1s 27us/sample - loss: 0.4447 - accuracy: 0.8516 - val_loss: 0.4494 - val_accuracy: 0.8532\n",
      "Epoch 89/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4442 - accuracy: 0.8515 - val_loss: 0.4491 - val_accuracy: 0.8520- loss: 0\n",
      "Epoch 90/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4436 - accuracy: 0.8516 - val_loss: 0.4485 - val_accuracy: 0.8518\n",
      "Epoch 91/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4430 - accuracy: 0.8524 - val_loss: 0.4483 - val_accuracy: 0.8536\n",
      "Epoch 92/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4425 - accuracy: 0.8520 - val_loss: 0.4473 - val_accuracy: 0.8528\n",
      "Epoch 93/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4421 - accuracy: 0.8521 - val_loss: 0.4472 - val_accuracy: 0.8530\n",
      "Epoch 94/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4414 - accuracy: 0.8526 - val_loss: 0.4474 - val_accuracy: 0.8518: 0.4382 - accura\n",
      "Epoch 95/100\n",
      "36666/36666 [==============================] - 1s 28us/sample - loss: 0.4410 - accuracy: 0.8525 - val_loss: 0.4469 - val_accuracy: 0.8524\n",
      "Epoch 96/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4405 - accuracy: 0.8526 - val_loss: 0.4461 - val_accuracy: 0.8526\n",
      "Epoch 97/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4399 - accuracy: 0.8534 - val_loss: 0.4468 - val_accuracy: 0.8520\n",
      "Epoch 98/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4394 - accuracy: 0.8532 - val_loss: 0.4453 - val_accuracy: 0.8530\n",
      "Epoch 99/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4389 - accuracy: 0.8530 - val_loss: 0.4469 - val_accuracy: 0.8546\n",
      "Epoch 100/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4384 - accuracy: 0.8528 - val_loss: 0.4453 - val_accuracy: 0.8540\n",
      "18334/18334 [==============================] - 0s 19us/sample - loss: 0.4599 - accuracy: 0.8411\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.3893 - accuracy: 0.5911 - val_loss: 1.0313 - val_accuracy: 0.6840\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.9408 - accuracy: 0.7012 - val_loss: 0.8558 - val_accuracy: 0.7266\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 27us/sample - loss: 0.8241 - accuracy: 0.7338 - val_loss: 0.7763 - val_accuracy: 0.7506\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.7620 - accuracy: 0.7541 - val_loss: 0.7276 - val_accuracy: 0.7672\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.7207 - accuracy: 0.7669 - val_loss: 0.6945 - val_accuracy: 0.7792\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6908 - accuracy: 0.7774 - val_loss: 0.6680 - val_accuracy: 0.7844ccuracy: \n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.6674 - accuracy: 0.7851 - val_loss: 0.6484 - val_accuracy: 0.7894\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.6487 - accuracy: 0.7907 - val_loss: 0.6313 - val_accuracy: 0.7958\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.6329 - accuracy: 0.7959 - val_loss: 0.6180 - val_accuracy: 0.7992\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 27us/sample - loss: 0.6197 - accuracy: 0.7992 - val_loss: 0.6060 - val_accuracy: 0.8048\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 27us/sample - loss: 0.6083 - accuracy: 0.8028 - val_loss: 0.5952 - val_accuracy: 0.8078\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5983 - accuracy: 0.8057 - val_loss: 0.5858 - val_accuracy: 0.8110\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5892 - accuracy: 0.8082 - val_loss: 0.5780 - val_accuracy: 0.8160\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5814 - accuracy: 0.8108 - val_loss: 0.5715 - val_accuracy: 0.8172\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5741 - accuracy: 0.8141 - val_loss: 0.5643 - val_accuracy: 0.8172\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5677 - accuracy: 0.8141 - val_loss: 0.5583 - val_accuracy: 0.8182\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5617 - accuracy: 0.8166 - val_loss: 0.5536 - val_accuracy: 0.8232\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5565 - accuracy: 0.8188 - val_loss: 0.5477 - val_accuracy: 0.8244\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5514 - accuracy: 0.8194 - val_loss: 0.5437 - val_accuracy: 0.8286\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5466 - accuracy: 0.8206 - val_loss: 0.5399 - val_accuracy: 0.8270\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5425 - accuracy: 0.8216 - val_loss: 0.5350 - val_accuracy: 0.8282\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5382 - accuracy: 0.8228 - val_loss: 0.5313 - val_accuracy: 0.8286\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5345 - accuracy: 0.8238 - val_loss: 0.5279 - val_accuracy: 0.8310\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5308 - accuracy: 0.8250 - val_loss: 0.5251 - val_accuracy: 0.8314\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5277 - accuracy: 0.8251 - val_loss: 0.5225 - val_accuracy: 0.8316\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5245 - accuracy: 0.8257 - val_loss: 0.5189 - val_accuracy: 0.8336\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5216 - accuracy: 0.8271 - val_loss: 0.5160 - val_accuracy: 0.8346\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5186 - accuracy: 0.8276 - val_loss: 0.5133 - val_accuracy: 0.8348\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5159 - accuracy: 0.8283 - val_loss: 0.5109 - val_accuracy: 0.8350\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5131 - accuracy: 0.8293 - val_loss: 0.5096 - val_accuracy: 0.8350\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5110 - accuracy: 0.8304 - val_loss: 0.5069 - val_accuracy: 0.8350\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5086 - accuracy: 0.8301 - val_loss: 0.5054 - val_accuracy: 0.8344loss: 0.505\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5063 - accuracy: 0.8312 - val_loss: 0.5038 - val_accuracy: 0.8354\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5041 - accuracy: 0.8314 - val_loss: 0.5002 - val_accuracy: 0.8374\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5022 - accuracy: 0.8327 - val_loss: 0.4989 - val_accuracy: 0.8384\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5001 - accuracy: 0.8325 - val_loss: 0.4969 - val_accuracy: 0.8390\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4983 - accuracy: 0.8334 - val_loss: 0.4952 - val_accuracy: 0.8376\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4965 - accuracy: 0.8326 - val_loss: 0.4939 - val_accuracy: 0.8380\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4946 - accuracy: 0.8343 - val_loss: 0.4927 - val_accuracy: 0.8394\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4930 - accuracy: 0.8349 - val_loss: 0.4914 - val_accuracy: 0.8394\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4914 - accuracy: 0.8350 - val_loss: 0.4894 - val_accuracy: 0.8410\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4899 - accuracy: 0.8351 - val_loss: 0.4882 - val_accuracy: 0.8390- loss: 0.4839 - accuracy: 0.83 - ETA: 0s - loss: 0.483\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4883 - accuracy: 0.8356 - val_loss: 0.4868 - val_accuracy: 0.8428\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4866 - accuracy: 0.8363 - val_loss: 0.4859 - val_accuracy: 0.8412\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4853 - accuracy: 0.8366 - val_loss: 0.4846 - val_accuracy: 0.8414\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4840 - accuracy: 0.8363 - val_loss: 0.4833 - val_accuracy: 0.8424\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4825 - accuracy: 0.8370 - val_loss: 0.4816 - val_accuracy: 0.8438\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4811 - accuracy: 0.8375 - val_loss: 0.4808 - val_accuracy: 0.8434\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4800 - accuracy: 0.8377 - val_loss: 0.4801 - val_accuracy: 0.8442\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4788 - accuracy: 0.8381 - val_loss: 0.4788 - val_accuracy: 0.8428\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - ETA: 0s - loss: 0.4790 - accuracy: 0.83 - 1s 32us/sample - loss: 0.4776 - accuracy: 0.8382 - val_loss: 0.4774 - val_accuracy: 0.8454\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4762 - accuracy: 0.8387 - val_loss: 0.4763 - val_accuracy: 0.8454\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4753 - accuracy: 0.8393 - val_loss: 0.4756 - val_accuracy: 0.8452\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4742 - accuracy: 0.8394 - val_loss: 0.4750 - val_accuracy: 0.8462\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4730 - accuracy: 0.8403 - val_loss: 0.4749 - val_accuracy: 0.8458\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4719 - accuracy: 0.8399 - val_loss: 0.4735 - val_accuracy: 0.8472\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4710 - accuracy: 0.8411 - val_loss: 0.4719 - val_accuracy: 0.8468\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4700 - accuracy: 0.8404 - val_loss: 0.4709 - val_accuracy: 0.8474\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4691 - accuracy: 0.8413 - val_loss: 0.4700 - val_accuracy: 0.8478\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4681 - accuracy: 0.8417 - val_loss: 0.4700 - val_accuracy: 0.8466\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4672 - accuracy: 0.8411 - val_loss: 0.4687 - val_accuracy: 0.8474\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4661 - accuracy: 0.8420 - val_loss: 0.4675 - val_accuracy: 0.8474\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4653 - accuracy: 0.8416 - val_loss: 0.4675 - val_accuracy: 0.8472s - loss: 0.4561 - \n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4644 - accuracy: 0.8420 - val_loss: 0.4668 - val_accuracy: 0.8486\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4635 - accuracy: 0.8432 - val_loss: 0.4656 - val_accuracy: 0.8482\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4626 - accuracy: 0.8437 - val_loss: 0.4654 - val_accuracy: 0.8490\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4619 - accuracy: 0.8431 - val_loss: 0.4644 - val_accuracy: 0.8482\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4612 - accuracy: 0.8439 - val_loss: 0.4640 - val_accuracy: 0.8498\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4603 - accuracy: 0.8441 - val_loss: 0.4641 - val_accuracy: 0.8490\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4595 - accuracy: 0.8439 - val_loss: 0.4632 - val_accuracy: 0.8498\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4587 - accuracy: 0.8442 - val_loss: 0.4621 - val_accuracy: 0.8490\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4581 - accuracy: 0.8446 - val_loss: 0.4618 - val_accuracy: 0.8476\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4573 - accuracy: 0.8446 - val_loss: 0.4605 - val_accuracy: 0.8490\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4567 - accuracy: 0.8451 - val_loss: 0.4603 - val_accuracy: 0.8476\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4560 - accuracy: 0.8449 - val_loss: 0.4595 - val_accuracy: 0.8502\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4554 - accuracy: 0.8451 - val_loss: 0.4588 - val_accuracy: 0.8500\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4546 - accuracy: 0.8451 - val_loss: 0.4584 - val_accuracy: 0.8512\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4539 - accuracy: 0.8457 - val_loss: 0.4582 - val_accuracy: 0.8510\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4532 - accuracy: 0.8454 - val_loss: 0.4569 - val_accuracy: 0.8490\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4525 - accuracy: 0.8459 - val_loss: 0.4575 - val_accuracy: 0.8486\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4519 - accuracy: 0.8457 - val_loss: 0.4558 - val_accuracy: 0.8508loss: 0.4521 - accuracy - ETA: 0s - loss: 0.4477 - \n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4514 - accuracy: 0.8462 - val_loss: 0.4558 - val_accuracy: 0.8518\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4508 - accuracy: 0.8466 - val_loss: 0.4549 - val_accuracy: 0.8506\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4503 - accuracy: 0.8467 - val_loss: 0.4548 - val_accuracy: 0.8518\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4496 - accuracy: 0.8472 - val_loss: 0.4546 - val_accuracy: 0.8498\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4489 - accuracy: 0.8474 - val_loss: 0.4537 - val_accuracy: 0.8506\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4485 - accuracy: 0.8475 - val_loss: 0.4538 - val_accuracy: 0.8508\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4479 - accuracy: 0.8478 - val_loss: 0.4537 - val_accuracy: 0.8508\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4474 - accuracy: 0.8478 - val_loss: 0.4528 - val_accuracy: 0.8512\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4468 - accuracy: 0.8483 - val_loss: 0.4520 - val_accuracy: 0.8520\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4464 - accuracy: 0.8480 - val_loss: 0.4518 - val_accuracy: 0.8498\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4457 - accuracy: 0.8475 - val_loss: 0.4511 - val_accuracy: 0.8500\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4449 - accuracy: 0.8483 - val_loss: 0.4509 - val_accuracy: 0.8508\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4447 - accuracy: 0.8487 - val_loss: 0.4512 - val_accuracy: 0.8510\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4442 - accuracy: 0.8486 - val_loss: 0.4507 - val_accuracy: 0.8522\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4438 - accuracy: 0.8489 - val_loss: 0.4497 - val_accuracy: 0.8522\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4431 - accuracy: 0.8493 - val_loss: 0.4494 - val_accuracy: 0.8524\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4426 - accuracy: 0.8492 - val_loss: 0.4502 - val_accuracy: 0.8504\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4423 - accuracy: 0.8498 - val_loss: 0.4485 - val_accuracy: 0.8532\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4417 - accuracy: 0.8495 - val_loss: 0.4482 - val_accuracy: 0.8534\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 0.4534 - accuracy: 0.8485\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 1.4018 - accuracy: 0.5846 - val_loss: 1.0323 - val_accuracy: 0.6834\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.9466 - accuracy: 0.7000 - val_loss: 0.8566 - val_accuracy: 0.7266\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.8285 - accuracy: 0.7341 - val_loss: 0.7789 - val_accuracy: 0.7530\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.7657 - accuracy: 0.7566 - val_loss: 0.7276 - val_accuracy: 0.7726\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7237 - accuracy: 0.7703 - val_loss: 0.6953 - val_accuracy: 0.7794\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6936 - accuracy: 0.7802 - val_loss: 0.6689 - val_accuracy: 0.7902\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6698 - accuracy: 0.7886 - val_loss: 0.6486 - val_accuracy: 0.7978\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6506 - accuracy: 0.7937 - val_loss: 0.6316 - val_accuracy: 0.8028\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.6348 - accuracy: 0.7977 - val_loss: 0.6166 - val_accuracy: 0.8064\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.6211 - accuracy: 0.8022 - val_loss: 0.6062 - val_accuracy: 0.8096\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6095 - accuracy: 0.8056 - val_loss: 0.5956 - val_accuracy: 0.8096\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5993 - accuracy: 0.8079 - val_loss: 0.5862 - val_accuracy: 0.8164\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5903 - accuracy: 0.8099 - val_loss: 0.5779 - val_accuracy: 0.8166\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5822 - accuracy: 0.8119 - val_loss: 0.5706 - val_accuracy: 0.8172\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5749 - accuracy: 0.8145 - val_loss: 0.5631 - val_accuracy: 0.8220\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5681 - accuracy: 0.8157 - val_loss: 0.5587 - val_accuracy: 0.8236\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5620 - accuracy: 0.8179 - val_loss: 0.5517 - val_accuracy: 0.8262\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5567 - accuracy: 0.8189 - val_loss: 0.5470 - val_accuracy: 0.8276\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5515 - accuracy: 0.8204 - val_loss: 0.5435 - val_accuracy: 0.8290\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5468 - accuracy: 0.8216 - val_loss: 0.5394 - val_accuracy: 0.8308\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5422 - accuracy: 0.8226 - val_loss: 0.5346 - val_accuracy: 0.8306\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5382 - accuracy: 0.8248 - val_loss: 0.5309 - val_accuracy: 0.8328\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5345 - accuracy: 0.8253 - val_loss: 0.5272 - val_accuracy: 0.8348\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5308 - accuracy: 0.8263 - val_loss: 0.5244 - val_accuracy: 0.8358\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5273 - accuracy: 0.8266 - val_loss: 0.5221 - val_accuracy: 0.8356\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5242 - accuracy: 0.8283 - val_loss: 0.5179 - val_accuracy: 0.8364\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5211 - accuracy: 0.8297 - val_loss: 0.5161 - val_accuracy: 0.8368\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5183 - accuracy: 0.8298 - val_loss: 0.5136 - val_accuracy: 0.8372\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5156 - accuracy: 0.8300 - val_loss: 0.5102 - val_accuracy: 0.8378\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5130 - accuracy: 0.8307 - val_loss: 0.5080 - val_accuracy: 0.8390\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5104 - accuracy: 0.8318 - val_loss: 0.5084 - val_accuracy: 0.8366\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5081 - accuracy: 0.8324 - val_loss: 0.5039 - val_accuracy: 0.8394\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5059 - accuracy: 0.8322 - val_loss: 0.5016 - val_accuracy: 0.8400\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5035 - accuracy: 0.8337 - val_loss: 0.5001 - val_accuracy: 0.8396\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5016 - accuracy: 0.8346 - val_loss: 0.4977 - val_accuracy: 0.8416\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4997 - accuracy: 0.8352 - val_loss: 0.4965 - val_accuracy: 0.8414\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4978 - accuracy: 0.8351 - val_loss: 0.4941 - val_accuracy: 0.8430\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4958 - accuracy: 0.8355 - val_loss: 0.4927 - val_accuracy: 0.8420\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4941 - accuracy: 0.8360 - val_loss: 0.4927 - val_accuracy: 0.8406\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4922 - accuracy: 0.8361 - val_loss: 0.4922 - val_accuracy: 0.8410\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4907 - accuracy: 0.8370 - val_loss: 0.4892 - val_accuracy: 0.8430\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4891 - accuracy: 0.8372 - val_loss: 0.4868 - val_accuracy: 0.8426\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4876 - accuracy: 0.8372 - val_loss: 0.4859 - val_accuracy: 0.8428\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4861 - accuracy: 0.8379 - val_loss: 0.4848 - val_accuracy: 0.8430\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4846 - accuracy: 0.8381 - val_loss: 0.4834 - val_accuracy: 0.8440\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4833 - accuracy: 0.8388 - val_loss: 0.4828 - val_accuracy: 0.8432\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4819 - accuracy: 0.8390 - val_loss: 0.4816 - val_accuracy: 0.8432\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4806 - accuracy: 0.8398 - val_loss: 0.4805 - val_accuracy: 0.8422 accura\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4793 - accuracy: 0.8400 - val_loss: 0.4785 - val_accuracy: 0.8450\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4781 - accuracy: 0.8396 - val_loss: 0.4773 - val_accuracy: 0.8446\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4770 - accuracy: 0.8402 - val_loss: 0.4766 - val_accuracy: 0.8442\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4757 - accuracy: 0.8413 - val_loss: 0.4751 - val_accuracy: 0.8454\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4745 - accuracy: 0.8411 - val_loss: 0.4746 - val_accuracy: 0.8448\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4734 - accuracy: 0.8416 - val_loss: 0.4733 - val_accuracy: 0.8466\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4723 - accuracy: 0.8425 - val_loss: 0.4731 - val_accuracy: 0.8454\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4713 - accuracy: 0.8421 - val_loss: 0.4720 - val_accuracy: 0.8452\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4703 - accuracy: 0.8426 - val_loss: 0.4712 - val_accuracy: 0.8450\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4691 - accuracy: 0.8426 - val_loss: 0.4709 - val_accuracy: 0.8458\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4682 - accuracy: 0.8433 - val_loss: 0.4694 - val_accuracy: 0.8468\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4673 - accuracy: 0.8437 - val_loss: 0.4691 - val_accuracy: 0.8480\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4664 - accuracy: 0.8439 - val_loss: 0.4681 - val_accuracy: 0.8484\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4654 - accuracy: 0.8443 - val_loss: 0.4687 - val_accuracy: 0.8474\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4645 - accuracy: 0.8448 - val_loss: 0.4660 - val_accuracy: 0.8478\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4637 - accuracy: 0.8454 - val_loss: 0.4662 - val_accuracy: 0.8488\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4627 - accuracy: 0.8449 - val_loss: 0.4657 - val_accuracy: 0.8482\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4620 - accuracy: 0.8449 - val_loss: 0.4639 - val_accuracy: 0.8482\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4609 - accuracy: 0.8457 - val_loss: 0.4634 - val_accuracy: 0.8480\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4604 - accuracy: 0.8454 - val_loss: 0.4633 - val_accuracy: 0.8492\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4596 - accuracy: 0.8458 - val_loss: 0.4627 - val_accuracy: 0.8486\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4587 - accuracy: 0.8458 - val_loss: 0.4623 - val_accuracy: 0.8494\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4580 - accuracy: 0.8466 - val_loss: 0.4623 - val_accuracy: 0.8494\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4573 - accuracy: 0.8465 - val_loss: 0.4602 - val_accuracy: 0.8482\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4566 - accuracy: 0.8473 - val_loss: 0.4602 - val_accuracy: 0.8510\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4558 - accuracy: 0.8462 - val_loss: 0.4594 - val_accuracy: 0.8516\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4551 - accuracy: 0.8464 - val_loss: 0.4597 - val_accuracy: 0.8496\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4544 - accuracy: 0.8471 - val_loss: 0.4582 - val_accuracy: 0.8510\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4538 - accuracy: 0.8477 - val_loss: 0.4573 - val_accuracy: 0.8504\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4529 - accuracy: 0.8474 - val_loss: 0.4575 - val_accuracy: 0.8482\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4523 - accuracy: 0.8474 - val_loss: 0.4561 - val_accuracy: 0.8498\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4518 - accuracy: 0.8482 - val_loss: 0.4567 - val_accuracy: 0.8516\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4512 - accuracy: 0.8478 - val_loss: 0.4562 - val_accuracy: 0.8506\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4505 - accuracy: 0.8479 - val_loss: 0.4563 - val_accuracy: 0.8506\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4500 - accuracy: 0.8487 - val_loss: 0.4545 - val_accuracy: 0.8530\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4493 - accuracy: 0.8482 - val_loss: 0.4543 - val_accuracy: 0.8518\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4488 - accuracy: 0.8485 - val_loss: 0.4537 - val_accuracy: 0.8540\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4482 - accuracy: 0.8488 - val_loss: 0.4537 - val_accuracy: 0.8516\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4476 - accuracy: 0.8490 - val_loss: 0.4524 - val_accuracy: 0.8542\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4470 - accuracy: 0.8492 - val_loss: 0.4522 - val_accuracy: 0.8510\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4465 - accuracy: 0.8496 - val_loss: 0.4534 - val_accuracy: 0.8518\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4460 - accuracy: 0.8493 - val_loss: 0.4519 - val_accuracy: 0.8510\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4454 - accuracy: 0.8500 - val_loss: 0.4529 - val_accuracy: 0.8522\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4449 - accuracy: 0.8499 - val_loss: 0.4506 - val_accuracy: 0.8526\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4443 - accuracy: 0.8500 - val_loss: 0.4503 - val_accuracy: 0.8548\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4439 - accuracy: 0.8506 - val_loss: 0.4495 - val_accuracy: 0.8538\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4433 - accuracy: 0.8507 - val_loss: 0.4505 - val_accuracy: 0.8508\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4429 - accuracy: 0.8504 - val_loss: 0.4495 - val_accuracy: 0.8534\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4423 - accuracy: 0.8504 - val_loss: 0.4489 - val_accuracy: 0.8530\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4418 - accuracy: 0.8509 - val_loss: 0.4477 - val_accuracy: 0.8532\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4414 - accuracy: 0.8511 - val_loss: 0.4479 - val_accuracy: 0.8556\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4410 - accuracy: 0.8506 - val_loss: 0.4476 - val_accuracy: 0.8554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18333/18333 [==============================] - 0s 20us/sample - loss: 0.4544 - accuracy: 0.8449\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.6838 - accuracy: 0.5180 - val_loss: 1.2790 - val_accuracy: 0.6608\n",
      "Epoch 2/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 1.1419 - accuracy: 0.6739 - val_loss: 1.0248 - val_accuracy: 0.6884\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.9736 - accuracy: 0.7000 - val_loss: 0.9123 - val_accuracy: 0.7124\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.8875 - accuracy: 0.7205 - val_loss: 0.8457 - val_accuracy: 0.7296\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.8324 - accuracy: 0.7368 - val_loss: 0.8012 - val_accuracy: 0.7432\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.7930 - accuracy: 0.7488 - val_loss: 0.7675 - val_accuracy: 0.7576\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.7628 - accuracy: 0.7568 - val_loss: 0.7404 - val_accuracy: 0.7680\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.7386 - accuracy: 0.7647 - val_loss: 0.7191 - val_accuracy: 0.7718\n",
      "Epoch 9/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.7184 - accuracy: 0.7715 - val_loss: 0.7016 - val_accuracy: 0.7828\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.7014 - accuracy: 0.7778 - val_loss: 0.6862 - val_accuracy: 0.7860- loss: 0.7019 - accura\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.6867 - accuracy: 0.7829 - val_loss: 0.6730 - val_accuracy: 0.7900\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.6740 - accuracy: 0.7868 - val_loss: 0.6605 - val_accuracy: 0.7956\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.6626 - accuracy: 0.7902 - val_loss: 0.6501 - val_accuracy: 0.7980\n",
      "Epoch 14/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.6524 - accuracy: 0.7942 - val_loss: 0.6415 - val_accuracy: 0.7998\n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.6432 - accuracy: 0.7959 - val_loss: 0.6320 - val_accuracy: 0.8012\n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.6349 - accuracy: 0.7980 - val_loss: 0.6250 - val_accuracy: 0.8052\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.6273 - accuracy: 0.8006 - val_loss: 0.6180 - val_accuracy: 0.8060ss: 0.6287 - accu\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.6203 - accuracy: 0.8021 - val_loss: 0.6111 - val_accuracy: 0.8092\n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.6139 - accuracy: 0.8042 - val_loss: 0.6048 - val_accuracy: 0.8094\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.6078 - accuracy: 0.8053 - val_loss: 0.5998 - val_accuracy: 0.8106\n",
      "Epoch 21/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.6024 - accuracy: 0.8072 - val_loss: 0.5951 - val_accuracy: 0.8120\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5972 - accuracy: 0.8083 - val_loss: 0.5899 - val_accuracy: 0.8124\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5923 - accuracy: 0.8094 - val_loss: 0.5849 - val_accuracy: 0.8154\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5878 - accuracy: 0.8108 - val_loss: 0.5811 - val_accuracy: 0.8164\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5834 - accuracy: 0.8125 - val_loss: 0.5761 - val_accuracy: 0.8160\n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5795 - accuracy: 0.8127 - val_loss: 0.5730 - val_accuracy: 0.8176\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5755 - accuracy: 0.8144 - val_loss: 0.5686 - val_accuracy: 0.8186\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5719 - accuracy: 0.8148 - val_loss: 0.5665 - val_accuracy: 0.8204\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5684 - accuracy: 0.8160 - val_loss: 0.5632 - val_accuracy: 0.8200\n",
      "Epoch 30/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5652 - accuracy: 0.8166 - val_loss: 0.5595 - val_accuracy: 0.8230\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5620 - accuracy: 0.8172 - val_loss: 0.5561 - val_accuracy: 0.8228\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5590 - accuracy: 0.8184 - val_loss: 0.5543 - val_accuracy: 0.8236\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5562 - accuracy: 0.8197 - val_loss: 0.5506 - val_accuracy: 0.8236\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5534 - accuracy: 0.8201 - val_loss: 0.5485 - val_accuracy: 0.8250\n",
      "Epoch 35/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5507 - accuracy: 0.8211 - val_loss: 0.5458 - val_accuracy: 0.8252\n",
      "Epoch 36/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5482 - accuracy: 0.8214 - val_loss: 0.5434 - val_accuracy: 0.8264\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5457 - accuracy: 0.8220 - val_loss: 0.5409 - val_accuracy: 0.8266\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5435 - accuracy: 0.8226 - val_loss: 0.5391 - val_accuracy: 0.8266\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5412 - accuracy: 0.8232 - val_loss: 0.5367 - val_accuracy: 0.8276\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5388 - accuracy: 0.8245 - val_loss: 0.5358 - val_accuracy: 0.8272\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5369 - accuracy: 0.8243 - val_loss: 0.5329 - val_accuracy: 0.8278\n",
      "Epoch 42/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5349 - accuracy: 0.8248 - val_loss: 0.5309 - val_accuracy: 0.8278\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5329 - accuracy: 0.8258 - val_loss: 0.5293 - val_accuracy: 0.8290\n",
      "Epoch 44/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5311 - accuracy: 0.8264 - val_loss: 0.5277 - val_accuracy: 0.8298\n",
      "Epoch 45/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5292 - accuracy: 0.8271 - val_loss: 0.5258 - val_accuracy: 0.8318\n",
      "Epoch 46/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5274 - accuracy: 0.8268 - val_loss: 0.5243 - val_accuracy: 0.8314- loss: 0.529\n",
      "Epoch 47/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5257 - accuracy: 0.8275 - val_loss: 0.5226 - val_accuracy: 0.8322\n",
      "Epoch 48/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5240 - accuracy: 0.8279 - val_loss: 0.5210 - val_accuracy: 0.8324\n",
      "Epoch 49/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5224 - accuracy: 0.8287 - val_loss: 0.5194 - val_accuracy: 0.8328y: 0.\n",
      "Epoch 50/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5207 - accuracy: 0.8291 - val_loss: 0.5187 - val_accuracy: 0.8324\n",
      "Epoch 51/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5192 - accuracy: 0.8291 - val_loss: 0.5162 - val_accuracy: 0.8324\n",
      "Epoch 52/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5178 - accuracy: 0.8305 - val_loss: 0.5146 - val_accuracy: 0.8336\n",
      "Epoch 53/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5163 - accuracy: 0.8303 - val_loss: 0.5136 - val_accuracy: 0.8334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5148 - accuracy: 0.8310 - val_loss: 0.5121 - val_accuracy: 0.8332\n",
      "Epoch 55/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5135 - accuracy: 0.8309 - val_loss: 0.5114 - val_accuracy: 0.8324\n",
      "Epoch 56/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5121 - accuracy: 0.8310 - val_loss: 0.5096 - val_accuracy: 0.8350\n",
      "Epoch 57/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5108 - accuracy: 0.8323 - val_loss: 0.5091 - val_accuracy: 0.8354\n",
      "Epoch 58/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5095 - accuracy: 0.8323 - val_loss: 0.5078 - val_accuracy: 0.8342\n",
      "Epoch 59/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5083 - accuracy: 0.8322 - val_loss: 0.5061 - val_accuracy: 0.8366\n",
      "Epoch 60/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5071 - accuracy: 0.8330 - val_loss: 0.5048 - val_accuracy: 0.8354\n",
      "Epoch 61/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5059 - accuracy: 0.8331 - val_loss: 0.5041 - val_accuracy: 0.8374\n",
      "Epoch 62/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5047 - accuracy: 0.8332 - val_loss: 0.5029 - val_accuracy: 0.8364\n",
      "Epoch 63/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5035 - accuracy: 0.8339 - val_loss: 0.5017 - val_accuracy: 0.8364\n",
      "Epoch 64/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5024 - accuracy: 0.8336 - val_loss: 0.5011 - val_accuracy: 0.8364\n",
      "Epoch 65/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5014 - accuracy: 0.8342 - val_loss: 0.4997 - val_accuracy: 0.8366\n",
      "Epoch 66/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5002 - accuracy: 0.8349 - val_loss: 0.4987 - val_accuracy: 0.8376\n",
      "Epoch 67/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4992 - accuracy: 0.8350 - val_loss: 0.4979 - val_accuracy: 0.8356\n",
      "Epoch 68/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4982 - accuracy: 0.8354 - val_loss: 0.4971 - val_accuracy: 0.8378\n",
      "Epoch 69/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4972 - accuracy: 0.8349 - val_loss: 0.4965 - val_accuracy: 0.8378\n",
      "Epoch 70/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4961 - accuracy: 0.8362 - val_loss: 0.4955 - val_accuracy: 0.8382\n",
      "Epoch 71/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4952 - accuracy: 0.8357 - val_loss: 0.4942 - val_accuracy: 0.8388\n",
      "Epoch 72/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4943 - accuracy: 0.8364 - val_loss: 0.4936 - val_accuracy: 0.8402\n",
      "Epoch 73/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4934 - accuracy: 0.8366 - val_loss: 0.4932 - val_accuracy: 0.8382\n",
      "Epoch 74/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4925 - accuracy: 0.8372 - val_loss: 0.4926 - val_accuracy: 0.8400\n",
      "Epoch 75/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4916 - accuracy: 0.8369 - val_loss: 0.4912 - val_accuracy: 0.8398\n",
      "Epoch 76/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4906 - accuracy: 0.8369 - val_loss: 0.4912 - val_accuracy: 0.8398\n",
      "Epoch 77/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4898 - accuracy: 0.8380 - val_loss: 0.4899 - val_accuracy: 0.8418\n",
      "Epoch 78/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4890 - accuracy: 0.8369 - val_loss: 0.4886 - val_accuracy: 0.8406\n",
      "Epoch 79/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4881 - accuracy: 0.8385 - val_loss: 0.4884 - val_accuracy: 0.8408\n",
      "Epoch 80/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4873 - accuracy: 0.8384 - val_loss: 0.4883 - val_accuracy: 0.8412\n",
      "Epoch 81/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4865 - accuracy: 0.8386 - val_loss: 0.4868 - val_accuracy: 0.8412\n",
      "Epoch 82/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4857 - accuracy: 0.8392 - val_loss: 0.4867 - val_accuracy: 0.8414\n",
      "Epoch 83/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.4850 - accuracy: 0.8390 - val_loss: 0.4852 - val_accuracy: 0.8422\n",
      "Epoch 84/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.4841 - accuracy: 0.8395 - val_loss: 0.4846 - val_accuracy: 0.8424\n",
      "Epoch 85/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4835 - accuracy: 0.8394 - val_loss: 0.4840 - val_accuracy: 0.8420\n",
      "Epoch 86/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4827 - accuracy: 0.8396 - val_loss: 0.4831 - val_accuracy: 0.8422\n",
      "Epoch 87/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4819 - accuracy: 0.8397 - val_loss: 0.4832 - val_accuracy: 0.8426\n",
      "Epoch 88/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4812 - accuracy: 0.8401 - val_loss: 0.4825 - val_accuracy: 0.8414\n",
      "Epoch 89/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4805 - accuracy: 0.8403 - val_loss: 0.4811 - val_accuracy: 0.8428\n",
      "Epoch 90/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4799 - accuracy: 0.8402 - val_loss: 0.4809 - val_accuracy: 0.8428\n",
      "Epoch 91/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4792 - accuracy: 0.8411 - val_loss: 0.4805 - val_accuracy: 0.8422\n",
      "Epoch 92/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4785 - accuracy: 0.8405 - val_loss: 0.4794 - val_accuracy: 0.8430\n",
      "Epoch 93/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4778 - accuracy: 0.8411 - val_loss: 0.4790 - val_accuracy: 0.8438\n",
      "Epoch 94/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4772 - accuracy: 0.8414 - val_loss: 0.4787 - val_accuracy: 0.8438\n",
      "Epoch 95/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4766 - accuracy: 0.8415 - val_loss: 0.4776 - val_accuracy: 0.8426\n",
      "Epoch 96/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4759 - accuracy: 0.8420 - val_loss: 0.4775 - val_accuracy: 0.8440\n",
      "Epoch 97/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4753 - accuracy: 0.8420 - val_loss: 0.4767 - val_accuracy: 0.8448\n",
      "Epoch 98/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.4746 - accuracy: 0.8420 - val_loss: 0.4761 - val_accuracy: 0.8442\n",
      "Epoch 99/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4741 - accuracy: 0.8426 - val_loss: 0.4757 - val_accuracy: 0.8452\n",
      "Epoch 100/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4735 - accuracy: 0.8423 - val_loss: 0.4753 - val_accuracy: 0.8454\n",
      "18334/18334 [==============================] - 0s 22us/sample - loss: 0.4900 - accuracy: 0.8334\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.6658 - accuracy: 0.5080 - val_loss: 1.2837 - val_accuracy: 0.6468\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 1.1531 - accuracy: 0.6602 - val_loss: 1.0378 - val_accuracy: 0.6792\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.9895 - accuracy: 0.6870 - val_loss: 0.9271 - val_accuracy: 0.7068\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.9040 - accuracy: 0.7074 - val_loss: 0.8607 - val_accuracy: 0.7276\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.8490 - accuracy: 0.7231 - val_loss: 0.8153 - val_accuracy: 0.7414\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.8091 - accuracy: 0.7361 - val_loss: 0.7803 - val_accuracy: 0.7506\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.7786 - accuracy: 0.7462 - val_loss: 0.7543 - val_accuracy: 0.7600\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.7540 - accuracy: 0.7545 - val_loss: 0.7315 - val_accuracy: 0.7664\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.7334 - accuracy: 0.7613 - val_loss: 0.7132 - val_accuracy: 0.7746\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.7160 - accuracy: 0.7679 - val_loss: 0.6973 - val_accuracy: 0.7788\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7010 - accuracy: 0.7722 - val_loss: 0.6837 - val_accuracy: 0.7834\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6877 - accuracy: 0.7770 - val_loss: 0.6722 - val_accuracy: 0.7844\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6761 - accuracy: 0.7801 - val_loss: 0.6610 - val_accuracy: 0.7898\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6654 - accuracy: 0.7838 - val_loss: 0.6509 - val_accuracy: 0.7956\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6559 - accuracy: 0.7878 - val_loss: 0.6422 - val_accuracy: 0.7968\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6474 - accuracy: 0.7900 - val_loss: 0.6341 - val_accuracy: 0.8006\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6393 - accuracy: 0.7934 - val_loss: 0.6277 - val_accuracy: 0.7998\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6321 - accuracy: 0.7955 - val_loss: 0.6199 - val_accuracy: 0.8062\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6253 - accuracy: 0.7975 - val_loss: 0.6139 - val_accuracy: 0.8078\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6191 - accuracy: 0.7998 - val_loss: 0.6080 - val_accuracy: 0.8108\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6133 - accuracy: 0.8009 - val_loss: 0.6021 - val_accuracy: 0.8120\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.6078 - accuracy: 0.8024 - val_loss: 0.5968 - val_accuracy: 0.8134\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.6028 - accuracy: 0.8036 - val_loss: 0.5930 - val_accuracy: 0.8138\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5980 - accuracy: 0.8048 - val_loss: 0.5879 - val_accuracy: 0.8152\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5935 - accuracy: 0.8067 - val_loss: 0.5839 - val_accuracy: 0.8160\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5891 - accuracy: 0.8083 - val_loss: 0.5795 - val_accuracy: 0.8170\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5852 - accuracy: 0.8084 - val_loss: 0.5758 - val_accuracy: 0.8176\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5814 - accuracy: 0.8107 - val_loss: 0.5724 - val_accuracy: 0.8186\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5777 - accuracy: 0.8109 - val_loss: 0.5689 - val_accuracy: 0.8188\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5742 - accuracy: 0.8122 - val_loss: 0.5655 - val_accuracy: 0.8208\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5709 - accuracy: 0.8130 - val_loss: 0.5625 - val_accuracy: 0.8214\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5677 - accuracy: 0.8143 - val_loss: 0.5600 - val_accuracy: 0.8226\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5648 - accuracy: 0.8154 - val_loss: 0.5568 - val_accuracy: 0.8220\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5619 - accuracy: 0.8161 - val_loss: 0.5540 - val_accuracy: 0.8228\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5591 - accuracy: 0.8170 - val_loss: 0.5517 - val_accuracy: 0.8238\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5564 - accuracy: 0.8165 - val_loss: 0.5491 - val_accuracy: 0.8264\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5539 - accuracy: 0.8178 - val_loss: 0.5474 - val_accuracy: 0.8260\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5514 - accuracy: 0.8187 - val_loss: 0.5445 - val_accuracy: 0.8256\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5491 - accuracy: 0.8196 - val_loss: 0.5423 - val_accuracy: 0.8274\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5468 - accuracy: 0.8207 - val_loss: 0.5404 - val_accuracy: 0.8290\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5445 - accuracy: 0.8204 - val_loss: 0.5384 - val_accuracy: 0.8292\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5424 - accuracy: 0.8217 - val_loss: 0.5361 - val_accuracy: 0.8292\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5403 - accuracy: 0.8215 - val_loss: 0.5342 - val_accuracy: 0.8294\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5383 - accuracy: 0.8226 - val_loss: 0.5323 - val_accuracy: 0.8308\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5364 - accuracy: 0.8229 - val_loss: 0.5303 - val_accuracy: 0.8310s - loss: 0.5370 - ac\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5345 - accuracy: 0.8229 - val_loss: 0.5290 - val_accuracy: 0.8326\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5326 - accuracy: 0.8237 - val_loss: 0.5272 - val_accuracy: 0.8322\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5310 - accuracy: 0.8248 - val_loss: 0.5252 - val_accuracy: 0.8310\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5292 - accuracy: 0.8249 - val_loss: 0.5237 - val_accuracy: 0.8314\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5276 - accuracy: 0.8253 - val_loss: 0.5224 - val_accuracy: 0.8314\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5260 - accuracy: 0.8256 - val_loss: 0.5211 - val_accuracy: 0.8336\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5244 - accuracy: 0.8262 - val_loss: 0.5195 - val_accuracy: 0.8320\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5229 - accuracy: 0.8262 - val_loss: 0.5182 - val_accuracy: 0.8342\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5215 - accuracy: 0.8266 - val_loss: 0.5168 - val_accuracy: 0.8328\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5200 - accuracy: 0.8273 - val_loss: 0.5155 - val_accuracy: 0.8328\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5185 - accuracy: 0.8272 - val_loss: 0.5145 - val_accuracy: 0.834488 - accuracy: 0.\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5172 - accuracy: 0.8277 - val_loss: 0.5126 - val_accuracy: 0.8350\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5159 - accuracy: 0.8279 - val_loss: 0.5113 - val_accuracy: 0.8352\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5146 - accuracy: 0.8282 - val_loss: 0.5105 - val_accuracy: 0.8344\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5133 - accuracy: 0.8286 - val_loss: 0.5089 - val_accuracy: 0.8364\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5120 - accuracy: 0.8290 - val_loss: 0.5078 - val_accuracy: 0.8352ss: 0.5131 - ac\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5108 - accuracy: 0.8289 - val_loss: 0.5070 - val_accuracy: 0.8366\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5096 - accuracy: 0.8292 - val_loss: 0.5058 - val_accuracy: 0.8368\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5084 - accuracy: 0.8301 - val_loss: 0.5049 - val_accuracy: 0.8354\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5074 - accuracy: 0.8301 - val_loss: 0.5041 - val_accuracy: 0.8352\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5062 - accuracy: 0.8306 - val_loss: 0.5030 - val_accuracy: 0.8358\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5051 - accuracy: 0.8304 - val_loss: 0.5026 - val_accuracy: 0.8358ss: 0.5052 - ac\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5041 - accuracy: 0.8309 - val_loss: 0.5010 - val_accuracy: 0.8370\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5031 - accuracy: 0.8319 - val_loss: 0.4998 - val_accuracy: 0.8374\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5019 - accuracy: 0.8316 - val_loss: 0.4986 - val_accuracy: 0.8374\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5010 - accuracy: 0.8317 - val_loss: 0.4981 - val_accuracy: 0.8372\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5000 - accuracy: 0.8323 - val_loss: 0.4973 - val_accuracy: 0.8378\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4991 - accuracy: 0.8321 - val_loss: 0.4963 - val_accuracy: 0.8384\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4981 - accuracy: 0.8327 - val_loss: 0.4955 - val_accuracy: 0.8358\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4971 - accuracy: 0.8334 - val_loss: 0.4948 - val_accuracy: 0.8374\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4963 - accuracy: 0.8333 - val_loss: 0.4940 - val_accuracy: 0.8384\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4954 - accuracy: 0.8336 - val_loss: 0.4927 - val_accuracy: 0.8374\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4945 - accuracy: 0.8330 - val_loss: 0.4921 - val_accuracy: 0.8376\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4936 - accuracy: 0.8336 - val_loss: 0.4918 - val_accuracy: 0.8390\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4928 - accuracy: 0.8338 - val_loss: 0.4907 - val_accuracy: 0.8386\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4920 - accuracy: 0.8342 - val_loss: 0.4902 - val_accuracy: 0.8392\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4912 - accuracy: 0.8338 - val_loss: 0.4895 - val_accuracy: 0.8386\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4904 - accuracy: 0.8343 - val_loss: 0.4888 - val_accuracy: 0.8402\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4895 - accuracy: 0.8350 - val_loss: 0.4877 - val_accuracy: 0.8392\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4887 - accuracy: 0.8354 - val_loss: 0.4872 - val_accuracy: 0.8412\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4881 - accuracy: 0.8357 - val_loss: 0.4862 - val_accuracy: 0.8400\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4873 - accuracy: 0.8363 - val_loss: 0.4857 - val_accuracy: 0.8402\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4865 - accuracy: 0.8359 - val_loss: 0.4849 - val_accuracy: 0.8414\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4858 - accuracy: 0.8369 - val_loss: 0.4851 - val_accuracy: 0.8404\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4851 - accuracy: 0.8370 - val_loss: 0.4836 - val_accuracy: 0.8414\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4844 - accuracy: 0.8367 - val_loss: 0.4830 - val_accuracy: 0.8408\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4836 - accuracy: 0.8368 - val_loss: 0.4829 - val_accuracy: 0.8402\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4830 - accuracy: 0.8374 - val_loss: 0.4820 - val_accuracy: 0.8414\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4823 - accuracy: 0.8375 - val_loss: 0.4810 - val_accuracy: 0.8408\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4816 - accuracy: 0.8379 - val_loss: 0.4810 - val_accuracy: 0.8412\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4809 - accuracy: 0.8377 - val_loss: 0.4802 - val_accuracy: 0.8412\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4803 - accuracy: 0.8383 - val_loss: 0.4797 - val_accuracy: 0.8422\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4797 - accuracy: 0.8388 - val_loss: 0.4790 - val_accuracy: 0.8412\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4790 - accuracy: 0.8388 - val_loss: 0.4790 - val_accuracy: 0.8416\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4785 - accuracy: 0.8385 - val_loss: 0.4783 - val_accuracy: 0.8428\n",
      "18333/18333 [==============================] - 0s 19us/sample - loss: 0.4844 - accuracy: 0.8396\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.6077 - accuracy: 0.5095 - val_loss: 1.2546 - val_accuracy: 0.6540\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 1.1387 - accuracy: 0.6632 - val_loss: 1.0223 - val_accuracy: 0.6866\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.9811 - accuracy: 0.6915 - val_loss: 0.9142 - val_accuracy: 0.7156\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.8973 - accuracy: 0.7120 - val_loss: 0.8490 - val_accuracy: 0.7310\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.8429 - accuracy: 0.7293 - val_loss: 0.8042 - val_accuracy: 0.7454\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.8034 - accuracy: 0.7417 - val_loss: 0.7708 - val_accuracy: 0.7572\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7728 - accuracy: 0.7515 - val_loss: 0.7451 - val_accuracy: 0.7656\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.7485 - accuracy: 0.7597 - val_loss: 0.7222 - val_accuracy: 0.7750\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.7281 - accuracy: 0.7669 - val_loss: 0.7047 - val_accuracy: 0.7786\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.7108 - accuracy: 0.7728 - val_loss: 0.6888 - val_accuracy: 0.7828\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.6957 - accuracy: 0.7779 - val_loss: 0.6753 - val_accuracy: 0.7856\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.6826 - accuracy: 0.7827 - val_loss: 0.6635 - val_accuracy: 0.7908\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6708 - accuracy: 0.7868 - val_loss: 0.6533 - val_accuracy: 0.7918\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6605 - accuracy: 0.7893 - val_loss: 0.6436 - val_accuracy: 0.7972\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6510 - accuracy: 0.7923 - val_loss: 0.6346 - val_accuracy: 0.7990\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6424 - accuracy: 0.7950 - val_loss: 0.6270 - val_accuracy: 0.8002\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6346 - accuracy: 0.7974 - val_loss: 0.6192 - val_accuracy: 0.8020\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.6274 - accuracy: 0.7994 - val_loss: 0.6129 - val_accuracy: 0.8050\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6207 - accuracy: 0.8014 - val_loss: 0.6072 - val_accuracy: 0.8056\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.6146 - accuracy: 0.8031 - val_loss: 0.6015 - val_accuracy: 0.8086\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6087 - accuracy: 0.8050 - val_loss: 0.5965 - val_accuracy: 0.8108\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.6035 - accuracy: 0.8063 - val_loss: 0.5910 - val_accuracy: 0.8102\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5983 - accuracy: 0.8076 - val_loss: 0.5867 - val_accuracy: 0.8140\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5937 - accuracy: 0.8094 - val_loss: 0.5819 - val_accuracy: 0.8142\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5891 - accuracy: 0.8109 - val_loss: 0.5789 - val_accuracy: 0.8152\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5849 - accuracy: 0.8118 - val_loss: 0.5738 - val_accuracy: 0.8166\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5810 - accuracy: 0.8130 - val_loss: 0.5702 - val_accuracy: 0.8174\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5771 - accuracy: 0.8134 - val_loss: 0.5672 - val_accuracy: 0.8170\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5736 - accuracy: 0.8150 - val_loss: 0.5635 - val_accuracy: 0.8196\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5702 - accuracy: 0.8147 - val_loss: 0.5609 - val_accuracy: 0.8200\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5668 - accuracy: 0.8165 - val_loss: 0.5574 - val_accuracy: 0.8216\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5638 - accuracy: 0.8165 - val_loss: 0.5547 - val_accuracy: 0.8216\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5608 - accuracy: 0.8180 - val_loss: 0.5523 - val_accuracy: 0.8232\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5580 - accuracy: 0.8186 - val_loss: 0.5496 - val_accuracy: 0.8236\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5552 - accuracy: 0.8185 - val_loss: 0.5468 - val_accuracy: 0.8248\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5527 - accuracy: 0.8198 - val_loss: 0.5445 - val_accuracy: 0.8264\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5501 - accuracy: 0.8202 - val_loss: 0.5423 - val_accuracy: 0.8272\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5476 - accuracy: 0.8212 - val_loss: 0.5403 - val_accuracy: 0.8260\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5452 - accuracy: 0.8216 - val_loss: 0.5371 - val_accuracy: 0.8284\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5431 - accuracy: 0.8235 - val_loss: 0.5353 - val_accuracy: 0.8292\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5409 - accuracy: 0.8231 - val_loss: 0.5340 - val_accuracy: 0.8282\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5389 - accuracy: 0.8230 - val_loss: 0.5318 - val_accuracy: 0.8298\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5369 - accuracy: 0.8241 - val_loss: 0.5309 - val_accuracy: 0.8292\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5349 - accuracy: 0.8243 - val_loss: 0.5279 - val_accuracy: 0.8320\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5331 - accuracy: 0.8251 - val_loss: 0.5266 - val_accuracy: 0.8310\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5312 - accuracy: 0.8253 - val_loss: 0.5249 - val_accuracy: 0.8314\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5294 - accuracy: 0.8265 - val_loss: 0.5239 - val_accuracy: 0.8310\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5277 - accuracy: 0.8265 - val_loss: 0.5219 - val_accuracy: 0.8314\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5260 - accuracy: 0.8271 - val_loss: 0.5199 - val_accuracy: 0.8332\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5244 - accuracy: 0.8275 - val_loss: 0.5186 - val_accuracy: 0.8338\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5229 - accuracy: 0.8281 - val_loss: 0.5170 - val_accuracy: 0.8342\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5212 - accuracy: 0.8275 - val_loss: 0.5157 - val_accuracy: 0.8332\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5198 - accuracy: 0.8283 - val_loss: 0.5145 - val_accuracy: 0.8334\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5184 - accuracy: 0.8292 - val_loss: 0.5135 - val_accuracy: 0.8344\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5169 - accuracy: 0.8294 - val_loss: 0.5122 - val_accuracy: 0.8346\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5156 - accuracy: 0.8292 - val_loss: 0.5107 - val_accuracy: 0.8350\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5143 - accuracy: 0.8300 - val_loss: 0.5095 - val_accuracy: 0.8356\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5128 - accuracy: 0.8302 - val_loss: 0.5086 - val_accuracy: 0.8352\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5116 - accuracy: 0.8306 - val_loss: 0.5080 - val_accuracy: 0.8346\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5104 - accuracy: 0.8311 - val_loss: 0.5065 - val_accuracy: 0.8358\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5092 - accuracy: 0.8316 - val_loss: 0.5053 - val_accuracy: 0.8366\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5080 - accuracy: 0.8313 - val_loss: 0.5042 - val_accuracy: 0.8376\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5067 - accuracy: 0.8321 - val_loss: 0.5029 - val_accuracy: 0.8370\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5056 - accuracy: 0.8319 - val_loss: 0.5020 - val_accuracy: 0.8376\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5045 - accuracy: 0.8321 - val_loss: 0.5014 - val_accuracy: 0.8362- loss: 0.5050 - accuracy: \n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5035 - accuracy: 0.8324 - val_loss: 0.4999 - val_accuracy: 0.8384\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5024 - accuracy: 0.8321 - val_loss: 0.4992 - val_accuracy: 0.8380\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5014 - accuracy: 0.8326 - val_loss: 0.4979 - val_accuracy: 0.8386\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5004 - accuracy: 0.8337 - val_loss: 0.4974 - val_accuracy: 0.8382\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4994 - accuracy: 0.8335 - val_loss: 0.4964 - val_accuracy: 0.8384\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4983 - accuracy: 0.8345 - val_loss: 0.4950 - val_accuracy: 0.8398\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4974 - accuracy: 0.8339 - val_loss: 0.4947 - val_accuracy: 0.8394\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4963 - accuracy: 0.8346 - val_loss: 0.4937 - val_accuracy: 0.8402\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4953 - accuracy: 0.8346 - val_loss: 0.4926 - val_accuracy: 0.8404\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4946 - accuracy: 0.8347 - val_loss: 0.4923 - val_accuracy: 0.8394\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4937 - accuracy: 0.8353 - val_loss: 0.4915 - val_accuracy: 0.8394\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4928 - accuracy: 0.8357 - val_loss: 0.4907 - val_accuracy: 0.8400\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4920 - accuracy: 0.8353 - val_loss: 0.4899 - val_accuracy: 0.8406\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - ETA: 0s - loss: 0.4917 - accuracy: 0.83 - 1s 29us/sample - loss: 0.4911 - accuracy: 0.8361 - val_loss: 0.4891 - val_accuracy: 0.8406\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4904 - accuracy: 0.8361 - val_loss: 0.4883 - val_accuracy: 0.8402\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4895 - accuracy: 0.8366 - val_loss: 0.4878 - val_accuracy: 0.8412\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4887 - accuracy: 0.8369 - val_loss: 0.4874 - val_accuracy: 0.8396\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4879 - accuracy: 0.8365 - val_loss: 0.4865 - val_accuracy: 0.8402\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4872 - accuracy: 0.8370 - val_loss: 0.4855 - val_accuracy: 0.8410\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4864 - accuracy: 0.8371 - val_loss: 0.4847 - val_accuracy: 0.8416\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4857 - accuracy: 0.8376 - val_loss: 0.4844 - val_accuracy: 0.8412\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4848 - accuracy: 0.8378 - val_loss: 0.4841 - val_accuracy: 0.8420\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4843 - accuracy: 0.8382 - val_loss: 0.4832 - val_accuracy: 0.8412\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4835 - accuracy: 0.8386 - val_loss: 0.4824 - val_accuracy: 0.8414\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4828 - accuracy: 0.8383 - val_loss: 0.4814 - val_accuracy: 0.8432\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4821 - accuracy: 0.8384 - val_loss: 0.4813 - val_accuracy: 0.8418\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4813 - accuracy: 0.8387 - val_loss: 0.4809 - val_accuracy: 0.8408\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4807 - accuracy: 0.8388 - val_loss: 0.4798 - val_accuracy: 0.8420\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4801 - accuracy: 0.8392 - val_loss: 0.4795 - val_accuracy: 0.8430\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4795 - accuracy: 0.8394 - val_loss: 0.4787 - val_accuracy: 0.8428\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4788 - accuracy: 0.8394 - val_loss: 0.4785 - val_accuracy: 0.8422\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4782 - accuracy: 0.8394 - val_loss: 0.4773 - val_accuracy: 0.8434\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4775 - accuracy: 0.8398 - val_loss: 0.4771 - val_accuracy: 0.8454\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4770 - accuracy: 0.8396 - val_loss: 0.4765 - val_accuracy: 0.8436\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4763 - accuracy: 0.8399 - val_loss: 0.4762 - val_accuracy: 0.8438\n",
      "18333/18333 [==============================] - 0s 18us/sample - loss: 0.4846 - accuracy: 0.8361\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 2.1468 - accuracy: 0.2494 - val_loss: 1.9956 - val_accuracy: 0.3286\n",
      "Epoch 2/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 1.8773 - accuracy: 0.3871 - val_loss: 1.7585 - val_accuracy: 0.4396\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 1.6575 - accuracy: 0.4831 - val_loss: 1.5518 - val_accuracy: 0.5294\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 1.4702 - accuracy: 0.5559 - val_loss: 1.3765 - val_accuracy: 0.5836\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 1.3115 - accuracy: 0.5979 - val_loss: 1.2365 - val_accuracy: 0.6178\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 1.1946 - accuracy: 0.6278 - val_loss: 1.1388 - val_accuracy: 0.6474\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 1.1110 - accuracy: 0.6519 - val_loss: 1.0676 - val_accuracy: 0.6708\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 1.0485 - accuracy: 0.6687 - val_loss: 1.0130 - val_accuracy: 0.6864\n",
      "Epoch 9/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.9994 - accuracy: 0.6822 - val_loss: 0.9692 - val_accuracy: 0.6932\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.9595 - accuracy: 0.6936 - val_loss: 0.9329 - val_accuracy: 0.7004\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.9261 - accuracy: 0.7024 - val_loss: 0.9027 - val_accuracy: 0.7106\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.8973 - accuracy: 0.7094 - val_loss: 0.8760 - val_accuracy: 0.7178\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.8722 - accuracy: 0.7177 - val_loss: 0.8528 - val_accuracy: 0.7230\n",
      "Epoch 14/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.8500 - accuracy: 0.7246 - val_loss: 0.8318 - val_accuracy: 0.7294\n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.8300 - accuracy: 0.7300 - val_loss: 0.8128 - val_accuracy: 0.7348\n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.8117 - accuracy: 0.7349 - val_loss: 0.7949 - val_accuracy: 0.7414\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.7949 - accuracy: 0.7402 - val_loss: 0.7797 - val_accuracy: 0.7460\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.7796 - accuracy: 0.7458 - val_loss: 0.7658 - val_accuracy: 0.7480\n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.7658 - accuracy: 0.7492 - val_loss: 0.7524 - val_accuracy: 0.7538\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.7532 - accuracy: 0.7530 - val_loss: 0.7399 - val_accuracy: 0.7592\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.7414 - accuracy: 0.7580 - val_loss: 0.7298 - val_accuracy: 0.7624\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.7307 - accuracy: 0.7610 - val_loss: 0.7188 - val_accuracy: 0.7654\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.7206 - accuracy: 0.7648 - val_loss: 0.7087 - val_accuracy: 0.7696\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.7111 - accuracy: 0.7675 - val_loss: 0.6999 - val_accuracy: 0.7724\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.7022 - accuracy: 0.7708 - val_loss: 0.6911 - val_accuracy: 0.7764\n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.6939 - accuracy: 0.7744 - val_loss: 0.6826 - val_accuracy: 0.7796\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.6859 - accuracy: 0.7763 - val_loss: 0.6752 - val_accuracy: 0.7812\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.6785 - accuracy: 0.7788 - val_loss: 0.6684 - val_accuracy: 0.7824\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.6714 - accuracy: 0.7806 - val_loss: 0.6612 - val_accuracy: 0.7858\n",
      "Epoch 30/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.6646 - accuracy: 0.7840 - val_loss: 0.6551 - val_accuracy: 0.7862\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.6583 - accuracy: 0.7844 - val_loss: 0.6489 - val_accuracy: 0.7890\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.6522 - accuracy: 0.7870 - val_loss: 0.6426 - val_accuracy: 0.7912\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.6462 - accuracy: 0.7890 - val_loss: 0.6370 - val_accuracy: 0.7916\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.6407 - accuracy: 0.7906 - val_loss: 0.6318 - val_accuracy: 0.7966\n",
      "Epoch 35/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.6353 - accuracy: 0.7921 - val_loss: 0.6264 - val_accuracy: 0.7966\n",
      "Epoch 36/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.6303 - accuracy: 0.7942 - val_loss: 0.6218 - val_accuracy: 0.7994\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.6255 - accuracy: 0.7956 - val_loss: 0.6172 - val_accuracy: 0.7998\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.6209 - accuracy: 0.7965 - val_loss: 0.6125 - val_accuracy: 0.8016\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.6164 - accuracy: 0.7978 - val_loss: 0.6091 - val_accuracy: 0.8026\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.6123 - accuracy: 0.7995 - val_loss: 0.6047 - val_accuracy: 0.8028\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.6082 - accuracy: 0.8004 - val_loss: 0.6006 - val_accuracy: 0.8034\n",
      "Epoch 42/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.6043 - accuracy: 0.8020 - val_loss: 0.5967 - val_accuracy: 0.8044\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.6006 - accuracy: 0.8031 - val_loss: 0.5936 - val_accuracy: 0.8058\n",
      "Epoch 44/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5971 - accuracy: 0.8040 - val_loss: 0.5895 - val_accuracy: 0.8064\n",
      "Epoch 45/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5936 - accuracy: 0.8044 - val_loss: 0.5861 - val_accuracy: 0.8082\n",
      "Epoch 46/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5903 - accuracy: 0.8061 - val_loss: 0.5833 - val_accuracy: 0.8100\n",
      "Epoch 47/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.5871 - accuracy: 0.8071 - val_loss: 0.5802 - val_accuracy: 0.80900.5902 - ac\n",
      "Epoch 48/100\n",
      "36666/36666 [==============================] - 1s 29us/sample - loss: 0.5840 - accuracy: 0.8080 - val_loss: 0.5777 - val_accuracy: 0.8114\n",
      "Epoch 49/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5810 - accuracy: 0.8089 - val_loss: 0.5743 - val_accuracy: 0.8116\n",
      "Epoch 50/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5781 - accuracy: 0.8101 - val_loss: 0.5723 - val_accuracy: 0.8118\n",
      "Epoch 51/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5753 - accuracy: 0.8105 - val_loss: 0.5687 - val_accuracy: 0.8128\n",
      "Epoch 52/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5727 - accuracy: 0.8112 - val_loss: 0.5666 - val_accuracy: 0.8140\n",
      "Epoch 53/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5699 - accuracy: 0.8118 - val_loss: 0.5634 - val_accuracy: 0.8144\n",
      "Epoch 54/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5675 - accuracy: 0.8125 - val_loss: 0.5612 - val_accuracy: 0.8146\n",
      "Epoch 55/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.5650 - accuracy: 0.8130 - val_loss: 0.5590 - val_accuracy: 0.8146\n",
      "Epoch 56/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5626 - accuracy: 0.8144 - val_loss: 0.5565 - val_accuracy: 0.8164\n",
      "Epoch 57/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5603 - accuracy: 0.8145 - val_loss: 0.5537 - val_accuracy: 0.8172\n",
      "Epoch 58/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.5579 - accuracy: 0.8155 - val_loss: 0.5517 - val_accuracy: 0.8190s - loss: 0.5626 - accuracy - ETA: 0s - loss: 0.558\n",
      "Epoch 59/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.5558 - accuracy: 0.8155 - val_loss: 0.5497 - val_accuracy: 0.8184\n",
      "Epoch 60/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5537 - accuracy: 0.8163 - val_loss: 0.5478 - val_accuracy: 0.8194\n",
      "Epoch 61/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5516 - accuracy: 0.8164 - val_loss: 0.5457 - val_accuracy: 0.8186\n",
      "Epoch 62/100\n",
      "36666/36666 [==============================] - 1s 30us/sample - loss: 0.5495 - accuracy: 0.8173 - val_loss: 0.5436 - val_accuracy: 0.8206\n",
      "Epoch 63/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5475 - accuracy: 0.8178 - val_loss: 0.5417 - val_accuracy: 0.8208\n",
      "Epoch 64/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.5456 - accuracy: 0.8185 - val_loss: 0.5400 - val_accuracy: 0.8224\n",
      "Epoch 65/100\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.5436 - accuracy: 0.8187 - val_loss: 0.5374 - val_accuracy: 0.8236\n",
      "Epoch 66/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5419 - accuracy: 0.8184 - val_loss: 0.5357 - val_accuracy: 0.8250\n",
      "Epoch 67/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5400 - accuracy: 0.8197 - val_loss: 0.5355 - val_accuracy: 0.8224\n",
      "Epoch 68/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5383 - accuracy: 0.8203 - val_loss: 0.5326 - val_accuracy: 0.8242\n",
      "Epoch 69/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5366 - accuracy: 0.8209 - val_loss: 0.5314 - val_accuracy: 0.8244\n",
      "Epoch 70/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5349 - accuracy: 0.8212 - val_loss: 0.5293 - val_accuracy: 0.8252\n",
      "Epoch 71/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5333 - accuracy: 0.8218 - val_loss: 0.5274 - val_accuracy: 0.8268\n",
      "Epoch 72/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5315 - accuracy: 0.8213 - val_loss: 0.5262 - val_accuracy: 0.8268\n",
      "Epoch 73/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5300 - accuracy: 0.8219 - val_loss: 0.5247 - val_accuracy: 0.8264\n",
      "Epoch 74/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5286 - accuracy: 0.8229 - val_loss: 0.5232 - val_accuracy: 0.8272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5270 - accuracy: 0.8228 - val_loss: 0.5228 - val_accuracy: 0.8262\n",
      "Epoch 76/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5254 - accuracy: 0.8235 - val_loss: 0.5204 - val_accuracy: 0.8282\n",
      "Epoch 77/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5241 - accuracy: 0.8243 - val_loss: 0.5192 - val_accuracy: 0.8288\n",
      "Epoch 78/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5227 - accuracy: 0.8245 - val_loss: 0.5179 - val_accuracy: 0.8290\n",
      "Epoch 79/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5213 - accuracy: 0.8254 - val_loss: 0.5165 - val_accuracy: 0.8290\n",
      "Epoch 80/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5199 - accuracy: 0.8244 - val_loss: 0.5152 - val_accuracy: 0.8300\n",
      "Epoch 81/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5186 - accuracy: 0.8256 - val_loss: 0.5135 - val_accuracy: 0.8298\n",
      "Epoch 82/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5173 - accuracy: 0.8256 - val_loss: 0.5126 - val_accuracy: 0.8292\n",
      "Epoch 83/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5159 - accuracy: 0.8262 - val_loss: 0.5118 - val_accuracy: 0.8304\n",
      "Epoch 84/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5147 - accuracy: 0.8265 - val_loss: 0.5100 - val_accuracy: 0.8306\n",
      "Epoch 85/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5135 - accuracy: 0.8266 - val_loss: 0.5089 - val_accuracy: 0.8306\n",
      "Epoch 86/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5122 - accuracy: 0.8272 - val_loss: 0.5083 - val_accuracy: 0.8308\n",
      "Epoch 87/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.5110 - accuracy: 0.8277 - val_loss: 0.5073 - val_accuracy: 0.8308\n",
      "Epoch 88/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5099 - accuracy: 0.8279 - val_loss: 0.5056 - val_accuracy: 0.8328\n",
      "Epoch 89/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5087 - accuracy: 0.8282 - val_loss: 0.5045 - val_accuracy: 0.8320\n",
      "Epoch 90/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5076 - accuracy: 0.8279 - val_loss: 0.5036 - val_accuracy: 0.8330\n",
      "Epoch 91/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5064 - accuracy: 0.8287 - val_loss: 0.5024 - val_accuracy: 0.8326\n",
      "Epoch 92/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5053 - accuracy: 0.8288 - val_loss: 0.5028 - val_accuracy: 0.8314\n",
      "Epoch 93/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5043 - accuracy: 0.8289 - val_loss: 0.5004 - val_accuracy: 0.8346\n",
      "Epoch 94/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5032 - accuracy: 0.8293 - val_loss: 0.4995 - val_accuracy: 0.8348\n",
      "Epoch 95/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5021 - accuracy: 0.8300 - val_loss: 0.4987 - val_accuracy: 0.8340\n",
      "Epoch 96/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5012 - accuracy: 0.8304 - val_loss: 0.4974 - val_accuracy: 0.8362\n",
      "Epoch 97/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5001 - accuracy: 0.8302 - val_loss: 0.4968 - val_accuracy: 0.8364\n",
      "Epoch 98/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.4991 - accuracy: 0.8309 - val_loss: 0.4957 - val_accuracy: 0.8368\n",
      "Epoch 99/100\n",
      "36666/36666 [==============================] - 1s 31us/sample - loss: 0.4981 - accuracy: 0.8309 - val_loss: 0.4946 - val_accuracy: 0.8370\n",
      "Epoch 100/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4971 - accuracy: 0.8311 - val_loss: 0.4938 - val_accuracy: 0.8382\n",
      "18334/18334 [==============================] - 0s 21us/sample - loss: 0.5112 - accuracy: 0.8238\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 2.2140 - accuracy: 0.1594 - val_loss: 2.1341 - val_accuracy: 0.2356\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 2.0615 - accuracy: 0.3047 - val_loss: 1.9673 - val_accuracy: 0.3936\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.8810 - accuracy: 0.4346 - val_loss: 1.7793 - val_accuracy: 0.4662\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 1.7068 - accuracy: 0.4937 - val_loss: 1.6144 - val_accuracy: 0.5202\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 1.5465 - accuracy: 0.5285 - val_loss: 1.4524 - val_accuracy: 0.5502\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 1.3987 - accuracy: 0.5565 - val_loss: 1.3173 - val_accuracy: 0.6086\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 1.2793 - accuracy: 0.6068 - val_loss: 1.2105 - val_accuracy: 0.6462\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 1.1850 - accuracy: 0.6295 - val_loss: 1.1262 - val_accuracy: 0.6606\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.1108 - accuracy: 0.6408 - val_loss: 1.0601 - val_accuracy: 0.6712\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0525 - accuracy: 0.6495 - val_loss: 1.0078 - val_accuracy: 0.6808\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.0058 - accuracy: 0.6581 - val_loss: 0.9657 - val_accuracy: 0.6840\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.9679 - accuracy: 0.6648 - val_loss: 0.9312 - val_accuracy: 0.6902\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.9361 - accuracy: 0.6730 - val_loss: 0.9021 - val_accuracy: 0.6966\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.9090 - accuracy: 0.6796 - val_loss: 0.8770 - val_accuracy: 0.7042\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.8853 - accuracy: 0.6863 - val_loss: 0.8547 - val_accuracy: 0.7092\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.8645 - accuracy: 0.6935 - val_loss: 0.8353 - val_accuracy: 0.7170\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.8458 - accuracy: 0.6989 - val_loss: 0.8179 - val_accuracy: 0.7236\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.8289 - accuracy: 0.7047 - val_loss: 0.8018 - val_accuracy: 0.7298\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.8133 - accuracy: 0.7116 - val_loss: 0.7875 - val_accuracy: 0.7342\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7991 - accuracy: 0.7165 - val_loss: 0.7738 - val_accuracy: 0.7410\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.7857 - accuracy: 0.7223 - val_loss: 0.7612 - val_accuracy: 0.7442\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7734 - accuracy: 0.7276 - val_loss: 0.7497 - val_accuracy: 0.7484\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7620 - accuracy: 0.7323 - val_loss: 0.7387 - val_accuracy: 0.7526\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.7511 - accuracy: 0.7370 - val_loss: 0.7285 - val_accuracy: 0.7548\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.7410 - accuracy: 0.7403 - val_loss: 0.7187 - val_accuracy: 0.7598\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.7313 - accuracy: 0.7452 - val_loss: 0.7101 - val_accuracy: 0.7628\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7223 - accuracy: 0.7487 - val_loss: 0.7016 - val_accuracy: 0.7642\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.7136 - accuracy: 0.7526 - val_loss: 0.6933 - val_accuracy: 0.7708\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.7055 - accuracy: 0.7553 - val_loss: 0.6855 - val_accuracy: 0.7738\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6977 - accuracy: 0.7587 - val_loss: 0.6779 - val_accuracy: 0.7772\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6902 - accuracy: 0.7621 - val_loss: 0.6713 - val_accuracy: 0.7802\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6832 - accuracy: 0.7643 - val_loss: 0.6645 - val_accuracy: 0.7822\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6764 - accuracy: 0.7661 - val_loss: 0.6579 - val_accuracy: 0.7838\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6700 - accuracy: 0.7689 - val_loss: 0.6517 - val_accuracy: 0.7882\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6638 - accuracy: 0.7717 - val_loss: 0.6460 - val_accuracy: 0.7894\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6579 - accuracy: 0.7733 - val_loss: 0.6406 - val_accuracy: 0.7904\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6524 - accuracy: 0.7752 - val_loss: 0.6352 - val_accuracy: 0.7922\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6472 - accuracy: 0.7764 - val_loss: 0.6306 - val_accuracy: 0.7946\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6422 - accuracy: 0.7787 - val_loss: 0.6255 - val_accuracy: 0.7958\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6374 - accuracy: 0.7798 - val_loss: 0.6210 - val_accuracy: 0.7966\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6329 - accuracy: 0.7815 - val_loss: 0.6173 - val_accuracy: 0.7960\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6286 - accuracy: 0.7827 - val_loss: 0.6128 - val_accuracy: 0.7990\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6244 - accuracy: 0.7846 - val_loss: 0.6086 - val_accuracy: 0.8006\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.6203 - accuracy: 0.7853 - val_loss: 0.6049 - val_accuracy: 0.8020\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6165 - accuracy: 0.7863 - val_loss: 0.6021 - val_accuracy: 0.8006\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6128 - accuracy: 0.7880 - val_loss: 0.5986 - val_accuracy: 0.8028\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6095 - accuracy: 0.7894 - val_loss: 0.5944 - val_accuracy: 0.8026\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6059 - accuracy: 0.7892 - val_loss: 0.5915 - val_accuracy: 0.8052\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6027 - accuracy: 0.7905 - val_loss: 0.5891 - val_accuracy: 0.8036\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5996 - accuracy: 0.7921 - val_loss: 0.5850 - val_accuracy: 0.8068\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5965 - accuracy: 0.7934 - val_loss: 0.5827 - val_accuracy: 0.8050\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5937 - accuracy: 0.7937 - val_loss: 0.5801 - val_accuracy: 0.8072\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5908 - accuracy: 0.7951 - val_loss: 0.5773 - val_accuracy: 0.8072\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5881 - accuracy: 0.7952 - val_loss: 0.5751 - val_accuracy: 0.8086\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5853 - accuracy: 0.7965 - val_loss: 0.5716 - val_accuracy: 0.8110\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5828 - accuracy: 0.7979 - val_loss: 0.5698 - val_accuracy: 0.8110\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5803 - accuracy: 0.7981 - val_loss: 0.5672 - val_accuracy: 0.8120\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5778 - accuracy: 0.7992 - val_loss: 0.5650 - val_accuracy: 0.8134\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5755 - accuracy: 0.7996 - val_loss: 0.5620 - val_accuracy: 0.8140\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5732 - accuracy: 0.8008 - val_loss: 0.5603 - val_accuracy: 0.8158\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5709 - accuracy: 0.8019 - val_loss: 0.5583 - val_accuracy: 0.8148\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5687 - accuracy: 0.8024 - val_loss: 0.5562 - val_accuracy: 0.8186\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5666 - accuracy: 0.8035 - val_loss: 0.5541 - val_accuracy: 0.8172\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5644 - accuracy: 0.8046 - val_loss: 0.5522 - val_accuracy: 0.8186\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5624 - accuracy: 0.8048 - val_loss: 0.5505 - val_accuracy: 0.8188\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5603 - accuracy: 0.8057 - val_loss: 0.5484 - val_accuracy: 0.8190\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5582 - accuracy: 0.8059 - val_loss: 0.5470 - val_accuracy: 0.8192\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5563 - accuracy: 0.8070 - val_loss: 0.5448 - val_accuracy: 0.8212\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5543 - accuracy: 0.8077 - val_loss: 0.5427 - val_accuracy: 0.8202\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5524 - accuracy: 0.8084 - val_loss: 0.5421 - val_accuracy: 0.8202\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5506 - accuracy: 0.8093 - val_loss: 0.5390 - val_accuracy: 0.8202\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5487 - accuracy: 0.8090 - val_loss: 0.5375 - val_accuracy: 0.8202\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5469 - accuracy: 0.8097 - val_loss: 0.5362 - val_accuracy: 0.8210\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5453 - accuracy: 0.8104 - val_loss: 0.5345 - val_accuracy: 0.8224\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5435 - accuracy: 0.8117 - val_loss: 0.5328 - val_accuracy: 0.8224\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5419 - accuracy: 0.8124 - val_loss: 0.5312 - val_accuracy: 0.8222\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5403 - accuracy: 0.8125 - val_loss: 0.5299 - val_accuracy: 0.8244\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5387 - accuracy: 0.8131 - val_loss: 0.5282 - val_accuracy: 0.8244\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5372 - accuracy: 0.8134 - val_loss: 0.5265 - val_accuracy: 0.8232\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5357 - accuracy: 0.8140 - val_loss: 0.5252 - val_accuracy: 0.8244\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5342 - accuracy: 0.8145 - val_loss: 0.5238 - val_accuracy: 0.8244\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5327 - accuracy: 0.8149 - val_loss: 0.5229 - val_accuracy: 0.8252\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5313 - accuracy: 0.8152 - val_loss: 0.5217 - val_accuracy: 0.8260\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5299 - accuracy: 0.8160 - val_loss: 0.5202 - val_accuracy: 0.8260\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5285 - accuracy: 0.8160 - val_loss: 0.5192 - val_accuracy: 0.8270\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5271 - accuracy: 0.8167 - val_loss: 0.5180 - val_accuracy: 0.8272\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5258 - accuracy: 0.8173 - val_loss: 0.5160 - val_accuracy: 0.8272\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5245 - accuracy: 0.8175 - val_loss: 0.5157 - val_accuracy: 0.8272\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5232 - accuracy: 0.8185 - val_loss: 0.5140 - val_accuracy: 0.8274\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5219 - accuracy: 0.8183 - val_loss: 0.5129 - val_accuracy: 0.8282\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5206 - accuracy: 0.8184 - val_loss: 0.5117 - val_accuracy: 0.8286\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5196 - accuracy: 0.8187 - val_loss: 0.5106 - val_accuracy: 0.8270\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5183 - accuracy: 0.8195 - val_loss: 0.5096 - val_accuracy: 0.8276\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5170 - accuracy: 0.8195 - val_loss: 0.5082 - val_accuracy: 0.8278\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5158 - accuracy: 0.8198 - val_loss: 0.5076 - val_accuracy: 0.8282\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5148 - accuracy: 0.8201 - val_loss: 0.5064 - val_accuracy: 0.8284\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5136 - accuracy: 0.8203 - val_loss: 0.5054 - val_accuracy: 0.8284\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5125 - accuracy: 0.8204 - val_loss: 0.5044 - val_accuracy: 0.8290\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5114 - accuracy: 0.8214 - val_loss: 0.5033 - val_accuracy: 0.8298\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5103 - accuracy: 0.8211 - val_loss: 0.5019 - val_accuracy: 0.8298\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 0.5124 - accuracy: 0.8293\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 2.1703 - accuracy: 0.2325 - val_loss: 2.0320 - val_accuracy: 0.3244\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.9197 - accuracy: 0.3965 - val_loss: 1.7988 - val_accuracy: 0.4710\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.7035 - accuracy: 0.5031 - val_loss: 1.6010 - val_accuracy: 0.5384\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.5288 - accuracy: 0.5480 - val_loss: 1.4377 - val_accuracy: 0.5822\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.3748 - accuracy: 0.5913 - val_loss: 1.2891 - val_accuracy: 0.6322\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.2352 - accuracy: 0.6327 - val_loss: 1.1629 - val_accuracy: 0.6598\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 1.1264 - accuracy: 0.6512 - val_loss: 1.0721 - val_accuracy: 0.6732\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 1.0487 - accuracy: 0.6621 - val_loss: 1.0064 - val_accuracy: 0.6816loss: 1.0510 - accuracy: 0.\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.9913 - accuracy: 0.6750 - val_loss: 0.9561 - val_accuracy: 0.6898\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.9471 - accuracy: 0.6861 - val_loss: 0.9171 - val_accuracy: 0.7010\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.9119 - accuracy: 0.6946 - val_loss: 0.8850 - val_accuracy: 0.7102\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.8829 - accuracy: 0.7030 - val_loss: 0.8585 - val_accuracy: 0.7142\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.8582 - accuracy: 0.7104 - val_loss: 0.8361 - val_accuracy: 0.7204\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.8371 - accuracy: 0.7175 - val_loss: 0.8157 - val_accuracy: 0.7278\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.8184 - accuracy: 0.7241 - val_loss: 0.7980 - val_accuracy: 0.7338\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.8017 - accuracy: 0.7295 - val_loss: 0.7827 - val_accuracy: 0.7416\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7868 - accuracy: 0.7350 - val_loss: 0.7682 - val_accuracy: 0.7452\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7731 - accuracy: 0.7415 - val_loss: 0.7546 - val_accuracy: 0.7504\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.7605 - accuracy: 0.7457 - val_loss: 0.7428 - val_accuracy: 0.7556\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.7488 - accuracy: 0.7499 - val_loss: 0.7318 - val_accuracy: 0.7590\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.7381 - accuracy: 0.7551 - val_loss: 0.7209 - val_accuracy: 0.7634\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.7280 - accuracy: 0.7589 - val_loss: 0.7118 - val_accuracy: 0.7626\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.7186 - accuracy: 0.7624 - val_loss: 0.7023 - val_accuracy: 0.7714\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.7097 - accuracy: 0.7658 - val_loss: 0.6941 - val_accuracy: 0.7748s - loss: 0.7106 - accuracy: 0.76\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.7013 - accuracy: 0.7675 - val_loss: 0.6858 - val_accuracy: 0.7786\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6933 - accuracy: 0.7716 - val_loss: 0.6775 - val_accuracy: 0.7812\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.6859 - accuracy: 0.7748 - val_loss: 0.6708 - val_accuracy: 0.7800\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.6788 - accuracy: 0.7771 - val_loss: 0.6651 - val_accuracy: 0.7822\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.6720 - accuracy: 0.7792 - val_loss: 0.6576 - val_accuracy: 0.7860\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6656 - accuracy: 0.7820 - val_loss: 0.6511 - val_accuracy: 0.7884\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6596 - accuracy: 0.7836 - val_loss: 0.6445 - val_accuracy: 0.7908\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6538 - accuracy: 0.7850 - val_loss: 0.6399 - val_accuracy: 0.7908\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6482 - accuracy: 0.7875 - val_loss: 0.6335 - val_accuracy: 0.7968\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6430 - accuracy: 0.7896 - val_loss: 0.6290 - val_accuracy: 0.7940\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6380 - accuracy: 0.7905 - val_loss: 0.6238 - val_accuracy: 0.7980\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6330 - accuracy: 0.7919 - val_loss: 0.6202 - val_accuracy: 0.7980\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6284 - accuracy: 0.7939 - val_loss: 0.6144 - val_accuracy: 0.8004\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6241 - accuracy: 0.7944 - val_loss: 0.6102 - val_accuracy: 0.8036\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6197 - accuracy: 0.7963 - val_loss: 0.6061 - val_accuracy: 0.8034\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6157 - accuracy: 0.7968 - val_loss: 0.6022 - val_accuracy: 0.8046\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6118 - accuracy: 0.7988 - val_loss: 0.5984 - val_accuracy: 0.8056\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6079 - accuracy: 0.7994 - val_loss: 0.5947 - val_accuracy: 0.8064\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6043 - accuracy: 0.8008 - val_loss: 0.5916 - val_accuracy: 0.8056\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6008 - accuracy: 0.8017 - val_loss: 0.5879 - val_accuracy: 0.8092\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5974 - accuracy: 0.8018 - val_loss: 0.5849 - val_accuracy: 0.8078\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5941 - accuracy: 0.8027 - val_loss: 0.5819 - val_accuracy: 0.8098\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5910 - accuracy: 0.8036 - val_loss: 0.5783 - val_accuracy: 0.8112\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5879 - accuracy: 0.8049 - val_loss: 0.5758 - val_accuracy: 0.8100\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5850 - accuracy: 0.8050 - val_loss: 0.5727 - val_accuracy: 0.8112\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5821 - accuracy: 0.8059 - val_loss: 0.5704 - val_accuracy: 0.8112\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5794 - accuracy: 0.8068 - val_loss: 0.5671 - val_accuracy: 0.8144\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.5766 - accuracy: 0.8073 - val_loss: 0.5655 - val_accuracy: 0.8124\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5740 - accuracy: 0.8079 - val_loss: 0.5620 - val_accuracy: 0.8146\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5714 - accuracy: 0.8089 - val_loss: 0.5599 - val_accuracy: 0.8134\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5689 - accuracy: 0.8092 - val_loss: 0.5575 - val_accuracy: 0.8148\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5666 - accuracy: 0.8104 - val_loss: 0.5547 - val_accuracy: 0.8160\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5642 - accuracy: 0.8113 - val_loss: 0.5524 - val_accuracy: 0.8178\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5620 - accuracy: 0.8117 - val_loss: 0.5511 - val_accuracy: 0.8168\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5596 - accuracy: 0.8117 - val_loss: 0.5486 - val_accuracy: 0.8166\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5576 - accuracy: 0.8129 - val_loss: 0.5463 - val_accuracy: 0.8172\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5555 - accuracy: 0.8135 - val_loss: 0.5441 - val_accuracy: 0.8186\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5536 - accuracy: 0.8132 - val_loss: 0.5423 - val_accuracy: 0.8190\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5516 - accuracy: 0.8136 - val_loss: 0.5406 - val_accuracy: 0.8188\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5496 - accuracy: 0.8147 - val_loss: 0.5395 - val_accuracy: 0.8182\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5477 - accuracy: 0.8147 - val_loss: 0.5382 - val_accuracy: 0.8204\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5460 - accuracy: 0.8155 - val_loss: 0.5356 - val_accuracy: 0.8224\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5442 - accuracy: 0.8163 - val_loss: 0.5329 - val_accuracy: 0.8240\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5424 - accuracy: 0.8169 - val_loss: 0.5330 - val_accuracy: 0.8220\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5408 - accuracy: 0.8171 - val_loss: 0.5302 - val_accuracy: 0.8244\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5392 - accuracy: 0.8177 - val_loss: 0.5288 - val_accuracy: 0.8220\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5375 - accuracy: 0.8186 - val_loss: 0.5268 - val_accuracy: 0.8256\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5359 - accuracy: 0.8186 - val_loss: 0.5256 - val_accuracy: 0.8262\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.5345 - accuracy: 0.8193 - val_loss: 0.5245 - val_accuracy: 0.8264\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5330 - accuracy: 0.8199 - val_loss: 0.5227 - val_accuracy: 0.8272\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5315 - accuracy: 0.8201 - val_loss: 0.5217 - val_accuracy: 0.8270\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5300 - accuracy: 0.8210 - val_loss: 0.5202 - val_accuracy: 0.8266\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5287 - accuracy: 0.8214 - val_loss: 0.5184 - val_accuracy: 0.8286\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5273 - accuracy: 0.8217 - val_loss: 0.5173 - val_accuracy: 0.8260\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5259 - accuracy: 0.8227 - val_loss: 0.5174 - val_accuracy: 0.8258\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5246 - accuracy: 0.8228 - val_loss: 0.5157 - val_accuracy: 0.8254\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5233 - accuracy: 0.8229 - val_loss: 0.5141 - val_accuracy: 0.8276\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5221 - accuracy: 0.8228 - val_loss: 0.5131 - val_accuracy: 0.8290\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5208 - accuracy: 0.8239 - val_loss: 0.5113 - val_accuracy: 0.8300\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5196 - accuracy: 0.8247 - val_loss: 0.5101 - val_accuracy: 0.8312\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5185 - accuracy: 0.8246 - val_loss: 0.5087 - val_accuracy: 0.8314\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5172 - accuracy: 0.8251 - val_loss: 0.5098 - val_accuracy: 0.8306\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5161 - accuracy: 0.8255 - val_loss: 0.5070 - val_accuracy: 0.8330\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5150 - accuracy: 0.8262 - val_loss: 0.5071 - val_accuracy: 0.8288\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5139 - accuracy: 0.8260 - val_loss: 0.5050 - val_accuracy: 0.8316\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5128 - accuracy: 0.8258 - val_loss: 0.5041 - val_accuracy: 0.8322\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5117 - accuracy: 0.8264 - val_loss: 0.5029 - val_accuracy: 0.8326\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5106 - accuracy: 0.8268 - val_loss: 0.5022 - val_accuracy: 0.8324\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5096 - accuracy: 0.8268 - val_loss: 0.5010 - val_accuracy: 0.8342\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5088 - accuracy: 0.8271 - val_loss: 0.4999 - val_accuracy: 0.8338\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5077 - accuracy: 0.8277 - val_loss: 0.4996 - val_accuracy: 0.8338\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5067 - accuracy: 0.8277 - val_loss: 0.4993 - val_accuracy: 0.8340\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5057 - accuracy: 0.8282 - val_loss: 0.4983 - val_accuracy: 0.8344\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5048 - accuracy: 0.8285 - val_loss: 0.4970 - val_accuracy: 0.8352\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5039 - accuracy: 0.8284 - val_loss: 0.4955 - val_accuracy: 0.8368\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5029 - accuracy: 0.8293 - val_loss: 0.4950 - val_accuracy: 0.8356\n",
      "18333/18333 [==============================] - 0s 27us/sample - loss: 0.5114 - accuracy: 0.8266\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 2s 59us/sample - loss: 2.0642 - accuracy: 0.3481 - val_loss: 1.7694 - val_accuracy: 0.5120\n",
      "Epoch 2/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 1.4460 - accuracy: 0.6164 - val_loss: 1.1596 - val_accuracy: 0.6510\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 1.0184 - accuracy: 0.6691 - val_loss: 0.9053 - val_accuracy: 0.6942\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.8546 - accuracy: 0.7063 - val_loss: 0.7976 - val_accuracy: 0.7214\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.7745 - accuracy: 0.7317 - val_loss: 0.7334 - val_accuracy: 0.7466\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.7226 - accuracy: 0.7510 - val_loss: 0.6912 - val_accuracy: 0.7650\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.6837 - accuracy: 0.7642 - val_loss: 0.6558 - val_accuracy: 0.7784\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.6533 - accuracy: 0.7752 - val_loss: 0.6283 - val_accuracy: 0.7888\n",
      "Epoch 9/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.6282 - accuracy: 0.7851 - val_loss: 0.6097 - val_accuracy: 0.7916\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.6069 - accuracy: 0.7917 - val_loss: 0.5886 - val_accuracy: 0.7984\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.5891 - accuracy: 0.7987 - val_loss: 0.5783 - val_accuracy: 0.8066\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.5740 - accuracy: 0.8033 - val_loss: 0.5614 - val_accuracy: 0.8098\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.5603 - accuracy: 0.8084 - val_loss: 0.5498 - val_accuracy: 0.8154\n",
      "Epoch 14/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.5488 - accuracy: 0.8116 - val_loss: 0.5378 - val_accuracy: 0.8200\n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.5385 - accuracy: 0.8150 - val_loss: 0.5246 - val_accuracy: 0.8222\n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.5290 - accuracy: 0.8185 - val_loss: 0.5179 - val_accuracy: 0.8268\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.5210 - accuracy: 0.8220 - val_loss: 0.5110 - val_accuracy: 0.8276\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.5134 - accuracy: 0.8252 - val_loss: 0.5069 - val_accuracy: 0.8264\n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.5063 - accuracy: 0.8268 - val_loss: 0.4976 - val_accuracy: 0.8346\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.5003 - accuracy: 0.8284 - val_loss: 0.4956 - val_accuracy: 0.8290\n",
      "Epoch 21/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.4943 - accuracy: 0.8300 - val_loss: 0.4893 - val_accuracy: 0.8338\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.4888 - accuracy: 0.8324 - val_loss: 0.4793 - val_accuracy: 0.8394\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.4836 - accuracy: 0.8340 - val_loss: 0.4831 - val_accuracy: 0.8342\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.4783 - accuracy: 0.8352 - val_loss: 0.4752 - val_accuracy: 0.8378\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.4742 - accuracy: 0.8372 - val_loss: 0.4695 - val_accuracy: 0.8392\n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.4702 - accuracy: 0.8382 - val_loss: 0.4701 - val_accuracy: 0.8368\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.4661 - accuracy: 0.8387 - val_loss: 0.4703 - val_accuracy: 0.8394\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.4616 - accuracy: 0.8407 - val_loss: 0.4630 - val_accuracy: 0.8424\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.4580 - accuracy: 0.8423 - val_loss: 0.4595 - val_accuracy: 0.8426\n",
      "Epoch 30/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.4553 - accuracy: 0.8418 - val_loss: 0.4526 - val_accuracy: 0.8450\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.4512 - accuracy: 0.8436 - val_loss: 0.4507 - val_accuracy: 0.8450\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.4484 - accuracy: 0.8450 - val_loss: 0.4465 - val_accuracy: 0.8468\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.4453 - accuracy: 0.8452 - val_loss: 0.4428 - val_accuracy: 0.8500\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.4426 - accuracy: 0.8458 - val_loss: 0.4433 - val_accuracy: 0.8490\n",
      "Epoch 35/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.4391 - accuracy: 0.8479 - val_loss: 0.4408 - val_accuracy: 0.8506\n",
      "Epoch 36/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.4367 - accuracy: 0.8487 - val_loss: 0.4377 - val_accuracy: 0.8510\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.4342 - accuracy: 0.8496 - val_loss: 0.4351 - val_accuracy: 0.8498\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.4316 - accuracy: 0.8501 - val_loss: 0.4336 - val_accuracy: 0.8536\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.4293 - accuracy: 0.8514 - val_loss: 0.4308 - val_accuracy: 0.8538\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.4264 - accuracy: 0.8512 - val_loss: 0.4334 - val_accuracy: 0.8530\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.4249 - accuracy: 0.8522 - val_loss: 0.4305 - val_accuracy: 0.8526\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.4224 - accuracy: 0.8525 - val_loss: 0.4352 - val_accuracy: 0.8526\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.4200 - accuracy: 0.8546 - val_loss: 0.4229 - val_accuracy: 0.8554\n",
      "Epoch 44/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.4177 - accuracy: 0.8549 - val_loss: 0.4238 - val_accuracy: 0.8546\n",
      "Epoch 45/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.4161 - accuracy: 0.8548 - val_loss: 0.4246 - val_accuracy: 0.8558\n",
      "Epoch 46/100\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 0.4141 - accuracy: 0.8553 - val_loss: 0.4235 - val_accuracy: 0.8558\n",
      "Epoch 47/100\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 0.4121 - accuracy: 0.8558 - val_loss: 0.4149 - val_accuracy: 0.8572\n",
      "Epoch 48/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.4104 - accuracy: 0.8565 - val_loss: 0.4209 - val_accuracy: 0.8576\n",
      "Epoch 49/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.4086 - accuracy: 0.8578 - val_loss: 0.4142 - val_accuracy: 0.8594\n",
      "Epoch 50/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.4068 - accuracy: 0.8589 - val_loss: 0.4170 - val_accuracy: 0.8590\n",
      "Epoch 51/100\n",
      "36666/36666 [==============================] - 2s 55us/sample - loss: 0.4050 - accuracy: 0.8599 - val_loss: 0.4203 - val_accuracy: 0.8546\n",
      "Epoch 52/100\n",
      "36666/36666 [==============================] - 2s 56us/sample - loss: 0.4033 - accuracy: 0.8598 - val_loss: 0.4187 - val_accuracy: 0.8554\n",
      "Epoch 53/100\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 0.4014 - accuracy: 0.8597 - val_loss: 0.4094 - val_accuracy: 0.8600\n",
      "Epoch 54/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3998 - accuracy: 0.8611 - val_loss: 0.4069 - val_accuracy: 0.8612\n",
      "Epoch 55/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.3983 - accuracy: 0.8604 - val_loss: 0.4086 - val_accuracy: 0.8618\n",
      "Epoch 56/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3968 - accuracy: 0.8610 - val_loss: 0.4053 - val_accuracy: 0.8638\n",
      "Epoch 57/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.3948 - accuracy: 0.8628 - val_loss: 0.4061 - val_accuracy: 0.8604\n",
      "Epoch 58/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3939 - accuracy: 0.8631 - val_loss: 0.4029 - val_accuracy: 0.8622\n",
      "Epoch 59/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.3923 - accuracy: 0.8633 - val_loss: 0.4016 - val_accuracy: 0.8620\n",
      "Epoch 60/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3901 - accuracy: 0.8643 - val_loss: 0.4057 - val_accuracy: 0.8608\n",
      "Epoch 61/100\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.3889 - accuracy: 0.8648 - val_loss: 0.4038 - val_accuracy: 0.8614\n",
      "Epoch 62/100\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.3877 - accuracy: 0.8649 - val_loss: 0.4008 - val_accuracy: 0.8634\n",
      "Epoch 63/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3867 - accuracy: 0.8655 - val_loss: 0.4019 - val_accuracy: 0.8632\n",
      "Epoch 64/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.3853 - accuracy: 0.8667 - val_loss: 0.3976 - val_accuracy: 0.8638\n",
      "Epoch 65/100\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 0.3836 - accuracy: 0.8670 - val_loss: 0.3956 - val_accuracy: 0.8650\n",
      "Epoch 66/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3825 - accuracy: 0.8675 - val_loss: 0.3983 - val_accuracy: 0.8664\n",
      "Epoch 67/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3811 - accuracy: 0.8674 - val_loss: 0.3953 - val_accuracy: 0.8630\n",
      "Epoch 68/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.3798 - accuracy: 0.8678 - val_loss: 0.3985 - val_accuracy: 0.8614\n",
      "Epoch 69/100\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 0.3785 - accuracy: 0.8679 - val_loss: 0.3972 - val_accuracy: 0.8644\n",
      "Epoch 70/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.3771 - accuracy: 0.8695 - val_loss: 0.3917 - val_accuracy: 0.8678\n",
      "Epoch 71/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3759 - accuracy: 0.8690 - val_loss: 0.3924 - val_accuracy: 0.8658\n",
      "Epoch 72/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.3745 - accuracy: 0.8695 - val_loss: 0.3919 - val_accuracy: 0.8690: 0.375\n",
      "Epoch 73/100\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.3733 - accuracy: 0.8700 - val_loss: 0.4072 - val_accuracy: 0.8612\n",
      "Epoch 74/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3723 - accuracy: 0.8707 - val_loss: 0.3970 - val_accuracy: 0.8626\n",
      "Epoch 75/100\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.3709 - accuracy: 0.8714 - val_loss: 0.3982 - val_accuracy: 0.8614\n",
      "Epoch 76/100\n",
      "36666/36666 [==============================] - 2s 55us/sample - loss: 0.3697 - accuracy: 0.8710 - val_loss: 0.3870 - val_accuracy: 0.8658\n",
      "Epoch 77/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3692 - accuracy: 0.8709 - val_loss: 0.3879 - val_accuracy: 0.8650\n",
      "Epoch 78/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3677 - accuracy: 0.8718 - val_loss: 0.3882 - val_accuracy: 0.8676\n",
      "Epoch 79/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.3667 - accuracy: 0.8729 - val_loss: 0.3862 - val_accuracy: 0.8704\n",
      "Epoch 80/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3655 - accuracy: 0.8727 - val_loss: 0.3862 - val_accuracy: 0.8668\n",
      "Epoch 81/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3646 - accuracy: 0.8729 - val_loss: 0.3906 - val_accuracy: 0.8670\n",
      "Epoch 82/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3631 - accuracy: 0.8733 - val_loss: 0.3971 - val_accuracy: 0.8642\n",
      "Epoch 83/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.3622 - accuracy: 0.8735 - val_loss: 0.3839 - val_accuracy: 0.8716\n",
      "Epoch 84/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.3609 - accuracy: 0.8744 - val_loss: 0.3828 - val_accuracy: 0.8716\n",
      "Epoch 85/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3601 - accuracy: 0.8739 - val_loss: 0.3847 - val_accuracy: 0.8664\n",
      "Epoch 86/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.3592 - accuracy: 0.8752 - val_loss: 0.3838 - val_accuracy: 0.8698\n",
      "Epoch 87/100\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.3578 - accuracy: 0.8759 - val_loss: 0.3853 - val_accuracy: 0.8708\n",
      "Epoch 88/100\n",
      "36666/36666 [==============================] - 2s 57us/sample - loss: 0.3569 - accuracy: 0.8758 - val_loss: 0.3794 - val_accuracy: 0.8708\n",
      "Epoch 89/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.3564 - accuracy: 0.8756 - val_loss: 0.3785 - val_accuracy: 0.8706\n",
      "Epoch 90/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.3550 - accuracy: 0.8773 - val_loss: 0.3773 - val_accuracy: 0.8728\n",
      "Epoch 91/100\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.3541 - accuracy: 0.8761 - val_loss: 0.3758 - val_accuracy: 0.8702\n",
      "Epoch 92/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3530 - accuracy: 0.8757 - val_loss: 0.3786 - val_accuracy: 0.8738\n",
      "Epoch 93/100\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3522 - accuracy: 0.8769 - val_loss: 0.3761 - val_accuracy: 0.8718\n",
      "Epoch 94/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.3509 - accuracy: 0.8779 - val_loss: 0.3839 - val_accuracy: 0.8722\n",
      "Epoch 95/100\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.3506 - accuracy: 0.8777 - val_loss: 0.3756 - val_accuracy: 0.8712\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.3495 - accuracy: 0.8776 - val_loss: 0.3778 - val_accuracy: 0.8722\n",
      "Epoch 97/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3485 - accuracy: 0.8780 - val_loss: 0.3735 - val_accuracy: 0.8732\n",
      "Epoch 98/100\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 0.3478 - accuracy: 0.8787 - val_loss: 0.3757 - val_accuracy: 0.8722\n",
      "Epoch 99/100\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 0.3463 - accuracy: 0.8788 - val_loss: 0.3791 - val_accuracy: 0.8716\n",
      "Epoch 100/100\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3453 - accuracy: 0.8794 - val_loss: 0.3718 - val_accuracy: 0.8744\n",
      "18334/18334 [==============================] - 1s 33us/sample - loss: 0.3861 - accuracy: 0.8627\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 2.0738 - accuracy: 0.3269 - val_loss: 1.7547 - val_accuracy: 0.5312\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.4369 - accuracy: 0.5882 - val_loss: 1.1592 - val_accuracy: 0.6434\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 1.0387 - accuracy: 0.6558 - val_loss: 0.9217 - val_accuracy: 0.6818\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.8814 - accuracy: 0.6818 - val_loss: 0.8188 - val_accuracy: 0.7026\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.8035 - accuracy: 0.7073 - val_loss: 0.7604 - val_accuracy: 0.7230\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 2s 59us/sample - loss: 0.7537 - accuracy: 0.7285 - val_loss: 0.7188 - val_accuracy: 0.7488\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.7160 - accuracy: 0.7487 - val_loss: 0.6876 - val_accuracy: 0.7584\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.6850 - accuracy: 0.7633 - val_loss: 0.6578 - val_accuracy: 0.7744\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.6581 - accuracy: 0.7746 - val_loss: 0.6327 - val_accuracy: 0.7858\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.6342 - accuracy: 0.7834 - val_loss: 0.6139 - val_accuracy: 0.7928\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.6139 - accuracy: 0.7899 - val_loss: 0.5927 - val_accuracy: 0.8012\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.5957 - accuracy: 0.7952 - val_loss: 0.5835 - val_accuracy: 0.8052\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.5799 - accuracy: 0.8010 - val_loss: 0.5611 - val_accuracy: 0.8124\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.5658 - accuracy: 0.8065 - val_loss: 0.5524 - val_accuracy: 0.8126\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.5535 - accuracy: 0.8109 - val_loss: 0.5378 - val_accuracy: 0.8168\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.5423 - accuracy: 0.8121 - val_loss: 0.5301 - val_accuracy: 0.8184\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.5322 - accuracy: 0.8154 - val_loss: 0.5203 - val_accuracy: 0.8220\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.5230 - accuracy: 0.8192 - val_loss: 0.5122 - val_accuracy: 0.8268\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.5154 - accuracy: 0.8219 - val_loss: 0.5069 - val_accuracy: 0.8278\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.5082 - accuracy: 0.8243 - val_loss: 0.4981 - val_accuracy: 0.8328\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.5014 - accuracy: 0.8255 - val_loss: 0.4935 - val_accuracy: 0.8332\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4955 - accuracy: 0.8271 - val_loss: 0.4885 - val_accuracy: 0.8350\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.4900 - accuracy: 0.8278 - val_loss: 0.4854 - val_accuracy: 0.8342\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.4847 - accuracy: 0.8303 - val_loss: 0.4782 - val_accuracy: 0.8368\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 2s 60us/sample - loss: 0.4799 - accuracy: 0.8318 - val_loss: 0.4753 - val_accuracy: 0.8410\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4753 - accuracy: 0.8340 - val_loss: 0.4725 - val_accuracy: 0.8412\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4706 - accuracy: 0.8345 - val_loss: 0.4653 - val_accuracy: 0.8410\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4670 - accuracy: 0.8354 - val_loss: 0.4605 - val_accuracy: 0.8438\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4632 - accuracy: 0.8361 - val_loss: 0.4595 - val_accuracy: 0.8464\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.4590 - accuracy: 0.8370 - val_loss: 0.4569 - val_accuracy: 0.8462\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4550 - accuracy: 0.8394 - val_loss: 0.4559 - val_accuracy: 0.8456\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4521 - accuracy: 0.8403 - val_loss: 0.4539 - val_accuracy: 0.8470\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4495 - accuracy: 0.8416 - val_loss: 0.4468 - val_accuracy: 0.8496\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.4461 - accuracy: 0.8431 - val_loss: 0.4515 - val_accuracy: 0.8476\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 2s 62us/sample - loss: 0.4426 - accuracy: 0.8437 - val_loss: 0.4449 - val_accuracy: 0.8522\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.4399 - accuracy: 0.8447 - val_loss: 0.4379 - val_accuracy: 0.8514\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4375 - accuracy: 0.8466 - val_loss: 0.4408 - val_accuracy: 0.8498\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4348 - accuracy: 0.8468 - val_loss: 0.4441 - val_accuracy: 0.8462\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4326 - accuracy: 0.8477 - val_loss: 0.4327 - val_accuracy: 0.8526\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4300 - accuracy: 0.8494 - val_loss: 0.4306 - val_accuracy: 0.8528\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.4268 - accuracy: 0.8492 - val_loss: 0.4269 - val_accuracy: 0.8538\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.4250 - accuracy: 0.8499 - val_loss: 0.4268 - val_accuracy: 0.8556\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4223 - accuracy: 0.8508 - val_loss: 0.4332 - val_accuracy: 0.8502\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.4201 - accuracy: 0.8525 - val_loss: 0.4249 - val_accuracy: 0.8562\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4180 - accuracy: 0.8531 - val_loss: 0.4207 - val_accuracy: 0.8564\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4155 - accuracy: 0.8539 - val_loss: 0.4182 - val_accuracy: 0.8564\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4140 - accuracy: 0.8550 - val_loss: 0.4218 - val_accuracy: 0.8540\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4116 - accuracy: 0.8556 - val_loss: 0.4135 - val_accuracy: 0.8584\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4096 - accuracy: 0.8558 - val_loss: 0.4140 - val_accuracy: 0.8596\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4079 - accuracy: 0.8577 - val_loss: 0.4198 - val_accuracy: 0.8534\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4056 - accuracy: 0.8575 - val_loss: 0.4132 - val_accuracy: 0.8602\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4039 - accuracy: 0.8582 - val_loss: 0.4119 - val_accuracy: 0.8570\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4017 - accuracy: 0.8588 - val_loss: 0.4077 - val_accuracy: 0.8614\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4007 - accuracy: 0.8580 - val_loss: 0.4071 - val_accuracy: 0.8608\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.3992 - accuracy: 0.8590 - val_loss: 0.4062 - val_accuracy: 0.8608\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3971 - accuracy: 0.8601 - val_loss: 0.4119 - val_accuracy: 0.8590\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3955 - accuracy: 0.8602 - val_loss: 0.4110 - val_accuracy: 0.8620\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3943 - accuracy: 0.8613 - val_loss: 0.4064 - val_accuracy: 0.8592\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3925 - accuracy: 0.8616 - val_loss: 0.4031 - val_accuracy: 0.8598\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3907 - accuracy: 0.8625 - val_loss: 0.4026 - val_accuracy: 0.8614\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3892 - accuracy: 0.8625 - val_loss: 0.4033 - val_accuracy: 0.8632\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3880 - accuracy: 0.8625 - val_loss: 0.3983 - val_accuracy: 0.8638\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3862 - accuracy: 0.8645 - val_loss: 0.3947 - val_accuracy: 0.8648\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3850 - accuracy: 0.8641 - val_loss: 0.3952 - val_accuracy: 0.8644\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3834 - accuracy: 0.8648 - val_loss: 0.3918 - val_accuracy: 0.8670\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3825 - accuracy: 0.8660 - val_loss: 0.3962 - val_accuracy: 0.8630\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3808 - accuracy: 0.8651 - val_loss: 0.3921 - val_accuracy: 0.8662\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3796 - accuracy: 0.8674 - val_loss: 0.3897 - val_accuracy: 0.8658\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3780 - accuracy: 0.8676 - val_loss: 0.3900 - val_accuracy: 0.8670\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3772 - accuracy: 0.8673 - val_loss: 0.3902 - val_accuracy: 0.8684\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3758 - accuracy: 0.8680 - val_loss: 0.3874 - val_accuracy: 0.8656\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3748 - accuracy: 0.8688 - val_loss: 0.3882 - val_accuracy: 0.8660\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3733 - accuracy: 0.8693 - val_loss: 0.3871 - val_accuracy: 0.8650\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3719 - accuracy: 0.8696 - val_loss: 0.3928 - val_accuracy: 0.8652\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3708 - accuracy: 0.8699 - val_loss: 0.3889 - val_accuracy: 0.8666\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3694 - accuracy: 0.8700 - val_loss: 0.3853 - val_accuracy: 0.8658\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3684 - accuracy: 0.8706 - val_loss: 0.3933 - val_accuracy: 0.8630\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3671 - accuracy: 0.8725 - val_loss: 0.3868 - val_accuracy: 0.8698\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3665 - accuracy: 0.8725 - val_loss: 0.3841 - val_accuracy: 0.8652\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3649 - accuracy: 0.8714 - val_loss: 0.3804 - val_accuracy: 0.8672\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3640 - accuracy: 0.8726 - val_loss: 0.3828 - val_accuracy: 0.8656\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3632 - accuracy: 0.8723 - val_loss: 0.3857 - val_accuracy: 0.8660\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3618 - accuracy: 0.8742 - val_loss: 0.3836 - val_accuracy: 0.8690\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3612 - accuracy: 0.8743 - val_loss: 0.3864 - val_accuracy: 0.8632\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 2s 59us/sample - loss: 0.3593 - accuracy: 0.8736 - val_loss: 0.3787 - val_accuracy: 0.8688\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 0.3589 - accuracy: 0.8737 - val_loss: 0.3785 - val_accuracy: 0.8702\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.3577 - accuracy: 0.8746 - val_loss: 0.3778 - val_accuracy: 0.8684\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3564 - accuracy: 0.8744 - val_loss: 0.3794 - val_accuracy: 0.8674\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3556 - accuracy: 0.8757 - val_loss: 0.3751 - val_accuracy: 0.8700\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.3544 - accuracy: 0.8760 - val_loss: 0.3743 - val_accuracy: 0.8698\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3534 - accuracy: 0.8754 - val_loss: 0.3756 - val_accuracy: 0.8686\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3524 - accuracy: 0.8765 - val_loss: 0.3787 - val_accuracy: 0.8714\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3521 - accuracy: 0.8763 - val_loss: 0.3797 - val_accuracy: 0.8694\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3508 - accuracy: 0.8772 - val_loss: 0.3732 - val_accuracy: 0.8704\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3491 - accuracy: 0.8780 - val_loss: 0.3724 - val_accuracy: 0.8712\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3490 - accuracy: 0.8780 - val_loss: 0.3788 - val_accuracy: 0.8682\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3481 - accuracy: 0.8782 - val_loss: 0.3843 - val_accuracy: 0.8644\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.3472 - accuracy: 0.8787 - val_loss: 0.3691 - val_accuracy: 0.8700\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3462 - accuracy: 0.8791 - val_loss: 0.3799 - val_accuracy: 0.8700\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3447 - accuracy: 0.8786 - val_loss: 0.3751 - val_accuracy: 0.8672\n",
      "18333/18333 [==============================] - 1s 29us/sample - loss: 0.3817 - accuracy: 0.8689\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 2.0235 - accuracy: 0.3224 - val_loss: 1.7289 - val_accuracy: 0.5682\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.4245 - accuracy: 0.6297 - val_loss: 1.1585 - val_accuracy: 0.6738\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 1.0283 - accuracy: 0.6768 - val_loss: 0.9144 - val_accuracy: 0.6898\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.8638 - accuracy: 0.7068 - val_loss: 0.8056 - val_accuracy: 0.7254\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.7819 - accuracy: 0.7298 - val_loss: 0.7440 - val_accuracy: 0.7446\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.7290 - accuracy: 0.7483 - val_loss: 0.6991 - val_accuracy: 0.7576\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6899 - accuracy: 0.7622 - val_loss: 0.6652 - val_accuracy: 0.7714\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6584 - accuracy: 0.7726 - val_loss: 0.6375 - val_accuracy: 0.7772\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6317 - accuracy: 0.7835 - val_loss: 0.6089 - val_accuracy: 0.7882\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.6087 - accuracy: 0.7907 - val_loss: 0.5935 - val_accuracy: 0.7974\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.5892 - accuracy: 0.7973 - val_loss: 0.5714 - val_accuracy: 0.8042\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.5720 - accuracy: 0.8027 - val_loss: 0.5575 - val_accuracy: 0.8108\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.5573 - accuracy: 0.8079 - val_loss: 0.5417 - val_accuracy: 0.8152\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.5438 - accuracy: 0.8121 - val_loss: 0.5286 - val_accuracy: 0.8184\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.5325 - accuracy: 0.8160 - val_loss: 0.5176 - val_accuracy: 0.8238\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.5216 - accuracy: 0.8198 - val_loss: 0.5111 - val_accuracy: 0.8254\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.5121 - accuracy: 0.8222 - val_loss: 0.4994 - val_accuracy: 0.8278\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.5038 - accuracy: 0.8259 - val_loss: 0.4947 - val_accuracy: 0.8280\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.4959 - accuracy: 0.8273 - val_loss: 0.4875 - val_accuracy: 0.8334\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4894 - accuracy: 0.8298 - val_loss: 0.4850 - val_accuracy: 0.8344\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4824 - accuracy: 0.8324 - val_loss: 0.4745 - val_accuracy: 0.8386\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4768 - accuracy: 0.8337 - val_loss: 0.4707 - val_accuracy: 0.8406\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.4716 - accuracy: 0.8367 - val_loss: 0.4678 - val_accuracy: 0.8402\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4666 - accuracy: 0.8372 - val_loss: 0.4645 - val_accuracy: 0.8370\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4622 - accuracy: 0.8383 - val_loss: 0.4552 - val_accuracy: 0.8418\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4580 - accuracy: 0.8388 - val_loss: 0.4599 - val_accuracy: 0.8424\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4542 - accuracy: 0.8402 - val_loss: 0.4522 - val_accuracy: 0.8448\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4504 - accuracy: 0.8431 - val_loss: 0.4529 - val_accuracy: 0.8432\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4467 - accuracy: 0.8440 - val_loss: 0.4523 - val_accuracy: 0.8428\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4435 - accuracy: 0.8439 - val_loss: 0.4426 - val_accuracy: 0.8464\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.4398 - accuracy: 0.8456 - val_loss: 0.4413 - val_accuracy: 0.8458\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.4370 - accuracy: 0.8470 - val_loss: 0.4379 - val_accuracy: 0.8478\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.4342 - accuracy: 0.8473 - val_loss: 0.4481 - val_accuracy: 0.8438\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.4319 - accuracy: 0.8475 - val_loss: 0.4307 - val_accuracy: 0.8502\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.4286 - accuracy: 0.8500 - val_loss: 0.4354 - val_accuracy: 0.8510\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.4257 - accuracy: 0.8510 - val_loss: 0.4284 - val_accuracy: 0.8506\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.4238 - accuracy: 0.8513 - val_loss: 0.4250 - val_accuracy: 0.8556\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4215 - accuracy: 0.8521 - val_loss: 0.4292 - val_accuracy: 0.8504\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.4191 - accuracy: 0.8529 - val_loss: 0.4250 - val_accuracy: 0.8524\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.4163 - accuracy: 0.8540 - val_loss: 0.4264 - val_accuracy: 0.8516\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.4139 - accuracy: 0.8536 - val_loss: 0.4225 - val_accuracy: 0.8572\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.4122 - accuracy: 0.8550 - val_loss: 0.4144 - val_accuracy: 0.8560\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4102 - accuracy: 0.8565 - val_loss: 0.4166 - val_accuracy: 0.8546\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.4079 - accuracy: 0.8561 - val_loss: 0.4153 - val_accuracy: 0.8576\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.4060 - accuracy: 0.8573 - val_loss: 0.4103 - val_accuracy: 0.8574\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 0.4039 - accuracy: 0.8582 - val_loss: 0.4079 - val_accuracy: 0.8582\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.4022 - accuracy: 0.8581 - val_loss: 0.4086 - val_accuracy: 0.8592\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.4006 - accuracy: 0.8591 - val_loss: 0.4118 - val_accuracy: 0.8586s - loss: 0.4034 - accu\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.3986 - accuracy: 0.8600 - val_loss: 0.4060 - val_accuracy: 0.8602\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.3965 - accuracy: 0.8598 - val_loss: 0.4091 - val_accuracy: 0.8626\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.3953 - accuracy: 0.8610 - val_loss: 0.4121 - val_accuracy: 0.8596\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.3926 - accuracy: 0.8622 - val_loss: 0.4050 - val_accuracy: 0.8596\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.3914 - accuracy: 0.8622 - val_loss: 0.4001 - val_accuracy: 0.8624\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.3899 - accuracy: 0.8623 - val_loss: 0.4037 - val_accuracy: 0.8614\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.3881 - accuracy: 0.8630 - val_loss: 0.4016 - val_accuracy: 0.8604\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 2s 60us/sample - loss: 0.3867 - accuracy: 0.8635 - val_loss: 0.3968 - val_accuracy: 0.8640\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 2s 60us/sample - loss: 0.3852 - accuracy: 0.8636 - val_loss: 0.4023 - val_accuracy: 0.8630\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 0.3838 - accuracy: 0.8645 - val_loss: 0.4075 - val_accuracy: 0.8588\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.3825 - accuracy: 0.8659 - val_loss: 0.3966 - val_accuracy: 0.8644\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.3812 - accuracy: 0.8650 - val_loss: 0.3988 - val_accuracy: 0.8648\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.3796 - accuracy: 0.8666 - val_loss: 0.3934 - val_accuracy: 0.8640\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.3780 - accuracy: 0.8667 - val_loss: 0.3907 - val_accuracy: 0.8666\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3765 - accuracy: 0.8674 - val_loss: 0.3916 - val_accuracy: 0.8646\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3754 - accuracy: 0.8674 - val_loss: 0.3966 - val_accuracy: 0.8656\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3739 - accuracy: 0.8692 - val_loss: 0.3904 - val_accuracy: 0.8656\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.3727 - accuracy: 0.8682 - val_loss: 0.3991 - val_accuracy: 0.8618\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3720 - accuracy: 0.8687 - val_loss: 0.3891 - val_accuracy: 0.8650\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3708 - accuracy: 0.8684 - val_loss: 0.3918 - val_accuracy: 0.8652\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.3694 - accuracy: 0.8705 - val_loss: 0.3868 - val_accuracy: 0.8668\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.3678 - accuracy: 0.8699 - val_loss: 0.3871 - val_accuracy: 0.8668\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3667 - accuracy: 0.8707 - val_loss: 0.3956 - val_accuracy: 0.8638\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3657 - accuracy: 0.8707 - val_loss: 0.3902 - val_accuracy: 0.8686\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3643 - accuracy: 0.8711 - val_loss: 0.3867 - val_accuracy: 0.8672\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3630 - accuracy: 0.8734 - val_loss: 0.3883 - val_accuracy: 0.8660\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3619 - accuracy: 0.8731 - val_loss: 0.3850 - val_accuracy: 0.8652\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3609 - accuracy: 0.8731 - val_loss: 0.3840 - val_accuracy: 0.8636\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3595 - accuracy: 0.8744 - val_loss: 0.3896 - val_accuracy: 0.8642\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3590 - accuracy: 0.8738 - val_loss: 0.3795 - val_accuracy: 0.8674\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3579 - accuracy: 0.8739 - val_loss: 0.3794 - val_accuracy: 0.8666\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3564 - accuracy: 0.8754 - val_loss: 0.3854 - val_accuracy: 0.8652\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3558 - accuracy: 0.8745 - val_loss: 0.3769 - val_accuracy: 0.8682\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3549 - accuracy: 0.8745 - val_loss: 0.3804 - val_accuracy: 0.8692\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3534 - accuracy: 0.8753 - val_loss: 0.3784 - val_accuracy: 0.8684\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3520 - accuracy: 0.8768 - val_loss: 0.3778 - val_accuracy: 0.8676\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3515 - accuracy: 0.8766 - val_loss: 0.3778 - val_accuracy: 0.8680\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3506 - accuracy: 0.8768 - val_loss: 0.3784 - val_accuracy: 0.8674\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3494 - accuracy: 0.8774 - val_loss: 0.3788 - val_accuracy: 0.8684\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.3484 - accuracy: 0.8765 - val_loss: 0.3752 - val_accuracy: 0.8698\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.3472 - accuracy: 0.8793 - val_loss: 0.3759 - val_accuracy: 0.8700\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.3459 - accuracy: 0.8782 - val_loss: 0.3724 - val_accuracy: 0.8696\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 2s 60us/sample - loss: 0.3452 - accuracy: 0.8782 - val_loss: 0.3734 - val_accuracy: 0.8678\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 2s 59us/sample - loss: 0.3446 - accuracy: 0.8784 - val_loss: 0.3800 - val_accuracy: 0.8692\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 0.3434 - accuracy: 0.8794 - val_loss: 0.3725 - val_accuracy: 0.8688\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.3425 - accuracy: 0.8794 - val_loss: 0.3773 - val_accuracy: 0.8712\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.3410 - accuracy: 0.8807 - val_loss: 0.3768 - val_accuracy: 0.8710\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 0.3407 - accuracy: 0.8805 - val_loss: 0.3707 - val_accuracy: 0.8712\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.3395 - accuracy: 0.8811 - val_loss: 0.3773 - val_accuracy: 0.8654\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.3385 - accuracy: 0.8810 - val_loss: 0.3703 - val_accuracy: 0.8730\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.3377 - accuracy: 0.8810 - val_loss: 0.3702 - val_accuracy: 0.8684\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.3370 - accuracy: 0.8814 - val_loss: 0.3780 - val_accuracy: 0.8650\n",
      "18333/18333 [==============================] - 1s 34us/sample - loss: 0.3868 - accuracy: 0.8654\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 1.7151 - accuracy: 0.4942 - val_loss: 1.3135 - val_accuracy: 0.6552\n",
      "Epoch 2/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.1758 - accuracy: 0.6593 - val_loss: 1.0557 - val_accuracy: 0.6854\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.0023 - accuracy: 0.6852 - val_loss: 0.9397 - val_accuracy: 0.7030\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.9119 - accuracy: 0.7057 - val_loss: 0.8691 - val_accuracy: 0.7224\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.8536 - accuracy: 0.7247 - val_loss: 0.8204 - val_accuracy: 0.7442\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.8115 - accuracy: 0.7401 - val_loss: 0.7849 - val_accuracy: 0.7594\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.7793 - accuracy: 0.7521 - val_loss: 0.7571 - val_accuracy: 0.7670\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.7535 - accuracy: 0.7626 - val_loss: 0.7336 - val_accuracy: 0.7756\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.7321 - accuracy: 0.7698 - val_loss: 0.7146 - val_accuracy: 0.7804\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.7141 - accuracy: 0.7758 - val_loss: 0.6985 - val_accuracy: 0.7846\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.6983 - accuracy: 0.7809 - val_loss: 0.6844 - val_accuracy: 0.7900\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6849 - accuracy: 0.7851 - val_loss: 0.6719 - val_accuracy: 0.7922\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6729 - accuracy: 0.7880 - val_loss: 0.6611 - val_accuracy: 0.7948\n",
      "Epoch 14/100\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.6621 - accuracy: 0.7913 - val_loss: 0.6509 - val_accuracy: 0.7994\n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.6525 - accuracy: 0.7943 - val_loss: 0.6424 - val_accuracy: 0.7984\n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.6437 - accuracy: 0.7975 - val_loss: 0.6337 - val_accuracy: 0.8022\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6358 - accuracy: 0.7995 - val_loss: 0.6265 - val_accuracy: 0.8026\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.6284 - accuracy: 0.8014 - val_loss: 0.6196 - val_accuracy: 0.8034\n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6217 - accuracy: 0.8035 - val_loss: 0.6140 - val_accuracy: 0.8088\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6154 - accuracy: 0.8050 - val_loss: 0.6073 - val_accuracy: 0.8066\n",
      "Epoch 21/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.6097 - accuracy: 0.8069 - val_loss: 0.6020 - val_accuracy: 0.8110\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6043 - accuracy: 0.8073 - val_loss: 0.5973 - val_accuracy: 0.8118\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.5992 - accuracy: 0.8091 - val_loss: 0.5920 - val_accuracy: 0.8136\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.5944 - accuracy: 0.8107 - val_loss: 0.5879 - val_accuracy: 0.8136\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.5899 - accuracy: 0.8117 - val_loss: 0.5838 - val_accuracy: 0.8146\n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5857 - accuracy: 0.8118 - val_loss: 0.5791 - val_accuracy: 0.8152\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5816 - accuracy: 0.8131 - val_loss: 0.5762 - val_accuracy: 0.8170\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5779 - accuracy: 0.8149 - val_loss: 0.5723 - val_accuracy: 0.8190\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5743 - accuracy: 0.8150 - val_loss: 0.5683 - val_accuracy: 0.8198\n",
      "Epoch 30/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5709 - accuracy: 0.8164 - val_loss: 0.5662 - val_accuracy: 0.8208\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5675 - accuracy: 0.8170 - val_loss: 0.5622 - val_accuracy: 0.8218\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5645 - accuracy: 0.8178 - val_loss: 0.5599 - val_accuracy: 0.8236\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5615 - accuracy: 0.8187 - val_loss: 0.5565 - val_accuracy: 0.8244\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5585 - accuracy: 0.8198 - val_loss: 0.5547 - val_accuracy: 0.8236\n",
      "Epoch 35/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5559 - accuracy: 0.8205 - val_loss: 0.5515 - val_accuracy: 0.8248\n",
      "Epoch 36/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5531 - accuracy: 0.8212 - val_loss: 0.5490 - val_accuracy: 0.8260\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5508 - accuracy: 0.8210 - val_loss: 0.5472 - val_accuracy: 0.8262\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5482 - accuracy: 0.8219 - val_loss: 0.5440 - val_accuracy: 0.8280\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5459 - accuracy: 0.8225 - val_loss: 0.5419 - val_accuracy: 0.8294\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5437 - accuracy: 0.8233 - val_loss: 0.5400 - val_accuracy: 0.8284\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5415 - accuracy: 0.8241 - val_loss: 0.5382 - val_accuracy: 0.8298\n",
      "Epoch 42/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5393 - accuracy: 0.8247 - val_loss: 0.5362 - val_accuracy: 0.8290\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5374 - accuracy: 0.8253 - val_loss: 0.5339 - val_accuracy: 0.8312\n",
      "Epoch 44/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5354 - accuracy: 0.8261 - val_loss: 0.5322 - val_accuracy: 0.8324\n",
      "Epoch 45/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5334 - accuracy: 0.8262 - val_loss: 0.5308 - val_accuracy: 0.8326\n",
      "Epoch 46/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5317 - accuracy: 0.8270 - val_loss: 0.5286 - val_accuracy: 0.8324\n",
      "Epoch 47/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5299 - accuracy: 0.8276 - val_loss: 0.5272 - val_accuracy: 0.8332\n",
      "Epoch 48/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5281 - accuracy: 0.8279 - val_loss: 0.5254 - val_accuracy: 0.8326\n",
      "Epoch 49/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.5264 - accuracy: 0.8284 - val_loss: 0.5248 - val_accuracy: 0.8344\n",
      "Epoch 50/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5248 - accuracy: 0.8292 - val_loss: 0.5225 - val_accuracy: 0.8336\n",
      "Epoch 51/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5231 - accuracy: 0.8290 - val_loss: 0.5212 - val_accuracy: 0.8330\n",
      "Epoch 52/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5217 - accuracy: 0.8298 - val_loss: 0.5196 - val_accuracy: 0.8346\n",
      "Epoch 53/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5201 - accuracy: 0.8298 - val_loss: 0.5185 - val_accuracy: 0.8356ss: 0.5209 - accuracy: 0. - ETA: 0s - loss: 0.5224 - accu\n",
      "Epoch 54/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.5186 - accuracy: 0.8301 - val_loss: 0.5169 - val_accuracy: 0.8348\n",
      "Epoch 55/100\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.5172 - accuracy: 0.8307 - val_loss: 0.5162 - val_accuracy: 0.8362\n",
      "Epoch 56/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5159 - accuracy: 0.8307 - val_loss: 0.5143 - val_accuracy: 0.8360\n",
      "Epoch 57/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5144 - accuracy: 0.8313 - val_loss: 0.5134 - val_accuracy: 0.8358\n",
      "Epoch 58/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5131 - accuracy: 0.8321 - val_loss: 0.5122 - val_accuracy: 0.8372\n",
      "Epoch 59/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5119 - accuracy: 0.8317 - val_loss: 0.5110 - val_accuracy: 0.8382\n",
      "Epoch 60/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5106 - accuracy: 0.8323 - val_loss: 0.5101 - val_accuracy: 0.8384\n",
      "Epoch 61/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.5094 - accuracy: 0.8332 - val_loss: 0.5086 - val_accuracy: 0.8364\n",
      "Epoch 62/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5080 - accuracy: 0.8330 - val_loss: 0.5078 - val_accuracy: 0.8398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5070 - accuracy: 0.8327 - val_loss: 0.5061 - val_accuracy: 0.8386\n",
      "Epoch 64/100\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.5059 - accuracy: 0.8333 - val_loss: 0.5050 - val_accuracy: 0.8394\n",
      "Epoch 65/100\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.5047 - accuracy: 0.8335 - val_loss: 0.5047 - val_accuracy: 0.8408\n",
      "Epoch 66/100\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.5036 - accuracy: 0.8341 - val_loss: 0.5029 - val_accuracy: 0.8382\n",
      "Epoch 67/100\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.5026 - accuracy: 0.8339 - val_loss: 0.5025 - val_accuracy: 0.8402\n",
      "Epoch 68/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5015 - accuracy: 0.8344 - val_loss: 0.5015 - val_accuracy: 0.8414\n",
      "Epoch 69/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5004 - accuracy: 0.8350 - val_loss: 0.5003 - val_accuracy: 0.8404\n",
      "Epoch 70/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4994 - accuracy: 0.8349 - val_loss: 0.4996 - val_accuracy: 0.8404\n",
      "Epoch 71/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4984 - accuracy: 0.8355 - val_loss: 0.4983 - val_accuracy: 0.8416\n",
      "Epoch 72/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4974 - accuracy: 0.8357 - val_loss: 0.4978 - val_accuracy: 0.8418\n",
      "Epoch 73/100\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4965 - accuracy: 0.8358 - val_loss: 0.4967 - val_accuracy: 0.8426\n",
      "Epoch 74/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4956 - accuracy: 0.8361 - val_loss: 0.4957 - val_accuracy: 0.8432\n",
      "Epoch 75/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4947 - accuracy: 0.8363 - val_loss: 0.4952 - val_accuracy: 0.8418\n",
      "Epoch 76/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4938 - accuracy: 0.8365 - val_loss: 0.4940 - val_accuracy: 0.8420\n",
      "Epoch 77/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4928 - accuracy: 0.8369 - val_loss: 0.4934 - val_accuracy: 0.8430\n",
      "Epoch 78/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4919 - accuracy: 0.8375 - val_loss: 0.4929 - val_accuracy: 0.8428\n",
      "Epoch 79/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4911 - accuracy: 0.8375 - val_loss: 0.4922 - val_accuracy: 0.8416\n",
      "Epoch 80/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4903 - accuracy: 0.8382 - val_loss: 0.4908 - val_accuracy: 0.8434\n",
      "Epoch 81/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4894 - accuracy: 0.8382 - val_loss: 0.4902 - val_accuracy: 0.8438\n",
      "Epoch 82/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4887 - accuracy: 0.8381 - val_loss: 0.4893 - val_accuracy: 0.8434\n",
      "Epoch 83/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4879 - accuracy: 0.8383 - val_loss: 0.4886 - val_accuracy: 0.8446\n",
      "Epoch 84/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4871 - accuracy: 0.8389 - val_loss: 0.4886 - val_accuracy: 0.8436\n",
      "Epoch 85/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4863 - accuracy: 0.8390 - val_loss: 0.4870 - val_accuracy: 0.8432\n",
      "Epoch 86/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4855 - accuracy: 0.8388 - val_loss: 0.4868 - val_accuracy: 0.8448\n",
      "Epoch 87/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4847 - accuracy: 0.8395 - val_loss: 0.4864 - val_accuracy: 0.8442\n",
      "Epoch 88/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4841 - accuracy: 0.8401 - val_loss: 0.4859 - val_accuracy: 0.8446\n",
      "Epoch 89/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4833 - accuracy: 0.8396 - val_loss: 0.4845 - val_accuracy: 0.8440\n",
      "Epoch 90/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4826 - accuracy: 0.8402 - val_loss: 0.4854 - val_accuracy: 0.8444\n",
      "Epoch 91/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4819 - accuracy: 0.8406 - val_loss: 0.4840 - val_accuracy: 0.8456\n",
      "Epoch 92/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4812 - accuracy: 0.8402 - val_loss: 0.4829 - val_accuracy: 0.8460\n",
      "Epoch 93/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4805 - accuracy: 0.8408 - val_loss: 0.4826 - val_accuracy: 0.8442\n",
      "Epoch 94/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4799 - accuracy: 0.8414 - val_loss: 0.4820 - val_accuracy: 0.8458\n",
      "Epoch 95/100\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.4791 - accuracy: 0.8411 - val_loss: 0.4815 - val_accuracy: 0.8446\n",
      "Epoch 96/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4785 - accuracy: 0.8414 - val_loss: 0.4806 - val_accuracy: 0.8458\n",
      "Epoch 97/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4779 - accuracy: 0.8415 - val_loss: 0.4801 - val_accuracy: 0.8466\n",
      "Epoch 98/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4772 - accuracy: 0.8415 - val_loss: 0.4794 - val_accuracy: 0.8464\n",
      "Epoch 99/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4766 - accuracy: 0.8420 - val_loss: 0.4799 - val_accuracy: 0.8446\n",
      "Epoch 100/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4760 - accuracy: 0.8418 - val_loss: 0.4787 - val_accuracy: 0.8458\n",
      "18334/18334 [==============================] - 0s 25us/sample - loss: 0.4914 - accuracy: 0.8330\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 1.7261 - accuracy: 0.4791 - val_loss: 1.3094 - val_accuracy: 0.6498\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.1751 - accuracy: 0.6595 - val_loss: 1.0513 - val_accuracy: 0.6802\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0037 - accuracy: 0.6858 - val_loss: 0.9351 - val_accuracy: 0.7002\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.9150 - accuracy: 0.7058 - val_loss: 0.8674 - val_accuracy: 0.7184\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.8581 - accuracy: 0.7208 - val_loss: 0.8200 - val_accuracy: 0.7360\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.8172 - accuracy: 0.7333 - val_loss: 0.7852 - val_accuracy: 0.7474\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.7859 - accuracy: 0.7442 - val_loss: 0.7572 - val_accuracy: 0.7588\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.7606 - accuracy: 0.7506 - val_loss: 0.7351 - val_accuracy: 0.7644\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.7396 - accuracy: 0.7581 - val_loss: 0.7167 - val_accuracy: 0.7698\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.7218 - accuracy: 0.7641 - val_loss: 0.7005 - val_accuracy: 0.7774\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.7065 - accuracy: 0.7692 - val_loss: 0.6863 - val_accuracy: 0.7802\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6930 - accuracy: 0.7742 - val_loss: 0.6734 - val_accuracy: 0.7866\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6809 - accuracy: 0.7783 - val_loss: 0.6635 - val_accuracy: 0.7874\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.6702 - accuracy: 0.7823 - val_loss: 0.6532 - val_accuracy: 0.7920\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6605 - accuracy: 0.7853 - val_loss: 0.6438 - val_accuracy: 0.7954\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6517 - accuracy: 0.7873 - val_loss: 0.6361 - val_accuracy: 0.7980\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6436 - accuracy: 0.7907 - val_loss: 0.6281 - val_accuracy: 0.8008\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.6361 - accuracy: 0.7930 - val_loss: 0.6210 - val_accuracy: 0.8018\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.6292 - accuracy: 0.7953 - val_loss: 0.6156 - val_accuracy: 0.8038\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6229 - accuracy: 0.7973 - val_loss: 0.6098 - val_accuracy: 0.8050\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6169 - accuracy: 0.7989 - val_loss: 0.6039 - val_accuracy: 0.8068\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.6113 - accuracy: 0.8007 - val_loss: 0.5990 - val_accuracy: 0.8080\n",
      "Epoch 23/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6062 - accuracy: 0.8015 - val_loss: 0.5937 - val_accuracy: 0.8090\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6012 - accuracy: 0.8028 - val_loss: 0.5888 - val_accuracy: 0.8108\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5967 - accuracy: 0.8044 - val_loss: 0.5852 - val_accuracy: 0.8144\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5922 - accuracy: 0.8057 - val_loss: 0.5814 - val_accuracy: 0.8160\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5882 - accuracy: 0.8071 - val_loss: 0.5768 - val_accuracy: 0.8164\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5843 - accuracy: 0.8085 - val_loss: 0.5739 - val_accuracy: 0.8184\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5806 - accuracy: 0.8096 - val_loss: 0.5697 - val_accuracy: 0.8186\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5770 - accuracy: 0.8101 - val_loss: 0.5665 - val_accuracy: 0.8196\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5736 - accuracy: 0.8114 - val_loss: 0.5637 - val_accuracy: 0.8220\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5704 - accuracy: 0.8123 - val_loss: 0.5600 - val_accuracy: 0.8206\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5673 - accuracy: 0.8135 - val_loss: 0.5578 - val_accuracy: 0.8216\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5644 - accuracy: 0.8145 - val_loss: 0.5549 - val_accuracy: 0.8226\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5616 - accuracy: 0.8159 - val_loss: 0.5521 - val_accuracy: 0.8232\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5588 - accuracy: 0.8159 - val_loss: 0.5494 - val_accuracy: 0.8254\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5563 - accuracy: 0.8171 - val_loss: 0.5473 - val_accuracy: 0.8258\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5538 - accuracy: 0.8175 - val_loss: 0.5447 - val_accuracy: 0.8260\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5512 - accuracy: 0.8182 - val_loss: 0.5425 - val_accuracy: 0.8272\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5490 - accuracy: 0.8187 - val_loss: 0.5403 - val_accuracy: 0.8284\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5467 - accuracy: 0.8202 - val_loss: 0.5386 - val_accuracy: 0.8270\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5445 - accuracy: 0.8212 - val_loss: 0.5361 - val_accuracy: 0.8300\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5425 - accuracy: 0.8209 - val_loss: 0.5344 - val_accuracy: 0.8304\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5404 - accuracy: 0.8213 - val_loss: 0.5325 - val_accuracy: 0.8316\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5385 - accuracy: 0.8221 - val_loss: 0.5306 - val_accuracy: 0.8318\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5366 - accuracy: 0.8226 - val_loss: 0.5292 - val_accuracy: 0.8332\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5348 - accuracy: 0.8236 - val_loss: 0.5273 - val_accuracy: 0.8328\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5329 - accuracy: 0.8236 - val_loss: 0.5251 - val_accuracy: 0.8322\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5311 - accuracy: 0.8245 - val_loss: 0.5242 - val_accuracy: 0.8324\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5295 - accuracy: 0.8247 - val_loss: 0.5226 - val_accuracy: 0.8324\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5278 - accuracy: 0.8251 - val_loss: 0.5211 - val_accuracy: 0.8336\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5263 - accuracy: 0.8256 - val_loss: 0.5195 - val_accuracy: 0.8356\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5246 - accuracy: 0.8249 - val_loss: 0.5188 - val_accuracy: 0.8330\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5232 - accuracy: 0.8258 - val_loss: 0.5175 - val_accuracy: 0.8338\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5218 - accuracy: 0.8268 - val_loss: 0.5153 - val_accuracy: 0.8350\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5204 - accuracy: 0.8262 - val_loss: 0.5139 - val_accuracy: 0.8342\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5189 - accuracy: 0.8277 - val_loss: 0.5131 - val_accuracy: 0.8350\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5176 - accuracy: 0.8279 - val_loss: 0.5117 - val_accuracy: 0.8358\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5162 - accuracy: 0.8283 - val_loss: 0.5102 - val_accuracy: 0.8350\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5149 - accuracy: 0.8291 - val_loss: 0.5097 - val_accuracy: 0.8362\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5137 - accuracy: 0.8289 - val_loss: 0.5081 - val_accuracy: 0.8360\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5124 - accuracy: 0.8294 - val_loss: 0.5067 - val_accuracy: 0.8362\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5112 - accuracy: 0.8286 - val_loss: 0.5062 - val_accuracy: 0.8358\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5101 - accuracy: 0.8296 - val_loss: 0.5047 - val_accuracy: 0.8376\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5089 - accuracy: 0.8306 - val_loss: 0.5040 - val_accuracy: 0.8368\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5076 - accuracy: 0.8308 - val_loss: 0.5031 - val_accuracy: 0.8360\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5067 - accuracy: 0.8308 - val_loss: 0.5014 - val_accuracy: 0.8372\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5055 - accuracy: 0.8315 - val_loss: 0.5005 - val_accuracy: 0.8392\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5045 - accuracy: 0.8309 - val_loss: 0.4998 - val_accuracy: 0.8370\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5035 - accuracy: 0.8316 - val_loss: 0.4987 - val_accuracy: 0.8376\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5025 - accuracy: 0.8323 - val_loss: 0.4980 - val_accuracy: 0.8380\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5015 - accuracy: 0.8320 - val_loss: 0.4970 - val_accuracy: 0.8392\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5004 - accuracy: 0.8323 - val_loss: 0.4957 - val_accuracy: 0.8392\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4996 - accuracy: 0.8329 - val_loss: 0.4955 - val_accuracy: 0.8388\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4986 - accuracy: 0.8335 - val_loss: 0.4943 - val_accuracy: 0.8402\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4977 - accuracy: 0.8337 - val_loss: 0.4935 - val_accuracy: 0.8396\n",
      "Epoch 77/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4968 - accuracy: 0.8339 - val_loss: 0.4924 - val_accuracy: 0.8400\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4959 - accuracy: 0.8342 - val_loss: 0.4922 - val_accuracy: 0.8400\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4951 - accuracy: 0.8339 - val_loss: 0.4912 - val_accuracy: 0.8408\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4942 - accuracy: 0.8341 - val_loss: 0.4905 - val_accuracy: 0.8414\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4934 - accuracy: 0.8350 - val_loss: 0.4895 - val_accuracy: 0.8422\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4925 - accuracy: 0.8350 - val_loss: 0.4889 - val_accuracy: 0.8424\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4916 - accuracy: 0.8347 - val_loss: 0.4879 - val_accuracy: 0.8428\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4909 - accuracy: 0.8352 - val_loss: 0.4874 - val_accuracy: 0.8420\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4901 - accuracy: 0.8353 - val_loss: 0.4866 - val_accuracy: 0.8432\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4893 - accuracy: 0.8355 - val_loss: 0.4862 - val_accuracy: 0.8430\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4886 - accuracy: 0.8360 - val_loss: 0.4854 - val_accuracy: 0.8424\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4879 - accuracy: 0.8356 - val_loss: 0.4844 - val_accuracy: 0.8434\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4871 - accuracy: 0.8363 - val_loss: 0.4841 - val_accuracy: 0.8434\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4864 - accuracy: 0.8365 - val_loss: 0.4834 - val_accuracy: 0.8440\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4856 - accuracy: 0.8364 - val_loss: 0.4833 - val_accuracy: 0.8430\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4850 - accuracy: 0.8364 - val_loss: 0.4820 - val_accuracy: 0.8440\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4843 - accuracy: 0.8370 - val_loss: 0.4815 - val_accuracy: 0.8432\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4836 - accuracy: 0.8373 - val_loss: 0.4810 - val_accuracy: 0.8438\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4829 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.8440\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4823 - accuracy: 0.8378 - val_loss: 0.4794 - val_accuracy: 0.8450\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4815 - accuracy: 0.8376 - val_loss: 0.4796 - val_accuracy: 0.8448\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4810 - accuracy: 0.8379 - val_loss: 0.4790 - val_accuracy: 0.8440\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4803 - accuracy: 0.8382 - val_loss: 0.4779 - val_accuracy: 0.8446\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4797 - accuracy: 0.8381 - val_loss: 0.4775 - val_accuracy: 0.8442\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.4851 - accuracy: 0.8394\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 1.6724 - accuracy: 0.5032 - val_loss: 1.2991 - val_accuracy: 0.6518\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.1727 - accuracy: 0.6544 - val_loss: 1.0501 - val_accuracy: 0.6808\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0041 - accuracy: 0.6780 - val_loss: 0.9346 - val_accuracy: 0.7018\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.9147 - accuracy: 0.6995 - val_loss: 0.8657 - val_accuracy: 0.7232\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.8568 - accuracy: 0.7182 - val_loss: 0.8178 - val_accuracy: 0.7368\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.8152 - accuracy: 0.7333 - val_loss: 0.7829 - val_accuracy: 0.7514\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.7831 - accuracy: 0.7464 - val_loss: 0.7543 - val_accuracy: 0.7582\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.7573 - accuracy: 0.7551 - val_loss: 0.7318 - val_accuracy: 0.7678\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.7359 - accuracy: 0.7628 - val_loss: 0.7129 - val_accuracy: 0.7730\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7179 - accuracy: 0.7678 - val_loss: 0.6957 - val_accuracy: 0.7808\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.7024 - accuracy: 0.7738 - val_loss: 0.6821 - val_accuracy: 0.7860\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6887 - accuracy: 0.7779 - val_loss: 0.6695 - val_accuracy: 0.7890\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.6766 - accuracy: 0.7823 - val_loss: 0.6583 - val_accuracy: 0.7920\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6658 - accuracy: 0.7860 - val_loss: 0.6480 - val_accuracy: 0.7938\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6560 - accuracy: 0.7883 - val_loss: 0.6395 - val_accuracy: 0.7974\n",
      "Epoch 16/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6472 - accuracy: 0.7916 - val_loss: 0.6318 - val_accuracy: 0.7984\n",
      "Epoch 17/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6391 - accuracy: 0.7949 - val_loss: 0.6239 - val_accuracy: 0.8006\n",
      "Epoch 18/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6317 - accuracy: 0.7968 - val_loss: 0.6169 - val_accuracy: 0.8022\n",
      "Epoch 19/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6248 - accuracy: 0.7993 - val_loss: 0.6110 - val_accuracy: 0.8044\n",
      "Epoch 20/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6184 - accuracy: 0.8007 - val_loss: 0.6050 - val_accuracy: 0.8072\n",
      "Epoch 21/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6125 - accuracy: 0.8022 - val_loss: 0.5993 - val_accuracy: 0.8096\n",
      "Epoch 22/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6071 - accuracy: 0.8042 - val_loss: 0.5945 - val_accuracy: 0.8092\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6019 - accuracy: 0.8054 - val_loss: 0.5898 - val_accuracy: 0.8110\n",
      "Epoch 24/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5971 - accuracy: 0.8072 - val_loss: 0.5853 - val_accuracy: 0.8130\n",
      "Epoch 25/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5925 - accuracy: 0.8092 - val_loss: 0.5811 - val_accuracy: 0.8136\n",
      "Epoch 26/100\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.5882 - accuracy: 0.8103 - val_loss: 0.5777 - val_accuracy: 0.8142\n",
      "Epoch 27/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5840 - accuracy: 0.8111 - val_loss: 0.5735 - val_accuracy: 0.8152\n",
      "Epoch 28/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5803 - accuracy: 0.8115 - val_loss: 0.5698 - val_accuracy: 0.8174\n",
      "Epoch 29/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5766 - accuracy: 0.8125 - val_loss: 0.5662 - val_accuracy: 0.8186\n",
      "Epoch 30/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5731 - accuracy: 0.8137 - val_loss: 0.5631 - val_accuracy: 0.8202\n",
      "Epoch 31/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5697 - accuracy: 0.8148 - val_loss: 0.5600 - val_accuracy: 0.8206\n",
      "Epoch 32/100\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5666 - accuracy: 0.8150 - val_loss: 0.5569 - val_accuracy: 0.8218\n",
      "Epoch 33/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5636 - accuracy: 0.8165 - val_loss: 0.5544 - val_accuracy: 0.8212\n",
      "Epoch 34/100\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.5607 - accuracy: 0.8167 - val_loss: 0.5521 - val_accuracy: 0.8234\n",
      "Epoch 35/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5579 - accuracy: 0.8186 - val_loss: 0.5499 - val_accuracy: 0.8224\n",
      "Epoch 36/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5553 - accuracy: 0.8186 - val_loss: 0.5473 - val_accuracy: 0.8242\n",
      "Epoch 37/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5527 - accuracy: 0.8195 - val_loss: 0.5441 - val_accuracy: 0.8254\n",
      "Epoch 38/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5503 - accuracy: 0.8198 - val_loss: 0.5421 - val_accuracy: 0.8266\n",
      "Epoch 39/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5479 - accuracy: 0.8209 - val_loss: 0.5397 - val_accuracy: 0.8268\n",
      "Epoch 40/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5456 - accuracy: 0.8221 - val_loss: 0.5379 - val_accuracy: 0.8288\n",
      "Epoch 41/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5435 - accuracy: 0.8221 - val_loss: 0.5360 - val_accuracy: 0.8288\n",
      "Epoch 42/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5412 - accuracy: 0.8223 - val_loss: 0.5341 - val_accuracy: 0.8290\n",
      "Epoch 43/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5393 - accuracy: 0.8232 - val_loss: 0.5328 - val_accuracy: 0.8298\n",
      "Epoch 44/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5372 - accuracy: 0.8231 - val_loss: 0.5302 - val_accuracy: 0.8306\n",
      "Epoch 45/100\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5354 - accuracy: 0.8238 - val_loss: 0.5285 - val_accuracy: 0.8320\n",
      "Epoch 46/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5336 - accuracy: 0.8245 - val_loss: 0.5266 - val_accuracy: 0.8328\n",
      "Epoch 47/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5318 - accuracy: 0.8247 - val_loss: 0.5255 - val_accuracy: 0.8318\n",
      "Epoch 48/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5299 - accuracy: 0.8252 - val_loss: 0.5232 - val_accuracy: 0.8324\n",
      "Epoch 49/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5283 - accuracy: 0.8250 - val_loss: 0.5221 - val_accuracy: 0.8332\n",
      "Epoch 50/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5266 - accuracy: 0.8268 - val_loss: 0.5209 - val_accuracy: 0.8332\n",
      "Epoch 51/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5251 - accuracy: 0.8262 - val_loss: 0.5193 - val_accuracy: 0.8324\n",
      "Epoch 52/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5235 - accuracy: 0.8263 - val_loss: 0.5175 - val_accuracy: 0.8324\n",
      "Epoch 53/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5220 - accuracy: 0.8274 - val_loss: 0.5165 - val_accuracy: 0.8354\n",
      "Epoch 54/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5206 - accuracy: 0.8276 - val_loss: 0.5148 - val_accuracy: 0.8340\n",
      "Epoch 55/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5192 - accuracy: 0.8280 - val_loss: 0.5138 - val_accuracy: 0.8338\n",
      "Epoch 56/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5177 - accuracy: 0.8282 - val_loss: 0.5121 - val_accuracy: 0.8334\n",
      "Epoch 57/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5164 - accuracy: 0.8295 - val_loss: 0.5106 - val_accuracy: 0.8352\n",
      "Epoch 58/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5151 - accuracy: 0.8286 - val_loss: 0.5098 - val_accuracy: 0.8358\n",
      "Epoch 59/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5137 - accuracy: 0.8289 - val_loss: 0.5090 - val_accuracy: 0.8344\n",
      "Epoch 60/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5125 - accuracy: 0.8297 - val_loss: 0.5075 - val_accuracy: 0.8354\n",
      "Epoch 61/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5112 - accuracy: 0.8300 - val_loss: 0.5065 - val_accuracy: 0.8372\n",
      "Epoch 62/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.5101 - accuracy: 0.8300 - val_loss: 0.5056 - val_accuracy: 0.8378\n",
      "Epoch 63/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.5088 - accuracy: 0.8302 - val_loss: 0.5040 - val_accuracy: 0.8360\n",
      "Epoch 64/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5077 - accuracy: 0.8305 - val_loss: 0.5032 - val_accuracy: 0.8376\n",
      "Epoch 65/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.5065 - accuracy: 0.8311 - val_loss: 0.5020 - val_accuracy: 0.8368\n",
      "Epoch 66/100\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5055 - accuracy: 0.8315 - val_loss: 0.5010 - val_accuracy: 0.8378\n",
      "Epoch 67/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5044 - accuracy: 0.8318 - val_loss: 0.5005 - val_accuracy: 0.8378\n",
      "Epoch 68/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5034 - accuracy: 0.8323 - val_loss: 0.4992 - val_accuracy: 0.8382\n",
      "Epoch 69/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5023 - accuracy: 0.8328 - val_loss: 0.4989 - val_accuracy: 0.8392\n",
      "Epoch 70/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.5013 - accuracy: 0.8326 - val_loss: 0.4976 - val_accuracy: 0.8394\n",
      "Epoch 71/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.5003 - accuracy: 0.8331 - val_loss: 0.4968 - val_accuracy: 0.8398\n",
      "Epoch 72/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4993 - accuracy: 0.8333 - val_loss: 0.4960 - val_accuracy: 0.8406\n",
      "Epoch 73/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4984 - accuracy: 0.8335 - val_loss: 0.4949 - val_accuracy: 0.8404\n",
      "Epoch 74/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4974 - accuracy: 0.8331 - val_loss: 0.4940 - val_accuracy: 0.8400\n",
      "Epoch 75/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4965 - accuracy: 0.8337 - val_loss: 0.4939 - val_accuracy: 0.8410\n",
      "Epoch 76/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4957 - accuracy: 0.8336 - val_loss: 0.4926 - val_accuracy: 0.8410\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4948 - accuracy: 0.8342 - val_loss: 0.4918 - val_accuracy: 0.8416\n",
      "Epoch 78/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4939 - accuracy: 0.8345 - val_loss: 0.4912 - val_accuracy: 0.8420\n",
      "Epoch 79/100\n",
      "36667/36667 [==============================] - 1s 30us/sample - loss: 0.4929 - accuracy: 0.8358 - val_loss: 0.4909 - val_accuracy: 0.8428\n",
      "Epoch 80/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4922 - accuracy: 0.8356 - val_loss: 0.4892 - val_accuracy: 0.8426\n",
      "Epoch 81/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4913 - accuracy: 0.8360 - val_loss: 0.4887 - val_accuracy: 0.8420\n",
      "Epoch 82/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4905 - accuracy: 0.8359 - val_loss: 0.4886 - val_accuracy: 0.8428\n",
      "Epoch 83/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4898 - accuracy: 0.8357 - val_loss: 0.4876 - val_accuracy: 0.8430\n",
      "Epoch 84/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4889 - accuracy: 0.8366 - val_loss: 0.4867 - val_accuracy: 0.8426\n",
      "Epoch 85/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4882 - accuracy: 0.8364 - val_loss: 0.4859 - val_accuracy: 0.8420\n",
      "Epoch 86/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4875 - accuracy: 0.8372 - val_loss: 0.4853 - val_accuracy: 0.8428\n",
      "Epoch 87/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4867 - accuracy: 0.8376 - val_loss: 0.4847 - val_accuracy: 0.8432\n",
      "Epoch 88/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4860 - accuracy: 0.8379 - val_loss: 0.4839 - val_accuracy: 0.8424\n",
      "Epoch 89/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4853 - accuracy: 0.8374 - val_loss: 0.4834 - val_accuracy: 0.8432\n",
      "Epoch 90/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4845 - accuracy: 0.8381 - val_loss: 0.4826 - val_accuracy: 0.8432\n",
      "Epoch 91/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4839 - accuracy: 0.8385 - val_loss: 0.4820 - val_accuracy: 0.8440\n",
      "Epoch 92/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4832 - accuracy: 0.8386 - val_loss: 0.4819 - val_accuracy: 0.8426\n",
      "Epoch 93/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4824 - accuracy: 0.8388 - val_loss: 0.4818 - val_accuracy: 0.8450\n",
      "Epoch 94/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4818 - accuracy: 0.8391 - val_loss: 0.4807 - val_accuracy: 0.8434\n",
      "Epoch 95/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4811 - accuracy: 0.8388 - val_loss: 0.4803 - val_accuracy: 0.8440\n",
      "Epoch 96/100\n",
      "36667/36667 [==============================] - 1s 29us/sample - loss: 0.4804 - accuracy: 0.8395 - val_loss: 0.4795 - val_accuracy: 0.8442\n",
      "Epoch 97/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4799 - accuracy: 0.8397 - val_loss: 0.4786 - val_accuracy: 0.8426\n",
      "Epoch 98/100\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 0.4792 - accuracy: 0.8399 - val_loss: 0.4790 - val_accuracy: 0.8442\n",
      "Epoch 99/100\n",
      "36667/36667 [==============================] - 1s 28us/sample - loss: 0.4787 - accuracy: 0.8394 - val_loss: 0.4783 - val_accuracy: 0.84220.4756 - ac\n",
      "Epoch 100/100\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.4781 - accuracy: 0.8397 - val_loss: 0.4774 - val_accuracy: 0.8440\n",
      "18333/18333 [==============================] - 0s 21us/sample - loss: 0.4869 - accuracy: 0.8354\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.9817 - accuracy: 0.6658 - val_loss: 0.6241 - val_accuracy: 0.7926\n",
      "Epoch 2/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.5905 - accuracy: 0.7943 - val_loss: 0.5422 - val_accuracy: 0.8116\n",
      "Epoch 3/100\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5291 - accuracy: 0.8172 - val_loss: 0.4833 - val_accuracy: 0.8376\n",
      "Epoch 4/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4933 - accuracy: 0.8288 - val_loss: 0.4589 - val_accuracy: 0.8450\n",
      "Epoch 5/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4687 - accuracy: 0.8389 - val_loss: 0.4312 - val_accuracy: 0.8534\n",
      "Epoch 6/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4484 - accuracy: 0.8453 - val_loss: 0.4251 - val_accuracy: 0.8512\n",
      "Epoch 7/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4336 - accuracy: 0.8487 - val_loss: 0.4245 - val_accuracy: 0.8520\n",
      "Epoch 8/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4209 - accuracy: 0.8523 - val_loss: 0.4204 - val_accuracy: 0.8550\n",
      "Epoch 9/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4080 - accuracy: 0.8571 - val_loss: 0.4311 - val_accuracy: 0.8484\n",
      "Epoch 10/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3977 - accuracy: 0.8582 - val_loss: 0.3953 - val_accuracy: 0.8574\n",
      "Epoch 11/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3877 - accuracy: 0.8630 - val_loss: 0.3977 - val_accuracy: 0.8590\n",
      "Epoch 12/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3786 - accuracy: 0.8644 - val_loss: 0.3918 - val_accuracy: 0.8638\n",
      "Epoch 13/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3701 - accuracy: 0.8685 - val_loss: 0.3933 - val_accuracy: 0.8576\n",
      "Epoch 14/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3642 - accuracy: 0.8697 - val_loss: 0.3814 - val_accuracy: 0.8656\n",
      "Epoch 15/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3574 - accuracy: 0.8712 - val_loss: 0.3931 - val_accuracy: 0.8594\n",
      "Epoch 16/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3533 - accuracy: 0.8738 - val_loss: 0.3772 - val_accuracy: 0.8684\n",
      "Epoch 17/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3464 - accuracy: 0.8759 - val_loss: 0.3921 - val_accuracy: 0.8596\n",
      "Epoch 18/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3424 - accuracy: 0.8772 - val_loss: 0.3760 - val_accuracy: 0.8646\n",
      "Epoch 19/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3363 - accuracy: 0.8798 - val_loss: 0.3651 - val_accuracy: 0.8674\n",
      "Epoch 20/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3331 - accuracy: 0.8807 - val_loss: 0.3663 - val_accuracy: 0.8702\n",
      "Epoch 21/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3283 - accuracy: 0.8818 - val_loss: 0.3588 - val_accuracy: 0.8702\n",
      "Epoch 22/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3241 - accuracy: 0.8830 - val_loss: 0.3780 - val_accuracy: 0.8652\n",
      "Epoch 23/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3210 - accuracy: 0.8848 - val_loss: 0.3573 - val_accuracy: 0.8730\n",
      "Epoch 24/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3175 - accuracy: 0.8862 - val_loss: 0.3670 - val_accuracy: 0.8660\n",
      "Epoch 25/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3143 - accuracy: 0.8857 - val_loss: 0.3563 - val_accuracy: 0.8714\n",
      "Epoch 26/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3101 - accuracy: 0.8889 - val_loss: 0.3907 - val_accuracy: 0.8668\n",
      "Epoch 27/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3079 - accuracy: 0.8878 - val_loss: 0.3569 - val_accuracy: 0.8728\n",
      "Epoch 28/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3033 - accuracy: 0.8906 - val_loss: 0.3558 - val_accuracy: 0.8746\n",
      "Epoch 29/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3016 - accuracy: 0.8909 - val_loss: 0.3590 - val_accuracy: 0.8710\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2981 - accuracy: 0.8918 - val_loss: 0.3709 - val_accuracy: 0.8696\n",
      "Epoch 31/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.2941 - accuracy: 0.8933 - val_loss: 0.3746 - val_accuracy: 0.8678\n",
      "Epoch 32/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2919 - accuracy: 0.8943 - val_loss: 0.3591 - val_accuracy: 0.8736\n",
      "Epoch 33/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2901 - accuracy: 0.8943 - val_loss: 0.3581 - val_accuracy: 0.8722\n",
      "Epoch 34/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2869 - accuracy: 0.8959 - val_loss: 0.3578 - val_accuracy: 0.8716\n",
      "Epoch 35/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2844 - accuracy: 0.8971 - val_loss: 0.3612 - val_accuracy: 0.8718\n",
      "Epoch 36/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2828 - accuracy: 0.8990 - val_loss: 0.3575 - val_accuracy: 0.8708\n",
      "Epoch 37/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2798 - accuracy: 0.8983 - val_loss: 0.3565 - val_accuracy: 0.8716\n",
      "Epoch 38/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2766 - accuracy: 0.8993 - val_loss: 0.3523 - val_accuracy: 0.8742\n",
      "Epoch 39/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2749 - accuracy: 0.9013 - val_loss: 0.3762 - val_accuracy: 0.8692\n",
      "Epoch 40/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.2729 - accuracy: 0.9000 - val_loss: 0.3513 - val_accuracy: 0.8758\n",
      "Epoch 41/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2708 - accuracy: 0.9014 - val_loss: 0.3558 - val_accuracy: 0.8754\n",
      "Epoch 42/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2675 - accuracy: 0.9030 - val_loss: 0.3533 - val_accuracy: 0.8756\n",
      "Epoch 43/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.2656 - accuracy: 0.9025 - val_loss: 0.3627 - val_accuracy: 0.8726\n",
      "Epoch 44/100\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2636 - accuracy: 0.9044 - val_loss: 0.3620 - val_accuracy: 0.8720\n",
      "Epoch 45/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2618 - accuracy: 0.9038 - val_loss: 0.3826 - val_accuracy: 0.8678\n",
      "Epoch 46/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.2601 - accuracy: 0.9044 - val_loss: 0.3635 - val_accuracy: 0.8718\n",
      "Epoch 47/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2579 - accuracy: 0.9059 - val_loss: 0.3500 - val_accuracy: 0.8766\n",
      "Epoch 48/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.2575 - accuracy: 0.9050 - val_loss: 0.3509 - val_accuracy: 0.8802\n",
      "Epoch 49/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.2549 - accuracy: 0.9070 - val_loss: 0.3807 - val_accuracy: 0.8714\n",
      "Epoch 50/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.2528 - accuracy: 0.9077 - val_loss: 0.3608 - val_accuracy: 0.8786\n",
      "Epoch 51/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2505 - accuracy: 0.9088 - val_loss: 0.3641 - val_accuracy: 0.8770\n",
      "Epoch 52/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.2494 - accuracy: 0.9082 - val_loss: 0.3740 - val_accuracy: 0.8700\n",
      "Epoch 53/100\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.2481 - accuracy: 0.9100 - val_loss: 0.3747 - val_accuracy: 0.8682\n",
      "Epoch 54/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.2460 - accuracy: 0.9098 - val_loss: 0.3815 - val_accuracy: 0.8688\n",
      "Epoch 55/100\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.2443 - accuracy: 0.9094 - val_loss: 0.3678 - val_accuracy: 0.8772\n",
      "Epoch 56/100\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2434 - accuracy: 0.9101 - val_loss: 0.3887 - val_accuracy: 0.8706\n",
      "Epoch 57/100\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.2409 - accuracy: 0.9116 - val_loss: 0.3718 - val_accuracy: 0.8680\n",
      "18334/18334 [==============================] - 0s 25us/sample - loss: 0.3765 - accuracy: 0.8710\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.0463 - accuracy: 0.6225 - val_loss: 0.7164 - val_accuracy: 0.7510\n",
      "Epoch 2/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6315 - accuracy: 0.7784 - val_loss: 0.5735 - val_accuracy: 0.8046\n",
      "Epoch 3/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.5562 - accuracy: 0.8053 - val_loss: 0.5118 - val_accuracy: 0.8296\n",
      "Epoch 4/100\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5176 - accuracy: 0.8183 - val_loss: 0.4985 - val_accuracy: 0.8314\n",
      "Epoch 5/100\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4866 - accuracy: 0.8291 - val_loss: 0.4812 - val_accuracy: 0.8352\n",
      "Epoch 6/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4685 - accuracy: 0.8345 - val_loss: 0.4392 - val_accuracy: 0.8492\n",
      "Epoch 7/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4486 - accuracy: 0.8405 - val_loss: 0.4233 - val_accuracy: 0.8548\n",
      "Epoch 8/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4345 - accuracy: 0.8468 - val_loss: 0.4649 - val_accuracy: 0.8406\n",
      "Epoch 9/100\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4217 - accuracy: 0.8502 - val_loss: 0.4183 - val_accuracy: 0.8534\n",
      "Epoch 10/100\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4115 - accuracy: 0.8547 - val_loss: 0.4063 - val_accuracy: 0.8626\n",
      "Epoch 11/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4013 - accuracy: 0.8561 - val_loss: 0.4228 - val_accuracy: 0.8476\n",
      "Epoch 12/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3927 - accuracy: 0.8598 - val_loss: 0.3855 - val_accuracy: 0.8664\n",
      "Epoch 13/100\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3832 - accuracy: 0.8636 - val_loss: 0.3818 - val_accuracy: 0.8654\n",
      "Epoch 14/100\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3770 - accuracy: 0.8649 - val_loss: 0.3816 - val_accuracy: 0.8682\n",
      "Epoch 15/100\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3704 - accuracy: 0.8673 - val_loss: 0.3799 - val_accuracy: 0.8662\n",
      "Epoch 16/100\n",
      " 4896/36667 [===>..........................] - ETA: 0s - loss: 0.3574 - accuracy: 0.8689WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-4c4fdd703808>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m rnd_search_cv.fit(X_train, y_train, epochs=100,\n\u001b[1;32m      8\u001b[0m                  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/tensorflow_core/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/tensorflow_core/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/vision-env/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " param_distribs = {\n",
    "        \"n_hidden\": [0, 1, 2, 3],\n",
    "        \"n_neurons\": np.arange(1, 100),\n",
    "        \"learning_rate\": reciprocal(3e-4, 3e-2)}\n",
    "    \n",
    "rnd_search_cv = RandomizedSearchCV(keras_classifier, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-f97e75618950>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vision-env)",
   "language": "python",
   "name": "vision-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
